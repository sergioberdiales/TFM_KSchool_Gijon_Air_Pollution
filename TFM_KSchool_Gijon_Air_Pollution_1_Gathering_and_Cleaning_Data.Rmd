---
title: "Gijon Air Pollution - Gathering and Cleaning Data"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


### Project goals:

  - Construct a web dashboard to visualize the evolution of the main air pollution indicators of Gijon city. (Asturias; Spain).
  - Build a model to predict in the short term (<24h) the evolution of air pollutants concentration by monitoring station.

### Data gathering

Loading packages
```{r , warning= FALSE, message= FALSE}
library(readr)
library(dplyr)
library(tidyr)
library(openair) # http://davidcarslaw.github.io/openair/
library(purrr)
library(lubridate)
library(ggplot2)
library(stringr)
library(knitr)
library(xts)
library(zoo)
library(gridExtra)
library(astsa)
library(rvest)
library(fpp2)
library(ranger)
library(broom)
library(RcppRoll)


```


First of all I have to check if I will have the basic data to make the analysis. I need air pollution and weather data of the Gijon area. 
The town hall of Gijon has an open data web portal here https://transparencia.gijon.es/. We can download pollution air data on csv format from year 2000 to 2017 [here](https://transparencia.gijon.es/search/risp_dataset/page/1808-catalogo-de-datos?utf8=%E2%9C%93&search=aire+&search_sector=&search_format=&commit=Buscar&authenticity_token=j8%2F3CvCuPcDkrRe%2F1NR5RBp0t%2FOOosiA7724w3T2mB4%3D): 

I downloaded 18 csv files with air pollution and weather data of Gijón from years 2000 to 2017. I saved them in the "data" folder.
I downloaded two more files from this web, a csv file with the description of the variables and another csv file with information about the measurement stations. 

We take a look to the information included in  the stations_info.csv file. It includes the stations addresses, longitude, latitude and their IDs and names. All this information, as we will see, is included in the csv files with pollution and weather data too. So, we are not going to use this file anymore.


```{r , warning= FALSE, message= FALSE}
stations <- read_delim('data/stations_info.csv',
                       delim = ';',
                       escape_double = FALSE, 
                       trim_ws = TRUE,
                       locale = locale(encoding = "ISO-8859-1"),
                       col_types = cols(.default = "c"))
stations



```

We can see on this image the location of each station. http://movil.asturias.es/medioambiente/articulos/ficheros/Informe%20de%20calidad%20del%20aire%20en%20Asturias%202016.pdf

![Image source: "Informe de calidad del aire del Principado de Asturias (2016)".](imgs/gijon_stations_map.jpg)

The air_data_descriptors.csv file contains information about the nature of the elements monitored by the stations. Names, descriptions and units.
```{r , warning= FALSE, message= FALSE}
variables <- read_csv('data/air_data_descriptors.csv', locale = locale(encoding = "ISO-8859-1"))
variables

```

In order to import the data from the 18 csv files we list all the files in the object data_files. 

```{r warning= FALSE, message= FALSE}
data_files <- list.files(path = "data", pattern = "air_data_20*")
```

Then, we map the function read_csv on this list in order to import every file and finally merge them in a unique dataframe (air_data_0) with reduce(rbind). 

```{r warning= FALSE, message= FALSE}
air_data_0 <- data_files %>% 
    map(function(x) {
        read_csv(paste0("./data/", x), locale = locale(encoding = "ISO-8859-1"), col_types = cols(.default = "c"))
    }) %>%
    reduce(rbind)
```
We take a look to the data set
```{r warning= FALSE, message= FALSE}
glimpse(air_data_0)
```


We change the names of some variables.

```{r warning= FALSE, message= FALSE}

# Variables names changing
air_data_1 <- air_data_0 %>% rename(station = `Estación`,
                                    station_name = `Título`,
                                    date_time_utc = `Fecha Solar (UTC)`,
                                    latitude = latitud,
                                    longitude = longitud)
```

We imported all the columns as characters in order to avoid problems with the format attributions. So, we have to make now some format variable changes.

We change the date_time_utc format from character to date time. 
```{r warning= FALSE, message= FALSE}

air_data_1$date_time_utc <- ymd_hms(air_data_1$date_time_utc)
```

We change the station and station_name formats from character to factor.
```{r warning= FALSE, message= FALSE}
air_data_1$station <- as.factor(air_data_1$station)
air_data_1$station_name <- as.factor(air_data_1$station_name)
```

We create a vector with all the variables we want to be numeric
```{r warning= FALSE, message= FALSE}
num <- colnames(air_data_1)[c(3, 4, 6:22)]
```
We make the conversion of this set of variables to numeric 
```{r warning= FALSE, message= FALSE}
air_data_1 <- air_data_1 %>% mutate_at(num, as.numeric)
```

We create a dictionary with an alias for each station in order to add a new variable with more
convenient station names
```{r warning= FALSE, message= FALSE}
alias_dict <- data.frame(
      station = c("1", "2", "3", "4", "10", "11"),
      station_alias = c("Constitución", "Argentina", "H. Felgueroso", "Castilla", "Montevil", "Santa Bárbara")
)
```
We join the alias dictionary to the air_data_1 data frame to add the new variable to the data 
set.
```{r warning= FALSE, message= FALSE}
air_data_1 <- air_data_1 %>% left_join(alias_dict, by = 'station')
```

We call the summary function to inspect the data main indicators
```{r warning= FALSE, message= FALSE}
summary(air_data_1)
```

There are several variables which minimun values are -9999.

```{r warning = FALSE, message = FALSE}

kable(air_data_1 %>% filter(SO2 == -9999))


```

They are all from the same day (2000-01-27) and from the same station ('H. Felgueroso'). All the variables from that day, excepts the 'CO' indicator, are equal to '-9999'. 

So, we replace these values by NAs. 
```{r warning = FALSE, message = FALSE}

air_data_2 <- air_data_1 %>% mutate(SO2 = replace(SO2, SO2 == -9999, NA),
                                    NO = replace(NO, NO == -9999, NA),
                                    NO2 = replace(NO2, NO2 == -9999, NA),
                                    PM10 = replace(PM10, PM10 == -9999, NA),
                                    O3 = replace(O3, O3 == -9999, NA))

```


We check again the output of summary. 

```{r warning = FALSE, message = FALSE}
summary(air_data_2)
```

Some pollutant variables have as minimum negative values. It does not make much sense. We take a look to the data in order to quantify the problem.

30 SO2 observations between 2015-12-25 and 2015-12-28 from the Montevil station:

```{r warning = FALSE, message = FALSE}
kable(neg_SO2 <- air_data_2 %>% filter(SO2 < 0))
```

2 RS observations from the Constitucion station:

```{r warning = FALSE, message = FALSE}
kable(neg_RS <- air_data_2 %>% filter(RS < 0))
```

27 TOL observations between the 2008-12-11 and the 2008-12-15 from the Constitucion station:

```{r warning = FALSE, message = FALSE}
kable(neg_TOL <- air_data_2 %>% filter(TOL < 0))
```

59 MXIL observations between the 2008-12-10 and the 2008-12-15 from the Constitucion station:

```{r warning = FALSE, message = FALSE}
kable(neg_MXIL <- air_data_2 %>% filter(MXIL < 0))
```

There are not many cases. We replace them all by NAs and call again the summary function (to do: ask to the data owner about this detail).

```{r warning = FALSE, message = FALSE}

air_data_2 <- air_data_2 %>% mutate(SO2 = replace(SO2, SO2 < 0, NA),
                                    RS = replace(RS, RS < 0, NA),
                                    TOL = replace(TOL, TOL < 0, NA),
                                    MXIL = replace(MXIL, MXIL < 0, NA))

summary(air_data_2)

```

We take a look to the data completeness. What proportion of nas do we have by variable, station, year, etc?
```{r warning = FALSE, message = FALSE}

data_completeness <- air_data_2 %>% 
  group_by(station_alias, year = year(date_time_utc)) %>% 
  summarise_all(funs(round(sum(!is.na(.))/n(), 2))) %>%
  select(-c(3:7, 25:28)) # These columns do not have any na. We exclude them.

kable(head(data_completeness, 10))

```

We are going to check the data completeness by station:

Constitución: There is data registered from the variables SO2, NO, NO2, CO, PM10, 03, dd, vv, TMP,  HR, PRB, HS and LL since the year 2000.
There are measurements of the variables BEN, TOL and MXIL since the year 2006 (only 0.01% ). The PM25 particles are monitored since the year 2008 (2008: only covered 0,02% of the year).
During the year 2008 the completeness of several variables (HR, PRB, HS, LL, BEN, TOL y MXIL) decrease until 88% (to do: check there was not caused by a data importing problem.)
```{r warning = FALSE, message = FALSE}
constitucion_data <- data_completeness %>% filter(station_alias == 'Constitución')
kable(constitucion_data)
```

Argentina: data since the year 2000. Variables: SO2, NO, NO2, CO, PM10 and 03.
```{r warning = FALSE, message = FALSE}
argentina_data <- data_completeness %>% filter(station_alias == 'Argentina')
kable(argentina_data)
```

H. Felgueroso: data since the year 2000. Variables: SO2, NO, NO2, CO, PM10 and 03. During the year 2006 the completeness of the data decrease until 88% (to do: check there was not caused by a data importing problem.)
```{r warning = FALSE, message = FALSE}
felgueroso_data <- data_completeness %>% filter(station_alias == 'H. Felgueroso')
kable(felgueroso_data)
```

Castilla: data since the year 2000. Variables: SO2, NO, NO2, CO, PM10 and 03. During the year 2015 the completeness of the data decrease until 77% (to do: check there was not caused by a data importing problem.)
```{r warning = FALSE, message = FALSE}
castilla_data <- data_completeness %>% filter(station_alias == 'Castilla')
kable(castilla_data)
```

Montevil: Data since the year 2009. Variables: SO2, NO, NO2, 03, dd, vv, TMP, HR, PRB, HS, 
LL and PM25.
```{r warning = FALSE, message = FALSE}
montevil_data <- data_completeness %>% filter(station_alias == 'Montevil')
kable(montevil_data)
```

Santa Bárbara: Data since the year 2016. Variables: NO, NO2, CO, PM10, 03 and PM25
```{r warning = FALSE, message = FALSE}
barbara_data <- data_completeness %>% filter(station_alias == 'Santa Bárbara')
kable(barbara_data)
```

All the stations have 2018 data, but it is just 6 observations. We drop them to avoid problems when visualising the data.

```{r warning = FALSE, message = FALSE}
observations_per_year <- air_data_2 %>% group_by(year = year(date_time_utc)) %>%
                        summarise(n = n())
kable(observations_per_year)
```

```{r warning = FALSE, message = FALSE}
air_data_2$year <- year(air_data_2$date_time_utc)
air_data_2 <- air_data_2 %>% filter(year != '2018')

```

We add to the dataset several more time variables. 

```{r warning = FALSE, message = FALSE}

air_data_2$month <- month(air_data_2$date_time_utc)
air_data_2$year_month_day <- ymd(air_data_2$date_time_utc)
air_data_2$week_day <- wday(air_data_2$date_time_utc, week_start = getOption("lubridate.week.start", 1))
air_data_2$hour <- hour(air_data_2$date_time_utc)



```


```{r warning = FALSE, message = FALSE}

# We create a CO dataset with CO Moving averages (each 8 hours). It is needed to measure the acompplishment of UE #limits for this pollutant

co_data <- air_data_2 %>% select(station_alias, date_time_utc, CO) %>%
                          mutate(ma_co_8 = roll_mean(CO, 8, fill=0))

hist(co_data$ma_co_8)
summary(co_data$ma_co_8)
plot(co_data$ma_co_8)

# pending na treatment

saveRDS(co_data, file = "co_data.rds")
write_csv(co_data, "final_csvs/co_data.csv")



```

We save this dataset as a rds object.
```{r warning = FALSE, message = FALSE}

saveRDS(air_data_2, file = "air_data_2.rds")
#air_data_2 <- read_rds("air_data_2.rds")
#write_csv(air_data_2, "final_csvs/air_data_2.csv")
```

prueba