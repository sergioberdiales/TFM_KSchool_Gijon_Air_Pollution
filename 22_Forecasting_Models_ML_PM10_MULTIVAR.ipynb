{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "22_Forecasting_Models_ML_PM10_MULTIVAR.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sergioberdiales/TFM_KSchool_Gijon_Air_Pollution/blob/master/22_Forecasting_Models_ML_PM10_MULTIVAR.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "C2KUABWEp4T6",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "In this notebook we are going to try to improve the forecasts creating multivariate models. \n",
        "We will use the XGBoost algorithm and the three years training period (2014-01-01 - 2016-12-31).\n",
        "Testing period: 2017-01-01 - 2017-09-30. "
      ]
    },
    {
      "metadata": {
        "id": "i-4Gs37dWIA0",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### We import the libraries we need to run the algorithms"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "outputId": "64526906-52bf-4b09-fd65-789412d7236b",
        "id": "OxJRU8VLpp9W",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "%pylab inline\n",
        "import pandas as pd\n",
        "\n",
        "# We install and import pyreadr, in order to read rds objects.  \n",
        "# https://github.com/ofajardo/pyreadr\n",
        "\n",
        "!pip install pyreadr\n",
        "import pyreadr\n",
        "\n",
        "\n",
        "# Importing models\n",
        "\n",
        "\n",
        "import statsmodels.api as sm\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from xgboost import XGBRegressor\n",
        "import os\n",
        "os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\"\n",
        "\n",
        "# Importing metrics\n",
        "\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "from sklearn.metrics import r2_score\n",
        "\n",
        "# Model selection\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# Variable selection\n",
        "\n",
        "import sklearn\n",
        "from sklearn.feature_selection import f_regression\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Populating the interactive namespace from numpy and matplotlib\n",
            "Requirement already satisfied: pyreadr in /usr/local/lib/python3.6/dist-packages (0.1.6)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "adowIIZEus6d",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "Dh0qqPFMpp9d"
      },
      "cell_type": "markdown",
      "source": [
        "We upload the train and test data. All rds files from this folder  ~\\`TFM_KSchool_Gijon_Air_Pollution\\train_test\\\n",
        "Forecasting_Models_ML_PM10_MULTIVAR\n",
        "\n",
        "The train and test datasets were generated running this rmd file \"_10_2_train_test_MULTIVAR_datasets.rmd\""
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "outputId": "27d05b8a-fff1-45e3-d49b-18b2ebc3202a",
        "id": "gWOu3DSopp9e",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 662
        }
      },
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "uploaded = files.upload()\n",
        "\n",
        "for fn in uploaded.keys():\n",
        "  print('User uploaded file \"{name}\" with length {length} bytes'.format(\n",
        "      name=fn, length=len(uploaded[fn])))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-8da2fe4c-266a-40a6-adfd-3182b63acbb5\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-8da2fe4c-266a-40a6-adfd-3182b63acbb5\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving X_test_PM10_201701_201709_multivar.rds to X_test_PM10_201701_201709_multivar.rds\n",
            "Saving X_test_PM10_20170101_20170114_multivar.rds to X_test_PM10_20170101_20170114_multivar.rds\n",
            "Saving X_train_PM10_200901_201612_multivar.rds to X_train_PM10_200901_201612_multivar.rds\n",
            "Saving X_train_PM10_201401_201612_multivar.rds to X_train_PM10_201401_201612_multivar.rds\n",
            "Saving X_train_PM10_201610_201612_multivar.rds to X_train_PM10_201610_201612_multivar.rds\n",
            "Saving X_validation_PM10_201710_201712_multivar.rds to X_validation_PM10_201710_201712_multivar.rds\n",
            "Saving y_test_PM10_201701_201709_multivar.rds to y_test_PM10_201701_201709_multivar.rds\n",
            "Saving y_test_PM10_20170101_20170114_multivar.rds to y_test_PM10_20170101_20170114_multivar.rds\n",
            "Saving y_train_PM10_200901_201612_multivar.rds to y_train_PM10_200901_201612_multivar.rds\n",
            "Saving y_train_PM10_201401_201612_multivar.rds to y_train_PM10_201401_201612_multivar.rds\n",
            "Saving y_train_PM10_201610_201612_multivar.rds to y_train_PM10_201610_201612_multivar.rds\n",
            "Saving y_validation_PM10_201710_201712_multivar.rds to y_validation_PM10_201710_201712_multivar.rds\n",
            "User uploaded file \"X_test_PM10_201701_201709_multivar.rds\" with length 366304 bytes\n",
            "User uploaded file \"X_test_PM10_20170101_20170114_multivar.rds\" with length 5023 bytes\n",
            "User uploaded file \"X_train_PM10_200901_201612_multivar.rds\" with length 1702981 bytes\n",
            "User uploaded file \"X_train_PM10_201401_201612_multivar.rds\" with length 1486294 bytes\n",
            "User uploaded file \"X_train_PM10_201610_201612_multivar.rds\" with length 47980 bytes\n",
            "User uploaded file \"X_validation_PM10_201710_201712_multivar.rds\" with length 54956 bytes\n",
            "User uploaded file \"y_test_PM10_201701_201709_multivar.rds\" with length 8389 bytes\n",
            "User uploaded file \"y_test_PM10_20170101_20170114_multivar.rds\" with length 1179 bytes\n",
            "User uploaded file \"y_train_PM10_200901_201612_multivar.rds\" with length 237551 bytes\n",
            "User uploaded file \"y_train_PM10_201401_201612_multivar.rds\" with length 32888 bytes\n",
            "User uploaded file \"y_train_PM10_201610_201612_multivar.rds\" with length 3558 bytes\n",
            "User uploaded file \"y_validation_PM10_201710_201712_multivar.rds\" with length 3607 bytes\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "kV-EfqxNtTqI",
        "colab_type": "code",
        "outputId": "6c889766-2e62-45cc-ac51-69f2a64a1092",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "hmOhVnHk4lGx",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Adding the variable 'no_lab_days'\n",
        "As we saw in the data exploration phase if a day is holiday or not has an effect in the PM10 levels. So, we add the variable 'no_lab_days' to try to improve the model."
      ]
    },
    {
      "metadata": {
        "id": "kK1hRo93OzCi",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### XGBOOST"
      ]
    },
    {
      "metadata": {
        "id": "a-qac8vAo_dy",
        "colab_type": "code",
        "outputId": "28eba09f-beba-4a4b-9777-8b1e4c3eecd6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        }
      },
      "cell_type": "code",
      "source": [
        "X_train = pyreadr.read_r(\"X_train_PM10_201401_201612_multivar.rds\")\n",
        "y_train = pyreadr.read_r(\"y_train_PM10_201401_201612_multivar.rds\")\n",
        "\n",
        "X_test = pyreadr.read_r(\"X_test_PM10_201701_201709_multivar.rds\")\n",
        "y_test = pyreadr.read_r(\"y_test_PM10_201701_201709_multivar.rds\")\n",
        "\n",
        "X_train = X_train[None]\n",
        "y_train = y_train[None]\n",
        "X_test = X_test[None]\n",
        "y_test = y_test[None]\n",
        "\n",
        "X_train = X_train[['PM10_1', 'PM10_2', 'PM10_3', 'PM10_4', 'PM10_22', 'PM10_23', 'PM10_24',\n",
        "                   'PM10_48', 'PM10_72', 'PM10_96', 'PM10_120', 'PM10_144', 'PM10_168', 'no_lab_days']]\n",
        "X_test = X_test[['PM10_1', 'PM10_2', 'PM10_3', 'PM10_4', 'PM10_22', 'PM10_23', 'PM10_24',\n",
        "                 'PM10_48', 'PM10_72', 'PM10_96', 'PM10_120', 'PM10_144', 'PM10_168', 'no_lab_days']]\n",
        "\n",
        "\n",
        "X_train = pd.get_dummies(X_train)\n",
        "X_test  = pd.get_dummies(X_test)\n",
        "\n",
        "\n",
        "\n",
        "regXGB = XGBRegressor(n_estimators=500, min_samples_leaf=10,max_depth=2, random_state=42)\n",
        "regXGB.fit(X_train,y_train)\n",
        "\n",
        "\n",
        "# Compute train scores\n",
        "\n",
        "y_pred = regXGB.predict(X_train)\n",
        "\n",
        "r2_train = r2_score(y_train, y_pred)\n",
        "rmse_train = np.sqrt(mean_squared_error(y_train, y_pred))\n",
        "mae_train = mean_absolute_error(y_train, y_pred)\n",
        "r2_adjusted_train = 1 - (1-r2_score(y_train, y_pred))*(len(y_train)-1)/(len(y_train)-X_train.shape[1]-1)\n",
        "sd_train = std(y_train)\n",
        "\n",
        "print(\"R^2 train: {}\".format(r2_train))\n",
        "print(\"R^2 adjusted train: {}\".format(r2_adjusted_train))\n",
        "print(\"Mean Absolute Error train: {}\".format(mae_train))\n",
        "print(\"Root Mean Squared Error train: {}\".format(rmse_train)) \n",
        "print(\"Standard Deviation train: {}\".format(sd_train))  \n",
        "\n",
        "# Compute test scores\n",
        "\n",
        "y_pred = regXGB.predict(X_test)\n",
        "\n",
        "r2_test = r2_score(y_test, y_pred)\n",
        "rmse_test = np.sqrt(mean_squared_error(y_test, y_pred))\n",
        "mae_test = mean_absolute_error(y_test, y_pred)\n",
        "r2_adjusted_test = 1 - (1-r2_score(y_test, y_pred))*(len(y_test)-1)/(len(y_test)-X_test.shape[1]-1)\n",
        "sd_test = std(y_test)\n",
        "\n",
        "print(\"R^2 test: {}\".format(r2_test))\n",
        "print(\"R^2 adjusted test: {}\".format(r2_adjusted_test))\n",
        "print(\"Mean Absolute Error test: {}\".format(mae_test))\n",
        "print(\"Root Mean Squared Error test: {}\".format(rmse_test))\n",
        "print(\"Standard Deviation test: {}\".format(sd_test))  \n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "R^2 train: 0.6631146245341922\n",
            "R^2 adjusted train: 0.6629191549135831\n",
            "Mean Absolute Error train: 5.503836677301813\n",
            "Root Mean Squared Error train: 8.597633475294032\n",
            "Standard Deviation train: PM10_0    14.812823\n",
            "dtype: float64\n",
            "R^2 test: 0.5989526095973352\n",
            "R^2 adjusted test: 0.5980077830140087\n",
            "Mean Absolute Error test: 4.796642205995463\n",
            "Root Mean Squared Error test: 6.80743069887127\n",
            "Standard Deviation test: PM10_0    10.749429\n",
            "dtype: float64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "pBRprxjZ_o04",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        ""
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "y97KjgSq_pRL"
      },
      "cell_type": "markdown",
      "source": [
        "## Adding the variable 'hour'"
      ]
    },
    {
      "metadata": {
        "id": "AVzvaYhz7PWa",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The levels of the PM10 pollutant also depends on the hour of the day. We add as a new variable to the model"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "outputId": "1ecb5ea0-bd5b-4f99-a214-791b3e5568ed",
        "id": "8WEOp3WA4bbx",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        }
      },
      "cell_type": "code",
      "source": [
        "X_train = pyreadr.read_r(\"X_train_PM10_201401_201612_multivar.rds\")\n",
        "y_train = pyreadr.read_r(\"y_train_PM10_201401_201612_multivar.rds\")\n",
        "\n",
        "X_test = pyreadr.read_r(\"X_test_PM10_201701_201709_multivar.rds\")\n",
        "y_test = pyreadr.read_r(\"y_test_PM10_201701_201709_multivar.rds\")\n",
        "\n",
        "X_train = X_train[None]\n",
        "y_train = y_train[None]\n",
        "X_test = X_test[None]\n",
        "y_test = y_test[None]\n",
        "\n",
        "# We convert the 'hour' variable to string\n",
        "X_train.hour = X_train.hour.astype(str)\n",
        "X_test.hour = X_test.hour.astype(str)\n",
        "\n",
        "X_train = X_train[['PM10_1', 'PM10_2', 'PM10_3', 'PM10_4', 'PM10_22', 'PM10_23', 'PM10_24',\n",
        "                   'PM10_48', 'PM10_72', 'PM10_96', 'PM10_120', 'PM10_144', 'PM10_168', 'no_lab_days', 'hour']]\n",
        "X_test = X_test[['PM10_1', 'PM10_2', 'PM10_3', 'PM10_4', 'PM10_22', 'PM10_23', 'PM10_24',\n",
        "                 'PM10_48', 'PM10_72', 'PM10_96', 'PM10_120', 'PM10_144', 'PM10_168', 'no_lab_days', 'hour']]\n",
        "\n",
        "\n",
        "X_train = pd.get_dummies(X_train)\n",
        "X_test  = pd.get_dummies(X_test)\n",
        "\n",
        "\n",
        "\n",
        "regXGB = XGBRegressor(n_estimators=500, min_samples_leaf=10,max_depth=2, random_state=42)\n",
        "regXGB.fit(X_train,y_train)\n",
        "\n",
        "\n",
        "# Compute train scores\n",
        "\n",
        "y_pred = regXGB.predict(X_train)\n",
        "\n",
        "r2_train = r2_score(y_train, y_pred)\n",
        "rmse_train = np.sqrt(mean_squared_error(y_train, y_pred))\n",
        "mae_train = mean_absolute_error(y_train, y_pred)\n",
        "r2_adjusted_train = 1 - (1-r2_score(y_train, y_pred))*(len(y_train)-1)/(len(y_train)-X_train.shape[1]-1)\n",
        "sd_train = std(y_train)\n",
        "\n",
        "print(\"R^2 train: {}\".format(r2_train))\n",
        "print(\"R^2 adjusted train: {}\".format(r2_adjusted_train))\n",
        "print(\"Mean Absolute Error train: {}\".format(mae_train))\n",
        "print(\"Root Mean Squared Error train: {}\".format(rmse_train)) \n",
        "print(\"Standard Deviation train: {}\".format(sd_train))  \n",
        "\n",
        "# Compute test scores\n",
        "\n",
        "y_pred = regXGB.predict(X_test)\n",
        "\n",
        "r2_test = r2_score(y_test, y_pred)\n",
        "rmse_test = np.sqrt(mean_squared_error(y_test, y_pred))\n",
        "mae_test = mean_absolute_error(y_test, y_pred)\n",
        "r2_adjusted_test = 1 - (1-r2_score(y_test, y_pred))*(len(y_test)-1)/(len(y_test)-X_test.shape[1]-1)\n",
        "sd_test = std(y_test)\n",
        "\n",
        "print(\"R^2 test: {}\".format(r2_test))\n",
        "print(\"R^2 adjusted test: {}\".format(r2_adjusted_test))\n",
        "print(\"Mean Absolute Error test: {}\".format(mae_test))\n",
        "print(\"Root Mean Squared Error test: {}\".format(rmse_test))\n",
        "print(\"Standard Deviation test: {}\".format(sd_test))  \n"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "R^2 train: 0.6677327260973054\n",
            "R^2 adjusted train: 0.6672310061158044\n",
            "Mean Absolute Error train: 5.450381722721943\n",
            "Root Mean Squared Error train: 8.538500965207893\n",
            "Standard Deviation train: PM10_0    14.812823\n",
            "dtype: float64\n",
            "R^2 test: 0.6050019940808449\n",
            "R^2 adjusted test: 0.6025733448248387\n",
            "Mean Absolute Error test: 4.7570254454696705\n",
            "Root Mean Squared Error test: 6.7558940958393645\n",
            "Standard Deviation test: PM10_0    10.749429\n",
            "dtype: float64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "U2B56QO-FZjc",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        ""
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "VFhJ94y5FaKO"
      },
      "cell_type": "markdown",
      "source": [
        "## Adding the variable 'month'"
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "x3ZPc5-XFaKP"
      },
      "cell_type": "markdown",
      "source": [
        "The levels of the PM10 have a clear monthly seasonality. So, the inclusion of this variable could be some effect in the results."
      ]
    },
    {
      "metadata": {
        "id": "J-_jYe3CF1QY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        },
        "outputId": "efe58b7f-bfb2-44e0-f5c0-cc1825f607bf"
      },
      "cell_type": "code",
      "source": [
        "X_train = pyreadr.read_r(\"X_train_PM10_201401_201612_multivar.rds\")\n",
        "y_train = pyreadr.read_r(\"y_train_PM10_201401_201612_multivar.rds\")\n",
        "\n",
        "X_test = pyreadr.read_r(\"X_test_PM10_201701_201709_multivar.rds\")\n",
        "y_test = pyreadr.read_r(\"y_test_PM10_201701_201709_multivar.rds\")\n",
        "\n",
        "X_train = X_train[None]\n",
        "y_train = y_train[None]\n",
        "X_test = X_test[None]\n",
        "y_test = y_test[None]\n",
        "\n",
        "# We convert the 'hour' variable to string\n",
        "X_train.hour = X_train.hour.astype(str)\n",
        "X_test.hour = X_test.hour.astype(str)\n",
        "\n",
        "X_train = X_train[['PM10_1', 'PM10_2', 'PM10_3', 'PM10_4', 'PM10_22', 'PM10_23', 'PM10_24',\n",
        "                   'PM10_48', 'PM10_72', 'PM10_96', 'PM10_120', 'PM10_144', 'PM10_168', 'no_lab_days', 'hour', 'month']]\n",
        "X_test = X_test[['PM10_1', 'PM10_2', 'PM10_3', 'PM10_4', 'PM10_22', 'PM10_23', 'PM10_24',\n",
        "                 'PM10_48', 'PM10_72', 'PM10_96', 'PM10_120', 'PM10_144', 'PM10_168', 'no_lab_days', 'hour', 'month']]\n",
        "\n",
        "\n",
        "X_train = pd.get_dummies(X_train)\n",
        "X_test  = pd.get_dummies(X_test)\n",
        "\n",
        "\n",
        "\n",
        "regXGB = XGBRegressor(n_estimators=500, min_samples_leaf=10,max_depth=2, random_state=42)\n",
        "regXGB.fit(X_train,y_train)\n",
        "\n",
        "\n",
        "# Compute train scores\n",
        "\n",
        "y_pred = regXGB.predict(X_train)\n",
        "\n",
        "r2_train = r2_score(y_train, y_pred)\n",
        "rmse_train = np.sqrt(mean_squared_error(y_train, y_pred))\n",
        "mae_train = mean_absolute_error(y_train, y_pred)\n",
        "r2_adjusted_train = 1 - (1-r2_score(y_train, y_pred))*(len(y_train)-1)/(len(y_train)-X_train.shape[1]-1)\n",
        "sd_train = std(y_train)\n",
        "\n",
        "print(\"R^2 train: {}\".format(r2_train))\n",
        "print(\"R^2 adjusted train: {}\".format(r2_adjusted_train))\n",
        "print(\"Mean Absolute Error train: {}\".format(mae_train))\n",
        "print(\"Root Mean Squared Error train: {}\".format(rmse_train)) \n",
        "print(\"Standard Deviation train: {}\".format(sd_train))  \n",
        "\n",
        "# Compute test scores\n",
        "\n",
        "y_pred = regXGB.predict(X_test)\n",
        "\n",
        "r2_test = r2_score(y_test, y_pred)\n",
        "rmse_test = np.sqrt(mean_squared_error(y_test, y_pred))\n",
        "mae_test = mean_absolute_error(y_test, y_pred)\n",
        "r2_adjusted_test = 1 - (1-r2_score(y_test, y_pred))*(len(y_test)-1)/(len(y_test)-X_test.shape[1]-1)\n",
        "sd_test = std(y_test)\n",
        "\n",
        "print(\"R^2 test: {}\".format(r2_test))\n",
        "print(\"R^2 adjusted test: {}\".format(r2_adjusted_test))\n",
        "print(\"Mean Absolute Error test: {}\".format(mae_test))\n",
        "print(\"Root Mean Squared Error test: {}\".format(rmse_test))\n",
        "print(\"Standard Deviation test: {}\".format(sd_test))  \n"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "R^2 train: 0.6681943593836794\n",
            "R^2 adjusted train: 0.667680469825285\n",
            "Mean Absolute Error train: 5.447331970676348\n",
            "Root Mean Squared Error train: 8.532567449328933\n",
            "Standard Deviation train: PM10_0    14.812823\n",
            "dtype: float64\n",
            "R^2 test: 0.6051684283849006\n",
            "R^2 adjusted test: 0.6026781630325506\n",
            "Mean Absolute Error test: 4.752892953718895\n",
            "Root Mean Squared Error test: 6.754470631689703\n",
            "Standard Deviation test: PM10_0    10.749429\n",
            "dtype: float64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "4bYszbn7LM21",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Adding the week_day variable"
      ]
    },
    {
      "metadata": {
        "id": "0F9VfOznLNFb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        },
        "outputId": "3f9ae931-c4ca-45c2-8b17-29b186453756"
      },
      "cell_type": "code",
      "source": [
        "X_train = pyreadr.read_r(\"X_train_PM10_201401_201612_multivar.rds\")\n",
        "y_train = pyreadr.read_r(\"y_train_PM10_201401_201612_multivar.rds\")\n",
        "\n",
        "X_test = pyreadr.read_r(\"X_test_PM10_201701_201709_multivar.rds\")\n",
        "y_test = pyreadr.read_r(\"y_test_PM10_201701_201709_multivar.rds\")\n",
        "\n",
        "X_train = X_train[None]\n",
        "y_train = y_train[None]\n",
        "X_test = X_test[None]\n",
        "y_test = y_test[None]\n",
        "\n",
        "# We convert the 'hour' variable to string\n",
        "X_train.hour = X_train.hour.astype(str)\n",
        "X_test.hour = X_test.hour.astype(str)\n",
        "\n",
        "X_train = X_train[['PM10_1', 'PM10_2', 'PM10_3', 'PM10_4', 'PM10_22', 'PM10_23', 'PM10_24',\n",
        "                   'PM10_48', 'PM10_72', 'PM10_96', 'PM10_120', 'PM10_144', 'PM10_168', 'no_lab_days', 'hour', 'month', 'week_day']]\n",
        "X_test = X_test[['PM10_1', 'PM10_2', 'PM10_3', 'PM10_4', 'PM10_22', 'PM10_23', 'PM10_24',\n",
        "                 'PM10_48', 'PM10_72', 'PM10_96', 'PM10_120', 'PM10_144', 'PM10_168', 'no_lab_days', 'hour', 'month', 'week_day']]\n",
        "\n",
        "\n",
        "X_train = pd.get_dummies(X_train)\n",
        "X_test  = pd.get_dummies(X_test)\n",
        "\n",
        "\n",
        "\n",
        "regXGB = XGBRegressor(n_estimators=500, min_samples_leaf=10,max_depth=2, random_state=42)\n",
        "regXGB.fit(X_train,y_train)\n",
        "\n",
        "\n",
        "# Compute train scores\n",
        "\n",
        "y_pred = regXGB.predict(X_train)\n",
        "\n",
        "r2_train = r2_score(y_train, y_pred)\n",
        "rmse_train = np.sqrt(mean_squared_error(y_train, y_pred))\n",
        "mae_train = mean_absolute_error(y_train, y_pred)\n",
        "r2_adjusted_train = 1 - (1-r2_score(y_train, y_pred))*(len(y_train)-1)/(len(y_train)-X_train.shape[1]-1)\n",
        "sd_train = std(y_train)\n",
        "\n",
        "print(\"R^2 train: {}\".format(r2_train))\n",
        "print(\"R^2 adjusted train: {}\".format(r2_adjusted_train))\n",
        "print(\"Mean Absolute Error train: {}\".format(mae_train))\n",
        "print(\"Root Mean Squared Error train: {}\".format(rmse_train)) \n",
        "print(\"Standard Deviation train: {}\".format(sd_train))  \n",
        "\n",
        "# Compute test scores\n",
        "\n",
        "y_pred = regXGB.predict(X_test)\n",
        "\n",
        "r2_test = r2_score(y_test, y_pred)\n",
        "rmse_test = np.sqrt(mean_squared_error(y_test, y_pred))\n",
        "mae_test = mean_absolute_error(y_test, y_pred)\n",
        "r2_adjusted_test = 1 - (1-r2_score(y_test, y_pred))*(len(y_test)-1)/(len(y_test)-X_test.shape[1]-1)\n",
        "sd_test = std(y_test)\n",
        "\n",
        "print(\"R^2 test: {}\".format(r2_test))\n",
        "print(\"R^2 adjusted test: {}\".format(r2_adjusted_test))\n",
        "print(\"Mean Absolute Error test: {}\".format(mae_test))\n",
        "print(\"Root Mean Squared Error test: {}\".format(rmse_test))\n",
        "print(\"Standard Deviation test: {}\".format(sd_test))  \n"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "R^2 train: 0.6676343973851251\n",
            "R^2 adjusted train: 0.6671067512259363\n",
            "Mean Absolute Error train: 5.44979083115112\n",
            "Root Mean Squared Error train: 8.539764282067889\n",
            "Standard Deviation train: PM10_0    14.812823\n",
            "dtype: float64\n",
            "R^2 test: 0.6052312997470766\n",
            "R^2 adjusted test: 0.6026787817356636\n",
            "Mean Absolute Error test: 4.751691392509307\n",
            "Root Mean Squared Error test: 6.753932833161597\n",
            "Standard Deviation test: PM10_0    10.749429\n",
            "dtype: float64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "9Q9nBHjf_AsA",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##Adding lagged SO2 - NO2 levels as variables\n",
        "The SO2 and the NO2 are precursors of the PM10 pollutant. So, in theory the levels of these pollutants had to have influence on the PM10 levels. We include the one hour lagged levels of these pollutants to check if they increase the explanatory power of the model. "
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "outputId": "20de4c59-6ace-4b18-90ad-ebb6c01921fd",
        "id": "w7e0JIN00yE6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        }
      },
      "cell_type": "code",
      "source": [
        "X_train = pyreadr.read_r(\"X_train_PM10_201401_201612_multivar.rds\")\n",
        "y_train = pyreadr.read_r(\"y_train_PM10_201401_201612_multivar.rds\")\n",
        "\n",
        "X_test = pyreadr.read_r(\"X_test_PM10_201701_201709_multivar.rds\")\n",
        "y_test = pyreadr.read_r(\"y_test_PM10_201701_201709_multivar.rds\")\n",
        "\n",
        "X_train = X_train[None]\n",
        "y_train = y_train[None]\n",
        "X_test = X_test[None]\n",
        "y_test = y_test[None]\n",
        "\n",
        "# We convert the 'hour' variable to string\n",
        "X_train.hour = X_train.hour.astype(str)\n",
        "X_test.hour = X_test.hour.astype(str)\n",
        "\n",
        "X_train = X_train[['PM10_1', 'PM10_2', 'PM10_3', 'PM10_4', 'PM10_22', 'PM10_23', 'PM10_24', \n",
        "                   'PM10_48', 'PM10_72', 'PM10_96', 'PM10_120', 'PM10_144', 'PM10_168',\n",
        "                   'no_lab_days', 'hour', 'month', 'week_day','NO2_1', 'SO2_1']]\n",
        "\n",
        "X_test = X_test[['PM10_1', 'PM10_2', 'PM10_3', 'PM10_4', 'PM10_22', 'PM10_23', 'PM10_24',\n",
        "                 'PM10_48', 'PM10_72', 'PM10_96', 'PM10_120', 'PM10_144', 'PM10_168', \n",
        "                 'no_lab_days', 'hour', 'month', 'week_day','NO2_1', 'SO2_1']]\n",
        "\n",
        "\n",
        "X_train = pd.get_dummies(X_train)\n",
        "X_test  = pd.get_dummies(X_test)\n",
        "\n",
        "\n",
        "\n",
        "regXGB = XGBRegressor(n_estimators=500, min_samples_leaf=10,max_depth=2, random_state=42)\n",
        "regXGB.fit(X_train,y_train)\n",
        "\n",
        "\n",
        "# Compute train scores\n",
        "\n",
        "y_pred = regXGB.predict(X_train)\n",
        "\n",
        "r2_train = r2_score(y_train, y_pred)\n",
        "rmse_train = np.sqrt(mean_squared_error(y_train, y_pred))\n",
        "mae_train = mean_absolute_error(y_train, y_pred)\n",
        "r2_adjusted_train = 1 - (1-r2_score(y_train, y_pred))*(len(y_train)-1)/(len(y_train)-X_train.shape[1]-1)\n",
        "sd_train = std(y_train)\n",
        "\n",
        "print(\"R^2 train: {}\".format(r2_train))\n",
        "print(\"R^2 adjusted train: {}\".format(r2_adjusted_train))\n",
        "print(\"Mean Absolute Error train: {}\".format(mae_train))\n",
        "print(\"Root Mean Squared Error train: {}\".format(rmse_train)) \n",
        "print(\"Standard Deviation train: {}\".format(sd_train))  \n",
        "\n",
        "# Compute test scores\n",
        "\n",
        "y_pred = regXGB.predict(X_test)\n",
        "\n",
        "r2_test = r2_score(y_test, y_pred)\n",
        "rmse_test = np.sqrt(mean_squared_error(y_test, y_pred))\n",
        "mae_test = mean_absolute_error(y_test, y_pred)\n",
        "r2_adjusted_test = 1 - (1-r2_score(y_test, y_pred))*(len(y_test)-1)/(len(y_test)-X_test.shape[1]-1)\n",
        "sd_test = std(y_test)\n",
        "\n",
        "print(\"R^2 test: {}\".format(r2_test))\n",
        "print(\"R^2 adjusted test: {}\".format(r2_adjusted_test))\n",
        "print(\"Mean Absolute Error test: {}\".format(mae_test))\n",
        "print(\"Root Mean Squared Error test: {}\".format(rmse_test))\n",
        "print(\"Standard Deviation test: {}\".format(sd_test))  \n"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "R^2 train: 0.6722011798746166\n",
            "R^2 adjusted train: 0.671655356250647\n",
            "Mean Absolute Error train: 5.411945677774943\n",
            "Root Mean Squared Error train: 8.480892156395758\n",
            "Standard Deviation train: PM10_0    14.812823\n",
            "dtype: float64\n",
            "R^2 test: 0.6015486568153066\n",
            "R^2 adjusted test: 0.5988458002516621\n",
            "Mean Absolute Error test: 4.814010842149647\n",
            "Root Mean Squared Error test: 6.785362105465956\n",
            "Standard Deviation test: PM10_0    10.749429\n",
            "dtype: float64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "epAz5EoIAvYF",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        " The MAE increases. We remove these variables.\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "tfiMJPeBDYfr",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### We add the two hour lagged NO2-SO2 variables"
      ]
    },
    {
      "metadata": {
        "id": "NrjJyy2BpGd1",
        "colab_type": "code",
        "outputId": "80d51472-d881-423a-a9cf-2282a382af6a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        }
      },
      "cell_type": "code",
      "source": [
        "X_train = pyreadr.read_r(\"X_train_PM10_201401_201612_multivar.rds\")\n",
        "y_train = pyreadr.read_r(\"y_train_PM10_201401_201612_multivar.rds\")\n",
        "\n",
        "X_test = pyreadr.read_r(\"X_test_PM10_201701_201709_multivar.rds\")\n",
        "y_test = pyreadr.read_r(\"y_test_PM10_201701_201709_multivar.rds\")\n",
        "\n",
        "X_train = X_train[None]\n",
        "y_train = y_train[None]\n",
        "X_test = X_test[None]\n",
        "y_test = y_test[None]\n",
        "\n",
        "\n",
        "# We convert the 'hour' variable to string\n",
        "X_train.hour = X_train.hour.astype(str)\n",
        "X_test.hour = X_test.hour.astype(str)\n",
        "\n",
        "X_train = X_train[['PM10_1', 'PM10_2', 'PM10_3', 'PM10_4', 'PM10_22', 'PM10_23', 'PM10_24', \n",
        "                   'PM10_48', 'PM10_72', 'PM10_96', 'PM10_120', 'PM10_144', 'PM10_168',\n",
        "                   'no_lab_days', 'hour', 'month', 'week_day','NO2_2', 'SO2_2']]\n",
        "\n",
        "X_test = X_test[['PM10_1', 'PM10_2', 'PM10_3', 'PM10_4', 'PM10_22', 'PM10_23', 'PM10_24',\n",
        "                 'PM10_48', 'PM10_72', 'PM10_96', 'PM10_120', 'PM10_144', 'PM10_168',\n",
        "                 'no_lab_days', 'hour', 'month', 'week_day', 'NO2_2', 'SO2_2']]\n",
        "\n",
        "\n",
        "X_train = pd.get_dummies(X_train)\n",
        "X_test  = pd.get_dummies(X_test)\n",
        "\n",
        "\n",
        "\n",
        "regXGB = XGBRegressor(n_estimators=500, min_samples_leaf=10,max_depth=2, random_state=42)\n",
        "regXGB.fit(X_train,y_train)\n",
        "\n",
        "\n",
        "# Compute train scores\n",
        "\n",
        "y_pred = regXGB.predict(X_train)\n",
        "\n",
        "r2_train = r2_score(y_train, y_pred)\n",
        "rmse_train = np.sqrt(mean_squared_error(y_train, y_pred))\n",
        "mae_train = mean_absolute_error(y_train, y_pred)\n",
        "r2_adjusted_train = 1 - (1-r2_score(y_train, y_pred))*(len(y_train)-1)/(len(y_train)-X_train.shape[1]-1)\n",
        "sd_train = std(y_train)\n",
        "\n",
        "print(\"R^2 train: {}\".format(r2_train))\n",
        "print(\"R^2 adjusted train: {}\".format(r2_adjusted_train))\n",
        "print(\"Mean Absolute Error train: {}\".format(mae_train))\n",
        "print(\"Root Mean Squared Error train: {}\".format(rmse_train)) \n",
        "print(\"Standard Deviation train: {}\".format(sd_train))  \n",
        "\n",
        "# Compute test scores\n",
        "\n",
        "y_pred = regXGB.predict(X_test)\n",
        "\n",
        "r2_test = r2_score(y_test, y_pred)\n",
        "rmse_test = np.sqrt(mean_squared_error(y_test, y_pred))\n",
        "mae_test = mean_absolute_error(y_test, y_pred)\n",
        "r2_adjusted_test = 1 - (1-r2_score(y_test, y_pred))*(len(y_test)-1)/(len(y_test)-X_test.shape[1]-1)\n",
        "sd_test = std(y_test)\n",
        "\n",
        "print(\"R^2 test: {}\".format(r2_test))\n",
        "print(\"R^2 adjusted test: {}\".format(r2_adjusted_test))\n",
        "print(\"Mean Absolute Error test: {}\".format(mae_test))\n",
        "print(\"Root Mean Squared Error test: {}\".format(rmse_test))\n",
        "print(\"Standard Deviation test: {}\".format(sd_test))  \n"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "R^2 train: 0.6699616863321667\n",
            "R^2 adjusted train: 0.6694121336878158\n",
            "Mean Absolute Error train: 5.4299401094573865\n",
            "Root Mean Squared Error train: 8.509813209374219\n",
            "Standard Deviation train: PM10_0    14.812823\n",
            "dtype: float64\n",
            "R^2 test: 0.6051238277725847\n",
            "R^2 adjusted test: 0.6024452230390653\n",
            "Mean Absolute Error test: 4.764689330408576\n",
            "Root Mean Squared Error test: 6.7548521171643925\n",
            "Standard Deviation test: PM10_0    10.749429\n",
            "dtype: float64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "j-TKQ3ua9dCx",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The  MAE increases again. We remove these variables from the model."
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "awzYULqeF0uW"
      },
      "cell_type": "markdown",
      "source": [
        "# Weather variables"
      ]
    },
    {
      "metadata": {
        "id": "j3gA-WwGpGg3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "Wd_iDNPi_Eze"
      },
      "cell_type": "markdown",
      "source": [
        "##Adding lagged vv - wd (wind speed and wind direction)"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "outputId": "0d442a91-a5e3-4851-c0e6-2c88df1d9aec",
        "id": "ew6VpSJL_Ezg",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        }
      },
      "cell_type": "code",
      "source": [
        "X_train = pyreadr.read_r(\"X_train_PM10_201401_201612_multivar.rds\")\n",
        "y_train = pyreadr.read_r(\"y_train_PM10_201401_201612_multivar.rds\")\n",
        "\n",
        "X_test = pyreadr.read_r(\"X_test_PM10_201701_201709_multivar.rds\")\n",
        "y_test = pyreadr.read_r(\"y_test_PM10_201701_201709_multivar.rds\")\n",
        "\n",
        "X_train = X_train[None]\n",
        "y_train = y_train[None]\n",
        "X_test = X_test[None]\n",
        "y_test = y_test[None]\n",
        "\n",
        "# We convert the 'hour' variable to string\n",
        "X_train.hour = X_train.hour.astype(str)\n",
        "X_test.hour = X_test.hour.astype(str)\n",
        "\n",
        "X_train = X_train[['PM10_1', 'PM10_2', 'PM10_3', 'PM10_4', 'PM10_22', 'PM10_23', 'PM10_24', 'PM10_48', 'PM10_72', 'PM10_96', 'PM10_120',\n",
        "                   'PM10_144', 'PM10_168', 'no_lab_days', 'hour','month', 'week_day', 'vv_1','wd_1']]\n",
        "X_test = X_test[['PM10_1', 'PM10_2', 'PM10_3', 'PM10_4', 'PM10_22', 'PM10_23', 'PM10_24', 'PM10_48', 'PM10_72', 'PM10_96', 'PM10_120', \n",
        "                 'PM10_144', 'PM10_168', 'no_lab_days', 'hour','month', 'week_day', 'vv_1','wd_1']]\n",
        "\n",
        "X_train = pd.get_dummies(X_train)\n",
        "X_test  = pd.get_dummies(X_test)\n",
        "\n",
        "\n",
        "regXGB = XGBRegressor(n_estimators=500, min_samples_leaf=10,max_depth=2, random_state=42)\n",
        "regXGB.fit(X_train,y_train)\n",
        "\n",
        "\n",
        "# Compute train scores\n",
        "\n",
        "y_pred = regXGB.predict(X_train)\n",
        "\n",
        "r2_train = r2_score(y_train, y_pred)\n",
        "rmse_train = np.sqrt(mean_squared_error(y_train, y_pred))\n",
        "mae_train = mean_absolute_error(y_train, y_pred)\n",
        "r2_adjusted_train = 1 - (1-r2_score(y_train, y_pred))*(len(y_train)-1)/(len(y_train)-X_train.shape[1]-1)\n",
        "sd_train = std(y_train)\n",
        "\n",
        "print(\"R^2 train: {}\".format(r2_train))\n",
        "print(\"R^2 adjusted train: {}\".format(r2_adjusted_train))\n",
        "print(\"Mean Absolute Error train: {}\".format(mae_train))\n",
        "print(\"Root Mean Squared Error train: {}\".format(rmse_train)) \n",
        "print(\"Standard Deviation train: {}\".format(sd_train))  \n",
        "\n",
        "# Compute test scores\n",
        "\n",
        "y_pred = regXGB.predict(X_test)\n",
        "\n",
        "r2_test = r2_score(y_test, y_pred)\n",
        "rmse_test = np.sqrt(mean_squared_error(y_test, y_pred))\n",
        "mae_test = mean_absolute_error(y_test, y_pred)\n",
        "r2_adjusted_test = 1 - (1-r2_score(y_test, y_pred))*(len(y_test)-1)/(len(y_test)-X_test.shape[1]-1)\n",
        "sd_test = std(y_test)\n",
        "\n",
        "print(\"R^2 test: {}\".format(r2_test))\n",
        "print(\"R^2 adjusted test: {}\".format(r2_adjusted_test))\n",
        "print(\"Mean Absolute Error test: {}\".format(mae_test))\n",
        "print(\"Root Mean Squared Error test: {}\".format(rmse_test))\n",
        "print(\"Standard Deviation test: {}\".format(sd_test))  \n"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "R^2 train: 0.6735418428037112\n",
            "R^2 adjusted train: 0.6728082005425858\n",
            "Mean Absolute Error train: 5.398101778568063\n",
            "Root Mean Squared Error train: 8.463531405835221\n",
            "Standard Deviation train: PM10_0    14.812823\n",
            "dtype: float64\n",
            "R^2 test: 0.6129310378324916\n",
            "R^2 adjusted test: 0.6093810694887668\n",
            "Mean Absolute Error test: 4.745920449606892\n",
            "Root Mean Squared Error test: 6.687742691925128\n",
            "Standard Deviation test: PM10_0    10.749429\n",
            "dtype: float64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "JHq7jxpDDDi-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Adding rainfall (LL)"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "outputId": "f9985b51-e108-42ae-8f02-3a7c20b389c3",
        "id": "1QIjCXCQEtqg",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        }
      },
      "cell_type": "code",
      "source": [
        "X_train = pyreadr.read_r(\"X_train_PM10_201401_201612_multivar.rds\")\n",
        "y_train = pyreadr.read_r(\"y_train_PM10_201401_201612_multivar.rds\")\n",
        "\n",
        "X_test = pyreadr.read_r(\"X_test_PM10_201701_201709_multivar.rds\")\n",
        "y_test = pyreadr.read_r(\"y_test_PM10_201701_201709_multivar.rds\")\n",
        "\n",
        "X_train = X_train[None]\n",
        "y_train = y_train[None]\n",
        "X_test = X_test[None]\n",
        "y_test = y_test[None]\n",
        "\n",
        "# We convert the 'hour' variable to string\n",
        "X_train.hour = X_train.hour.astype(str)\n",
        "X_test.hour = X_test.hour.astype(str)\n",
        "\n",
        "X_train = X_train[['PM10_1', 'PM10_2', 'PM10_3', 'PM10_4', 'PM10_22', 'PM10_23', 'PM10_24',\n",
        "                   'PM10_48', 'PM10_72', 'PM10_96', 'PM10_120', 'PM10_144', 'PM10_168', \n",
        "                   'no_lab_days', 'hour', 'month', 'week_day', 'vv_1', 'wd_1', 'LL_1', 'LL_2']]\n",
        "\n",
        "X_test = X_test[['PM10_1', 'PM10_2', 'PM10_3', 'PM10_4', 'PM10_22', 'PM10_23', 'PM10_24', \n",
        "                 'PM10_48', 'PM10_72', 'PM10_96', 'PM10_120', 'PM10_144', 'PM10_168',\n",
        "                 'no_lab_days', 'hour', 'month', 'week_day', 'vv_1', 'wd_1', 'LL_1', 'LL_2']]\n",
        "\n",
        "X_train = pd.get_dummies(X_train)\n",
        "X_test  = pd.get_dummies(X_test)\n",
        "\n",
        "\n",
        "\n",
        "regXGB = XGBRegressor(n_estimators=500, min_samples_leaf=10,max_depth=2, random_state=42)\n",
        "regXGB.fit(X_train,y_train)\n",
        "\n",
        "\n",
        "# Compute train scores\n",
        "\n",
        "y_pred = regXGB.predict(X_train)\n",
        "\n",
        "r2_train = r2_score(y_train, y_pred)\n",
        "rmse_train = np.sqrt(mean_squared_error(y_train, y_pred))\n",
        "mae_train = mean_absolute_error(y_train, y_pred)\n",
        "r2_adjusted_train = 1 - (1-r2_score(y_train, y_pred))*(len(y_train)-1)/(len(y_train)-X_train.shape[1]-1)\n",
        "sd_train = std(y_train)\n",
        "\n",
        "print(\"R^2 train: {}\".format(r2_train))\n",
        "print(\"R^2 adjusted train: {}\".format(r2_adjusted_train))\n",
        "print(\"Mean Absolute Error train: {}\".format(mae_train))\n",
        "print(\"Root Mean Squared Error train: {}\".format(rmse_train)) \n",
        "print(\"Standard Deviation train: {}\".format(sd_train))  \n",
        "\n",
        "# Compute test scores\n",
        "\n",
        "y_pred = regXGB.predict(X_test)\n",
        "\n",
        "r2_test = r2_score(y_test, y_pred)\n",
        "rmse_test = np.sqrt(mean_squared_error(y_test, y_pred))\n",
        "mae_test = mean_absolute_error(y_test, y_pred)\n",
        "r2_adjusted_test = 1 - (1-r2_score(y_test, y_pred))*(len(y_test)-1)/(len(y_test)-X_test.shape[1]-1)\n",
        "sd_test = std(y_test)\n",
        "\n",
        "print(\"R^2 test: {}\".format(r2_test))\n",
        "print(\"R^2 adjusted test: {}\".format(r2_adjusted_test))\n",
        "print(\"Mean Absolute Error test: {}\".format(mae_test))\n",
        "print(\"Root Mean Squared Error test: {}\".format(rmse_test))\n",
        "print(\"Standard Deviation test: {}\".format(sd_test))  \n"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "R^2 train: 0.6750761873495172\n",
            "R^2 adjusted train: 0.6743207555380308\n",
            "Mean Absolute Error train: 5.385328554318593\n",
            "Root Mean Squared Error train: 8.443618796273906\n",
            "Standard Deviation train: PM10_0    14.812823\n",
            "dtype: float64\n",
            "R^2 test: 0.6137750539111198\n",
            "R^2 adjusted test: 0.6101095213636138\n",
            "Mean Absolute Error test: 4.741300497122194\n",
            "Root Mean Squared Error test: 6.68044729587217\n",
            "Standard Deviation test: PM10_0    10.749429\n",
            "dtype: float64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "sDqg91eTFMRe",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Adding the LL variable (rainfall) barely improves the model. "
      ]
    },
    {
      "metadata": {
        "id": "o5pIXCLAVOQ0",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Adding solar radiation (RS)"
      ]
    },
    {
      "metadata": {
        "id": "60Ms-MopV8E1",
        "colab_type": "code",
        "outputId": "0240a467-bd30-497d-f339-4f791805b636",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        }
      },
      "cell_type": "code",
      "source": [
        "X_train = pyreadr.read_r(\"X_train_PM10_201401_201612_multivar.rds\")\n",
        "y_train = pyreadr.read_r(\"y_train_PM10_201401_201612_multivar.rds\")\n",
        "\n",
        "X_test = pyreadr.read_r(\"X_test_PM10_201701_201709_multivar.rds\")\n",
        "y_test = pyreadr.read_r(\"y_test_PM10_201701_201709_multivar.rds\")\n",
        "\n",
        "X_train = X_train[None]\n",
        "y_train = y_train[None]\n",
        "X_test = X_test[None]\n",
        "y_test = y_test[None]\n",
        "\n",
        "# We convert the 'hour' variable to string\n",
        "X_train.hour = X_train.hour.astype(str)\n",
        "X_test.hour = X_test.hour.astype(str)\n",
        "\n",
        "X_train = X_train[['PM10_1', 'PM10_2', 'PM10_3', 'PM10_4', 'PM10_22', 'PM10_23', 'PM10_24',\n",
        "                   'PM10_48', 'PM10_72', 'PM10_96', 'PM10_120','PM10_144', 'PM10_168',\n",
        "                   'month', 'week_day', 'no_lab_days', 'hour',\n",
        "                   'vv_1', 'wd_1', 'LL_1', 'LL_2', 'RS_1', 'RS_2']]\n",
        "\n",
        "X_test = X_test[['PM10_1', 'PM10_2', 'PM10_3', 'PM10_4', 'PM10_22', 'PM10_23', 'PM10_24',\n",
        "                   'PM10_48', 'PM10_72', 'PM10_96', 'PM10_120','PM10_144', 'PM10_168',\n",
        "                   'month', 'week_day', 'no_lab_days', 'hour',\n",
        "                   'vv_1', 'wd_1', 'LL_1', 'LL_2', 'RS_1', 'RS_2']]\n",
        "\n",
        "X_train = pd.get_dummies(X_train)\n",
        "X_test  = pd.get_dummies(X_test)\n",
        "\n",
        "\n",
        "\n",
        "regXGB = XGBRegressor(n_estimators=500, min_samples_leaf=10,max_depth=2, random_state=42)\n",
        "regXGB.fit(X_train,y_train)\n",
        "\n",
        "\n",
        "# Compute train scores\n",
        "\n",
        "y_pred = regXGB.predict(X_train)\n",
        "\n",
        "r2_train = r2_score(y_train, y_pred)\n",
        "rmse_train = np.sqrt(mean_squared_error(y_train, y_pred))\n",
        "mae_train = mean_absolute_error(y_train, y_pred)\n",
        "r2_adjusted_train = 1 - (1-r2_score(y_train, y_pred))*(len(y_train)-1)/(len(y_train)-X_train.shape[1]-1)\n",
        "sd_train = std(y_train)\n",
        "\n",
        "print(\"R^2 train: {}\".format(r2_train))\n",
        "print(\"R^2 adjusted train: {}\".format(r2_adjusted_train))\n",
        "print(\"Mean Absolute Error train: {}\".format(mae_train))\n",
        "print(\"Root Mean Squared Error train: {}\".format(rmse_train)) \n",
        "print(\"Standard Deviation train: {}\".format(sd_train))  \n",
        "\n",
        "# Compute test scores\n",
        "\n",
        "y_pred = regXGB.predict(X_test)\n",
        "\n",
        "r2_test = r2_score(y_test, y_pred)\n",
        "rmse_test = np.sqrt(mean_squared_error(y_test, y_pred))\n",
        "mae_test = mean_absolute_error(y_test, y_pred)\n",
        "r2_adjusted_test = 1 - (1-r2_score(y_test, y_pred))*(len(y_test)-1)/(len(y_test)-X_test.shape[1]-1)\n",
        "sd_test = std(y_test)\n",
        "\n",
        "print(\"R^2 test: {}\".format(r2_test))\n",
        "print(\"R^2 adjusted test: {}\".format(r2_adjusted_test))\n",
        "print(\"Mean Absolute Error test: {}\".format(mae_test))\n",
        "print(\"Root Mean Squared Error test: {}\".format(rmse_test))\n",
        "print(\"Standard Deviation test: {}\".format(sd_test))  \n"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "R^2 train: 0.6746801275947865\n",
            "R^2 adjusted train: 0.6738985026349289\n",
            "Mean Absolute Error train: 5.383231667215004\n",
            "Root Mean Squared Error train: 8.448763324005329\n",
            "Standard Deviation train: PM10_0    14.812823\n",
            "dtype: float64\n",
            "R^2 test: 0.6149008632001653\n",
            "R^2 adjusted test: 0.6111229919214328\n",
            "Mean Absolute Error test: 4.723713980252608\n",
            "Root Mean Squared Error test: 6.670703753430319\n",
            "Standard Deviation test: PM10_0    10.749429\n",
            "dtype: float64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "2Pmbay_wKCi3",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##Adding two hours lagged NO2 and SO2 again\n",
        "We recover these variables in order to see if \n",
        "first one lag"
      ]
    },
    {
      "metadata": {
        "id": "HjBpc8wAJGF8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        },
        "outputId": "7522a5e9-cdc5-4723-ad87-71db360c65e0"
      },
      "cell_type": "code",
      "source": [
        "X_train = pyreadr.read_r(\"X_train_PM10_201401_201612_multivar.rds\")\n",
        "y_train = pyreadr.read_r(\"y_train_PM10_201401_201612_multivar.rds\")\n",
        "\n",
        "X_test = pyreadr.read_r(\"X_test_PM10_201701_201709_multivar.rds\")\n",
        "y_test = pyreadr.read_r(\"y_test_PM10_201701_201709_multivar.rds\")\n",
        "\n",
        "X_train = X_train[None]\n",
        "y_train = y_train[None]\n",
        "X_test = X_test[None]\n",
        "y_test = y_test[None]\n",
        "\n",
        "# We convert the 'hour' variable to string\n",
        "X_train.hour = X_train.hour.astype(str)\n",
        "X_test.hour = X_test.hour.astype(str)\n",
        "\n",
        "X_train = X_train[['PM10_1', 'PM10_2', 'PM10_3', 'PM10_4', 'PM10_22', 'PM10_23', 'PM10_24',\n",
        "                   'PM10_48', 'PM10_72', 'PM10_96', 'PM10_120', 'PM10_144', 'PM10_168', \n",
        "                   'no_lab_days', 'hour', 'month', 'week_day',\n",
        "                   'vv_1', 'wd_1', 'LL_1', 'LL_2', 'RS_1', 'RS_2','NO2_1', 'SO2_1']]\n",
        "\n",
        "X_test = X_test[['PM10_1', 'PM10_2', 'PM10_3', 'PM10_4', 'PM10_22', 'PM10_23', 'PM10_24',\n",
        "                   'PM10_48', 'PM10_72', 'PM10_96', 'PM10_120', 'PM10_144', 'PM10_168', \n",
        "                   'no_lab_days', 'hour', 'month', 'week_day',\n",
        "                   'vv_1', 'wd_1', 'LL_1', 'LL_2', 'RS_1', 'RS_2','NO2_1', 'SO2_1']]\n",
        "\n",
        "X_train = pd.get_dummies(X_train)\n",
        "X_test  = pd.get_dummies(X_test)\n",
        "\n",
        "\n",
        "regXGB = XGBRegressor(n_estimators=500, min_samples_leaf=10,max_depth=2, random_state=42)\n",
        "regXGB.fit(X_train,y_train)\n",
        "\n",
        "\n",
        "# Compute train scores\n",
        "\n",
        "y_pred = regXGB.predict(X_train)\n",
        "\n",
        "r2_train = r2_score(y_train, y_pred)\n",
        "rmse_train = np.sqrt(mean_squared_error(y_train, y_pred))\n",
        "mae_train = mean_absolute_error(y_train, y_pred)\n",
        "r2_adjusted_train = 1 - (1-r2_score(y_train, y_pred))*(len(y_train)-1)/(len(y_train)-X_train.shape[1]-1)\n",
        "sd_train = std(y_train)\n",
        "\n",
        "print(\"R^2 train: {}\".format(r2_train))\n",
        "print(\"R^2 adjusted train: {}\".format(r2_adjusted_train))\n",
        "print(\"Mean Absolute Error train: {}\".format(mae_train))\n",
        "print(\"Root Mean Squared Error train: {}\".format(rmse_train)) \n",
        "print(\"Standard Deviation train: {}\".format(sd_train))  \n",
        "\n",
        "# Compute test scores\n",
        "\n",
        "y_pred = regXGB.predict(X_test)\n",
        "\n",
        "r2_test = r2_score(y_test, y_pred)\n",
        "rmse_test = np.sqrt(mean_squared_error(y_test, y_pred))\n",
        "mae_test = mean_absolute_error(y_test, y_pred)\n",
        "r2_adjusted_test = 1 - (1-r2_score(y_test, y_pred))*(len(y_test)-1)/(len(y_test)-X_test.shape[1]-1)\n",
        "sd_test = std(y_test)\n",
        "\n",
        "print(\"R^2 test: {}\".format(r2_test))\n",
        "print(\"R^2 adjusted test: {}\".format(r2_adjusted_test))\n",
        "print(\"Mean Absolute Error test: {}\".format(mae_test))\n",
        "print(\"Root Mean Squared Error test: {}\".format(rmse_test))\n",
        "print(\"Standard Deviation test: {}\".format(sd_test))  \n"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "R^2 train: 0.6780333930577379\n",
            "R^2 adjusted train: 0.6772348090619117\n",
            "Mean Absolute Error train: 5.36435468197966\n",
            "Root Mean Squared Error train: 8.405107320564705\n",
            "Standard Deviation train: PM10_0    14.812823\n",
            "dtype: float64\n",
            "R^2 test: 0.6108817120272232\n",
            "R^2 adjusted test: 0.6069400262991039\n",
            "Mean Absolute Error test: 4.759544507377988\n",
            "Root Mean Squared Error test: 6.705423353788262\n",
            "Standard Deviation test: PM10_0    10.749429\n",
            "dtype: float64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "JEMQQf0aQW7m",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        ""
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "-i58xObsQ5kk"
      },
      "cell_type": "markdown",
      "source": [
        "##Adding two hours lagged NO2 and SO2 again\n",
        "We recover these variables in order to see if \n",
        "two hours lagged"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "outputId": "753a1f36-5d2a-4b8f-d4d2-fd8c1271aa5d",
        "id": "7T5wSNvFQ5kl",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        }
      },
      "cell_type": "code",
      "source": [
        "X_train = pyreadr.read_r(\"X_train_PM10_201401_201612_multivar.rds\")\n",
        "y_train = pyreadr.read_r(\"y_train_PM10_201401_201612_multivar.rds\")\n",
        "\n",
        "X_test = pyreadr.read_r(\"X_test_PM10_201701_201709_multivar.rds\")\n",
        "y_test = pyreadr.read_r(\"y_test_PM10_201701_201709_multivar.rds\")\n",
        "\n",
        "X_train = X_train[None]\n",
        "y_train = y_train[None]\n",
        "X_test = X_test[None]\n",
        "y_test = y_test[None]\n",
        "\n",
        "# We convert the 'hour' variable to string\n",
        "X_train.hour = X_train.hour.astype(str)\n",
        "X_test.hour = X_test.hour.astype(str)\n",
        "\n",
        "X_train = X_train[['PM10_1', 'PM10_2', 'PM10_3', 'PM10_4', 'PM10_22', 'PM10_23', 'PM10_24',\n",
        "                   'PM10_48', 'PM10_72', 'PM10_96', 'PM10_120', 'month', 'week_day',\n",
        "                    'no_lab_days', 'hour','PM10_144', 'PM10_168',\n",
        "                   'vv_1', 'wd_1', 'LL_1', 'LL_2', 'RS_1', 'RS_2','NO2_2', 'SO2_2']]\n",
        "\n",
        "X_test = X_test[['PM10_1', 'PM10_2', 'PM10_3', 'PM10_4', 'PM10_22', 'PM10_23', 'PM10_24',\n",
        "                   'PM10_48', 'PM10_72', 'PM10_96', 'PM10_120', 'month', 'week_day',\n",
        "                    'no_lab_days', 'hour','PM10_144', 'PM10_168',\n",
        "                   'vv_1', 'wd_1', 'LL_1', 'LL_2', 'RS_1', 'RS_2','NO2_2', 'SO2_2']]\n",
        "\n",
        "X_train = pd.get_dummies(X_train)\n",
        "X_test  = pd.get_dummies(X_test)\n",
        "\n",
        "\n",
        "regXGB = XGBRegressor(n_estimators=500, min_samples_leaf=10,max_depth=2, random_state=42)\n",
        "regXGB.fit(X_train,y_train)\n",
        "\n",
        "\n",
        "# Compute train scores\n",
        "\n",
        "y_pred = regXGB.predict(X_train)\n",
        "\n",
        "r2_train = r2_score(y_train, y_pred)\n",
        "rmse_train = np.sqrt(mean_squared_error(y_train, y_pred))\n",
        "mae_train = mean_absolute_error(y_train, y_pred)\n",
        "r2_adjusted_train = 1 - (1-r2_score(y_train, y_pred))*(len(y_train)-1)/(len(y_train)-X_train.shape[1]-1)\n",
        "sd_train = std(y_train)\n",
        "\n",
        "print(\"R^2 train: {}\".format(r2_train))\n",
        "print(\"R^2 adjusted train: {}\".format(r2_adjusted_train))\n",
        "print(\"Mean Absolute Error train: {}\".format(mae_train))\n",
        "print(\"Root Mean Squared Error train: {}\".format(rmse_train)) \n",
        "print(\"Standard Deviation train: {}\".format(sd_train))  \n",
        "\n",
        "# Compute test scores\n",
        "\n",
        "y_pred = regXGB.predict(X_test)\n",
        "\n",
        "r2_test = r2_score(y_test, y_pred)\n",
        "rmse_test = np.sqrt(mean_squared_error(y_test, y_pred))\n",
        "mae_test = mean_absolute_error(y_test, y_pred)\n",
        "r2_adjusted_test = 1 - (1-r2_score(y_test, y_pred))*(len(y_test)-1)/(len(y_test)-X_test.shape[1]-1)\n",
        "sd_test = std(y_test)\n",
        "\n",
        "print(\"R^2 test: {}\".format(r2_test))\n",
        "print(\"R^2 adjusted test: {}\".format(r2_adjusted_test))\n",
        "print(\"Mean Absolute Error test: {}\".format(mae_test))\n",
        "print(\"Root Mean Squared Error test: {}\".format(rmse_test))\n",
        "print(\"Standard Deviation test: {}\".format(sd_test))  \n"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "R^2 train: 0.6771478564985056\n",
            "R^2 adjusted train: 0.6763470760782406\n",
            "Mean Absolute Error train: 5.358657957088558\n",
            "Root Mean Squared Error train: 8.416658082130033\n",
            "Standard Deviation train: PM10_0    14.812823\n",
            "dtype: float64\n",
            "R^2 test: 0.6174061016366456\n",
            "R^2 adjusted test: 0.613530506591496\n",
            "Mean Absolute Error test: 4.706147752618614\n",
            "Root Mean Squared Error test: 6.64897042576772\n",
            "Standard Deviation test: PM10_0    10.749429\n",
            "dtype: float64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "M_HF_9CbT6ME"
      },
      "cell_type": "markdown",
      "source": [
        "### All the variables\n",
        "### Gridsearchcv  \n",
        " \"n_estimators\":[100, 500, 1000, 2000],  \n",
        "                                \"min_samples_leaf\":[10,30],  \n",
        "                                  \"max_depth\":range(2,5)},  \n",
        "                                    scoring=\"neg_mean_absolute_error\")  \n"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "outputId": "3f688acd-e53b-47b6-ec91-5a2bd7918411",
        "id": "P5IoXophT6MG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        }
      },
      "cell_type": "code",
      "source": [
        "X_train = pyreadr.read_r(\"X_train_PM10_201401_201612_multivar.rds\")\n",
        "y_train = pyreadr.read_r(\"y_train_PM10_201401_201612_multivar.rds\")\n",
        "\n",
        "X_test = pyreadr.read_r(\"X_test_PM10_201701_201709_multivar.rds\")\n",
        "y_test = pyreadr.read_r(\"y_test_PM10_201701_201709_multivar.rds\")\n",
        "\n",
        "X_train = X_train[None]\n",
        "y_train = y_train[None]\n",
        "X_test = X_test[None]\n",
        "y_test = y_test[None]\n",
        "\n",
        "# We convert the 'hour' variable to string\n",
        "X_train.hour = X_train.hour.astype(str)\n",
        "X_test.hour = X_test.hour.astype(str)\n",
        "\n",
        "# We convert the 'week_day' variable to string\n",
        "X_train.week_day = X_train.week_day.astype(str)\n",
        "X_test.week_day = X_test.week_day.astype(str)\n",
        "\n",
        "# We convert the 'month' variable to string\n",
        "X_train.month = X_train.month.astype(str)\n",
        "X_test.month = X_test.month.astype(str)\n",
        "\n",
        "X_train = X_train[['PM10_1', 'PM10_2', 'PM10_3', 'PM10_4', 'PM10_22', 'PM10_23', 'PM10_24', \n",
        "                   'PM10_48', 'PM10_72', 'PM10_96', 'PM10_120', 'PM10_144', 'PM10_168', \n",
        "                   'no_lab_days', 'hour', 'NO2_1', 'SO2_1', 'NO2_2', 'SO2_2', 'vv_1', \n",
        "                   'wd_1', 'LL_1', 'LL_2', 'week_day', 'month']]\n",
        "X_test = X_test[['PM10_1', 'PM10_2', 'PM10_3', 'PM10_4', 'PM10_22', 'PM10_23', 'PM10_24',\n",
        "                 'PM10_48', 'PM10_72', 'PM10_96', 'PM10_120', 'PM10_144', 'PM10_168',\n",
        "                 'no_lab_days', 'hour', 'NO2_1', 'SO2_1', 'NO2_2', 'SO2_2', 'vv_1', \n",
        "                 'wd_1', 'LL_1', 'LL_2', 'week_day', 'month']]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "X_train = pd.get_dummies(X_train)\n",
        "X_test  = pd.get_dummies(X_test)\n",
        "\n",
        "\n",
        "# Al hacer el one hot encoding el X_train y el X_test tienen distintas dimensiones. X_train tiene 47 variables y X_test 44. Por que? Porque el dataset de test tiene solo 9 meses, de enero a septiembre, y entonces la variable month solo se convierte en 9 variables, mientras que el dataset tendriamos 12, los 12 meses del anho. \n",
        "# Con el siguiente codigo solucionamos el problema (falta referencia)\n",
        "\n",
        "# Get missing columns in the training test\n",
        "missing_cols = set( X_train.columns ) - set( X_test.columns )\n",
        "# Add a missing column in test set with default value equal to 0\n",
        "for c in missing_cols:\n",
        "    X_test[c] = 0\n",
        "# Ensure the order of column in the test set is in the same order than in train set\n",
        "X_test = X_test[X_train.columns]\n",
        "# This code also ensure that column resulting from category in the test dataset but not present in the training dataset will be removed\n",
        "\n",
        "\n",
        "\n",
        "regXGB = GridSearchCV(XGBRegressor(n_estimators=350, min_samples_leaf=1,max_depth=4, random_state=42),\n",
        "                   param_grid={\"n_estimators\":[100, 500, 1000, 2000],\n",
        "                                \"min_samples_leaf\":[10,30],\n",
        "                                  \"max_depth\":range(2,5)},\n",
        "                                    scoring=\"neg_mean_absolute_error\")\n",
        "\n",
        "regXGB.fit(X_train,y_train)\n",
        "\n",
        "print(regXGB.best_params_)\n",
        "print(\"Best score: {}\".format(regXGB.best_score_))\n",
        "\n",
        "\n",
        "# Compute train scores\n",
        "\n",
        "y_pred = regXGB.predict(X_train)\n",
        "\n",
        "r2_train = r2_score(y_train, y_pred)\n",
        "rmse_train = np.sqrt(mean_squared_error(y_train, y_pred))\n",
        "mae_train = mean_absolute_error(y_train, y_pred)\n",
        "r2_adjusted_train = 1 - (1-r2_score(y_train, y_pred))*(len(y_train)-1)/(len(y_train)-X_train.shape[1]-1)\n",
        "sd_train = std(y_train)\n",
        "\n",
        "print(\"R^2 train: {}\".format(r2_train))\n",
        "print(\"R^2 adjusted train: {}\".format(r2_adjusted_train))\n",
        "print(\"Mean Absolute Error train: {}\".format(mae_train))\n",
        "print(\"Root Mean Squared Error train: {}\".format(rmse_train)) \n",
        "print(\"Standard Deviation train: {}\".format(sd_train))  \n",
        "\n",
        "# Compute test scores\n",
        "\n",
        "y_pred = regXGB.predict(X_test)\n",
        "\n",
        "r2_test = r2_score(y_test, y_pred)\n",
        "rmse_test = np.sqrt(mean_squared_error(y_test, y_pred))\n",
        "mae_test = mean_absolute_error(y_test, y_pred)\n",
        "r2_adjusted_test = 1 - (1-r2_score(y_test, y_pred))*(len(y_test)-1)/(len(y_test)-X_test.shape[1]-1)\n",
        "sd_test = std(y_test)\n",
        "\n",
        "print(\"R^2 test: {}\".format(r2_test))\n",
        "print(\"R^2 adjusted test: {}\".format(r2_adjusted_test))\n",
        "print(\"Mean Absolute Error test: {}\".format(mae_test))\n",
        "print(\"Root Mean Squared Error test: {}\".format(rmse_test))\n",
        "print(\"Standard Deviation test: {}\".format(sd_test))  \n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
            "  warnings.warn(CV_WARNING, FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{'max_depth': 2, 'min_samples_leaf': 10, 'n_estimators': 500}\n",
            "Best score: -5.601586251842673\n",
            "R^2 train: 0.6827653548537419\n",
            "R^2 adjusted train: 0.6817688448771326\n",
            "Mean Absolute Error train: 5.311897631850796\n",
            "Root Mean Squared Error train: 8.343113522235745\n",
            "Standard Deviation train: PM10_0    14.812823\n",
            "dtype: float64\n",
            "R^2 test: 0.6183819125339685\n",
            "R^2 adjusted test: 0.61347617295537\n",
            "Mean Absolute Error test: 4.742529574133801\n",
            "Root Mean Squared Error test: 6.640485867950488\n",
            "Standard Deviation test: PM10_0    10.749429\n",
            "dtype: float64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "SpkHBnFvRMbE",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "{'max_depth': 2, 'min_samples_leaf': 10, 'n_estimators': 500}\n",
        "Best score: -5.601586251842673\n",
        "R^2 train: 0.6827653548537419\n",
        "R^2 adjusted train: 0.6817688448771326\n",
        "Mean Absolute Error train: 5.311897631850796\n",
        "Root Mean Squared Error train: 8.343113522235745\n",
        "Standard Deviation train: PM10_0    14.812823\n",
        "dtype: float64\n",
        "R^2 test: 0.6183819125339685\n",
        "R^2 adjusted test: 0.61347617295537\n",
        "Mean Absolute Error test: 4.742529574133801\n",
        "Root Mean Squared Error test: 6.640485867950488\n",
        "Standard Deviation test: PM10_0    10.749429\n",
        "dtype: float64"
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "eDauVJKo4JfJ"
      },
      "cell_type": "markdown",
      "source": [
        "# PM10 forecasts 2 hours ahead\n",
        "n_estimators=500, min_samples_leaf=10,max_depth=2, random_state=42"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "outputId": "9662e078-85a4-4544-9fbe-ebd4d9d1e7e1",
        "id": "RLME_PlZ4JfK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        }
      },
      "cell_type": "code",
      "source": [
        "X_train = pyreadr.read_r(\"X_train_PM10_201401_201612_multivar.rds\")\n",
        "y_train = pyreadr.read_r(\"y_train_PM10_201401_201612_multivar.rds\")\n",
        "\n",
        "X_test = pyreadr.read_r(\"X_test_PM10_201701_201709_multivar.rds\")\n",
        "y_test = pyreadr.read_r(\"y_test_PM10_201701_201709_multivar.rds\")\n",
        "\n",
        "X_train = X_train[None]\n",
        "y_train = y_train[None]\n",
        "X_test = X_test[None]\n",
        "y_test = y_test[None]\n",
        "\n",
        "# We convert the 'hour' variable to string\n",
        "X_train.hour = X_train.hour.astype(str)\n",
        "X_test.hour = X_test.hour.astype(str)\n",
        "\n",
        "# We convert the 'week_day' variable to string\n",
        "X_train.week_day = X_train.week_day.astype(str)\n",
        "X_test.week_day = X_test.week_day.astype(str)\n",
        "\n",
        "# We convert the 'month' variable to string\n",
        "X_train.month = X_train.month.astype(str)\n",
        "X_test.month = X_test.month.astype(str)\n",
        "\n",
        "X_train = X_train[['PM10_2', 'PM10_3', 'PM10_4', 'PM10_22', 'PM10_23', 'PM10_24',\n",
        "                   'PM10_48', 'PM10_72', 'PM10_96', 'PM10_120', 'month', 'week_day','no_lab_days', 'hour',\n",
        "                    'PM10_144', 'PM10_168', 'vv_2', 'wd_2', 'LL_2', 'RS_2','NO2_2', 'SO2_2']]\n",
        "                   \n",
        "X_test = X_test[['PM10_2', 'PM10_3', 'PM10_4', 'PM10_22', 'PM10_23', 'PM10_24',\n",
        "                   'PM10_48', 'PM10_72', 'PM10_96', 'PM10_120', 'month', 'week_day','no_lab_days', 'hour',\n",
        "                    'PM10_144', 'PM10_168', 'vv_2', 'wd_2', 'LL_2', 'RS_2','NO2_2', 'SO2_2']]\n",
        "\n",
        "\n",
        "X_train = pd.get_dummies(X_train)\n",
        "X_test  = pd.get_dummies(X_test)\n",
        "\n",
        "\n",
        "# Al hacer el one hot encoding el X_train y el X_test tienen distintas dimensiones. X_train tiene 47 variables y X_test 44. Por que? Porque el dataset de test tiene solo 9 meses, de enero a septiembre, y entonces la variable month solo se convierte en 9 variables, mientras que el dataset tendriamos 12, los 12 meses del anho. \n",
        "# Con el siguiente codigo solucionamos el problema (falta referencia)\n",
        "\n",
        "# Get missing columns in the training test\n",
        "missing_cols = set( X_train.columns ) - set( X_test.columns )\n",
        "# Add a missing column in test set with default value equal to 0\n",
        "for c in missing_cols:\n",
        "    X_test[c] = 0\n",
        "# Ensure the order of column in the test set is in the same order than in train set\n",
        "X_test = X_test[X_train.columns]\n",
        "# This code also ensure that column resulting from category in the test dataset but not present in the training dataset will be removed\n",
        "\n",
        "\n",
        "\n",
        "regXGB = XGBRegressor(n_estimators=500, min_samples_leaf=10,max_depth=2, random_state=42)\n",
        "regXGB.fit(X_train,y_train)\n",
        "\n",
        "\n",
        "# Compute train scores\n",
        "\n",
        "y_pred = regXGB.predict(X_train)\n",
        "\n",
        "r2_train = r2_score(y_train, y_pred)\n",
        "rmse_train = np.sqrt(mean_squared_error(y_train, y_pred))\n",
        "mae_train = mean_absolute_error(y_train, y_pred)\n",
        "r2_adjusted_train = 1 - (1-r2_score(y_train, y_pred))*(len(y_train)-1)/(len(y_train)-X_train.shape[1]-1)\n",
        "sd_train = std(y_train)\n",
        "\n",
        "print(\"R^2 train: {}\".format(r2_train))\n",
        "print(\"R^2 adjusted train: {}\".format(r2_adjusted_train))\n",
        "print(\"Mean Absolute Error train: {}\".format(mae_train))\n",
        "print(\"Root Mean Squared Error train: {}\".format(rmse_train)) \n",
        "print(\"Standard Deviation train: {}\".format(sd_train))  \n",
        "\n",
        "# Compute test scores\n",
        "\n",
        "y_pred = regXGB.predict(X_test)\n",
        "\n",
        "r2_test = r2_score(y_test, y_pred)\n",
        "rmse_test = np.sqrt(mean_squared_error(y_test, y_pred))\n",
        "mae_test = mean_absolute_error(y_test, y_pred)\n",
        "r2_adjusted_test = 1 - (1-r2_score(y_test, y_pred))*(len(y_test)-1)/(len(y_test)-X_test.shape[1]-1)\n",
        "sd_test = std(y_test)\n",
        "\n",
        "print(\"R^2 test: {}\".format(r2_test))\n",
        "print(\"R^2 adjusted test: {}\".format(r2_adjusted_test))\n",
        "print(\"Mean Absolute Error test: {}\".format(mae_test))\n",
        "print(\"Root Mean Squared Error test: {}\".format(rmse_test))\n",
        "print(\"Standard Deviation test: {}\".format(sd_test))  \n"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "R^2 train: 0.5702202383228376\n",
            "R^2 adjusted train: 0.5689203499436519\n",
            "Mean Absolute Error train: 6.336664454894228\n",
            "Root Mean Squared Error train: 9.710930100285669\n",
            "Standard Deviation train: PM10_0    14.812823\n",
            "dtype: float64\n",
            "R^2 test: 0.47676922203065597\n",
            "R^2 adjusted test: 0.4702952371509591\n",
            "Mean Absolute Error test: 5.5608391185893336\n",
            "Root Mean Squared Error test: 7.775566190657504\n",
            "Standard Deviation test: PM10_0    10.749429\n",
            "dtype: float64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "BGcFlBxqAhIb",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        ""
      ]
    },
    {
      "metadata": {
        "id": "Ht2DvjhDAHzd",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# PM10 forecasts 6 hours ahead\n",
        "n_estimators=500, min_samples_leaf=10,max_depth=2, random_state=42"
      ]
    },
    {
      "metadata": {
        "id": "mCef-K8-mL8b",
        "colab_type": "code",
        "outputId": "0baaf84e-f107-4a0c-caa3-a02908ef218a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        }
      },
      "cell_type": "code",
      "source": [
        "X_train = pyreadr.read_r(\"X_train_PM10_201401_201612_multivar.rds\")\n",
        "y_train = pyreadr.read_r(\"y_train_PM10_201401_201612_multivar.rds\")\n",
        "\n",
        "X_test = pyreadr.read_r(\"X_test_PM10_201701_201709_multivar.rds\")\n",
        "y_test = pyreadr.read_r(\"y_test_PM10_201701_201709_multivar.rds\")\n",
        "\n",
        "X_train = X_train[None]\n",
        "y_train = y_train[None]\n",
        "X_test = X_test[None]\n",
        "y_test = y_test[None]\n",
        "\n",
        "# We convert the 'hour' variable to string\n",
        "X_train.hour = X_train.hour.astype(str)\n",
        "X_test.hour = X_test.hour.astype(str)\n",
        "\n",
        "# We convert the 'week_day' variable to string\n",
        "X_train.week_day = X_train.week_day.astype(str)\n",
        "X_test.week_day = X_test.week_day.astype(str)\n",
        "\n",
        "# We convert the 'month' variable to string\n",
        "X_train.month = X_train.month.astype(str)\n",
        "X_test.month = X_test.month.astype(str)\n",
        "\n",
        "\n",
        "X_train = X_train[['PM10_6','PM10_7', 'PM10_8', 'PM10_9', 'PM10_22', 'PM10_23', 'PM10_24', \n",
        "                   'PM10_48', 'PM10_72', 'PM10_96', 'PM10_120', 'PM10_144', 'PM10_168', \n",
        "                   'month', 'week_day','no_lab_days', 'hour']]\n",
        "\n",
        "X_test = X_test[['PM10_6','PM10_7', 'PM10_8', 'PM10_9', 'PM10_22', 'PM10_23', 'PM10_24', \n",
        "                   'PM10_48', 'PM10_72', 'PM10_96', 'PM10_120', 'PM10_144', 'PM10_168', \n",
        "                   'month', 'week_day','no_lab_days', 'hour']]\n",
        "\n",
        "\n",
        "\n",
        "X_train = pd.get_dummies(X_train)\n",
        "X_test  = pd.get_dummies(X_test)\n",
        "\n",
        "\n",
        "# Al hacer el one hot encoding el X_train y el X_test tienen distintas dimensiones. X_train tiene 47 variables y X_test 44. Por que? Porque el dataset de test tiene solo 9 meses, de enero a septiembre, y entonces la variable month solo se convierte en 9 variables, mientras que el dataset tendriamos 12, los 12 meses del anho. \n",
        "# Con el siguiente codigo solucionamos el problema (falta referencia)\n",
        "\n",
        "# Get missing columns in the training test\n",
        "missing_cols = set( X_train.columns ) - set( X_test.columns )\n",
        "# Add a missing column in test set with default value equal to 0\n",
        "for c in missing_cols:\n",
        "    X_test[c] = 0\n",
        "# Ensure the order of column in the test set is in the same order than in train set\n",
        "X_test = X_test[X_train.columns]\n",
        "# This code also ensure that column resulting from category in the test dataset but not present in the training dataset will be removed\n",
        "\n",
        "\n",
        "\n",
        "regXGB = XGBRegressor(n_estimators=500, min_samples_leaf=10,max_depth=2, random_state=42)\n",
        "regXGB.fit(X_train,y_train)\n",
        "\n",
        "\n",
        "# Compute train scores\n",
        "\n",
        "y_pred = regXGB.predict(X_train)\n",
        "\n",
        "r2_train = r2_score(y_train, y_pred)\n",
        "rmse_train = np.sqrt(mean_squared_error(y_train, y_pred))\n",
        "mae_train = mean_absolute_error(y_train, y_pred)\n",
        "r2_adjusted_train = 1 - (1-r2_score(y_train, y_pred))*(len(y_train)-1)/(len(y_train)-X_train.shape[1]-1)\n",
        "sd_train = std(y_train)\n",
        "\n",
        "print(\"R^2 train: {}\".format(r2_train))\n",
        "print(\"R^2 adjusted train: {}\".format(r2_adjusted_train))\n",
        "print(\"Mean Absolute Error train: {}\".format(mae_train))\n",
        "print(\"Root Mean Squared Error train: {}\".format(rmse_train)) \n",
        "print(\"Standard Deviation train: {}\".format(sd_train))  \n",
        "\n",
        "# Compute test scores\n",
        "\n",
        "y_pred = regXGB.predict(X_test)\n",
        "\n",
        "r2_test = r2_score(y_test, y_pred)\n",
        "rmse_test = np.sqrt(mean_squared_error(y_test, y_pred))\n",
        "mae_test = mean_absolute_error(y_test, y_pred)\n",
        "r2_adjusted_test = 1 - (1-r2_score(y_test, y_pred))*(len(y_test)-1)/(len(y_test)-X_test.shape[1]-1)\n",
        "sd_test = std(y_test)\n",
        "\n",
        "print(\"R^2 test: {}\".format(r2_test))\n",
        "print(\"R^2 adjusted test: {}\".format(r2_adjusted_test))\n",
        "print(\"Mean Absolute Error test: {}\".format(mae_test))\n",
        "print(\"Root Mean Squared Error test: {}\".format(rmse_test))\n",
        "print(\"Standard Deviation test: {}\".format(sd_test))  \n"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "R^2 train: 0.4016048048015286\n",
            "R^2 adjusted train: 0.4002600443954101\n",
            "Mean Absolute Error train: 7.821355014675849\n",
            "Root Mean Squared Error train: 11.458608900573376\n",
            "Standard Deviation train: PM10_0    14.812823\n",
            "dtype: float64\n",
            "R^2 test: 0.2680946370432574\n",
            "R^2 adjusted test: 0.261382032512661\n",
            "Mean Absolute Error test: 6.763604330901764\n",
            "Root Mean Squared Error test: 9.196293983085365\n",
            "Standard Deviation test: PM10_0    10.749429\n",
            "dtype: float64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "VsFdGORYGEa9",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# PM10 forecasts 6 hours ahead\n",
        "### Gridsearchcv  \n",
        " \"n_estimators\":[100, 500, 1000, 2000],  \n",
        "                                \"min_samples_leaf\":[10,30],  \n",
        "                                  \"max_depth\":range(2,5)},  \n",
        "                                    scoring=\"neg_mean_absolute_error\")  \n"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "7pd2ElriFRPJ",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "X_train = pyreadr.read_r(\"X_train_PM10_201401_201612_multivar.rds\")\n",
        "y_train = pyreadr.read_r(\"y_train_PM10_201401_201612_multivar.rds\")\n",
        "\n",
        "X_test = pyreadr.read_r(\"X_test_PM10_201701_201709_multivar.rds\")\n",
        "y_test = pyreadr.read_r(\"y_test_PM10_201701_201709_multivar.rds\")\n",
        "\n",
        "X_train = X_train[None]\n",
        "y_train = y_train[None]\n",
        "X_test = X_test[None]\n",
        "y_test = y_test[None]\n",
        "\n",
        "# We convert the 'hour' variable to string\n",
        "X_train.hour = X_train.hour.astype(str)\n",
        "X_test.hour = X_test.hour.astype(str)\n",
        "\n",
        "# We convert the 'week_day' variable to string\n",
        "X_train.week_day = X_train.week_day.astype(str)\n",
        "X_test.week_day = X_test.week_day.astype(str)\n",
        "\n",
        "# We convert the 'month' variable to string\n",
        "X_train.month = X_train.month.astype(str)\n",
        "X_test.month = X_test.month.astype(str)\n",
        "\n",
        "X_train = X_train[['PM10_6','PM10_7', 'PM10_8', 'PM10_9', 'PM10_22', 'PM10_23', 'PM10_24', \n",
        "                   'PM10_48', 'PM10_72', 'PM10_96', 'PM10_120', 'PM10_144', 'PM10_168', \n",
        "                   'month', 'week_day','no_lab_days', 'hour']]\n",
        "\n",
        "X_test = X_test[['PM10_6','PM10_7', 'PM10_8', 'PM10_9', 'PM10_22', 'PM10_23', 'PM10_24', \n",
        "                   'PM10_48', 'PM10_72', 'PM10_96', 'PM10_120', 'PM10_144', 'PM10_168', \n",
        "                   'month', 'week_day','no_lab_days', 'hour']]\n",
        "\n",
        "\n",
        "X_train = pd.get_dummies(X_train)\n",
        "X_test  = pd.get_dummies(X_test)\n",
        "\n",
        "\n",
        "# Al hacer el one hot encoding el X_train y el X_test tienen distintas dimensiones. X_train tiene 47 variables y X_test 44. Por que? Porque el dataset de test tiene solo 9 meses, de enero a septiembre, y entonces la variable month solo se convierte en 9 variables, mientras que el dataset tendriamos 12, los 12 meses del anho. \n",
        "# Con el siguiente codigo solucionamos el problema (falta referencia)\n",
        "\n",
        "# Get missing columns in the training test\n",
        "missing_cols = set( X_train.columns ) - set( X_test.columns )\n",
        "# Add a missing column in test set with default value equal to 0\n",
        "for c in missing_cols:\n",
        "    X_test[c] = 0\n",
        "# Ensure the order of column in the test set is in the same order than in train set\n",
        "X_test = X_test[X_train.columns]\n",
        "# This code also ensure that column resulting from category in the test dataset but not present in the training dataset will be removed\n",
        "\n",
        "\n",
        "\n",
        "regXGB = GridSearchCV(XGBRegressor(n_estimators=350, min_samples_leaf=1,max_depth=4, random_state=42),\n",
        "                   param_grid={\"n_estimators\":[100, 500, 1000, 2000],\n",
        "                                \"min_samples_leaf\":[10,30],\n",
        "                                  \"max_depth\":range(2,5)},\n",
        "                                    scoring=\"neg_mean_absolute_error\")\n",
        "\n",
        "regXGB.fit(X_train,y_train)\n",
        "\n",
        "print(regXGB.best_params_)\n",
        "print(\"Best score: {}\".format(regXGB.best_score_))\n",
        "\n",
        "\n",
        "# Compute train scores\n",
        "\n",
        "y_pred = regXGB.predict(X_train)\n",
        "\n",
        "r2_train = r2_score(y_train, y_pred)\n",
        "rmse_train = np.sqrt(mean_squared_error(y_train, y_pred))\n",
        "mae_train = mean_absolute_error(y_train, y_pred)\n",
        "r2_adjusted_train = 1 - (1-r2_score(y_train, y_pred))*(len(y_train)-1)/(len(y_train)-X_train.shape[1]-1)\n",
        "sd_train = std(y_train)\n",
        "\n",
        "print(\"R^2 train: {}\".format(r2_train))\n",
        "print(\"R^2 adjusted train: {}\".format(r2_adjusted_train))\n",
        "print(\"Mean Absolute Error train: {}\".format(mae_train))\n",
        "print(\"Root Mean Squared Error train: {}\".format(rmse_train)) \n",
        "print(\"Standard Deviation train: {}\".format(sd_train))  \n",
        "\n",
        "# Compute test scores\n",
        "\n",
        "y_pred = regXGB.predict(X_test)\n",
        "\n",
        "r2_test = r2_score(y_test, y_pred)\n",
        "rmse_test = np.sqrt(mean_squared_error(y_test, y_pred))\n",
        "mae_test = mean_absolute_error(y_test, y_pred)\n",
        "r2_adjusted_test = 1 - (1-r2_score(y_test, y_pred))*(len(y_test)-1)/(len(y_test)-X_test.shape[1]-1)\n",
        "sd_test = std(y_test)\n",
        "\n",
        "print(\"R^2 test: {}\".format(r2_test))\n",
        "print(\"R^2 adjusted test: {}\".format(r2_adjusted_test))\n",
        "print(\"Mean Absolute Error test: {}\".format(mae_test))\n",
        "print(\"Root Mean Squared Error test: {}\".format(rmse_test))\n",
        "print(\"Standard Deviation test: {}\".format(sd_test))  \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "zF9wio5RBWQ2"
      },
      "cell_type": "markdown",
      "source": [
        "# PM10 forecasts 12 hours ahead"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "outputId": "3c35b454-c4bd-4d7f-b205-26ae75ec28e8",
        "id": "mLQaa1ynBWQ3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        }
      },
      "cell_type": "code",
      "source": [
        "X_train = pyreadr.read_r(\"X_train_PM10_201401_201612_multivar.rds\")\n",
        "y_train = pyreadr.read_r(\"y_train_PM10_201401_201612_multivar.rds\")\n",
        "\n",
        "X_test = pyreadr.read_r(\"X_test_PM10_201701_201709_multivar.rds\")\n",
        "y_test = pyreadr.read_r(\"y_test_PM10_201701_201709_multivar.rds\")\n",
        "\n",
        "X_train = X_train[None]\n",
        "y_train = y_train[None]\n",
        "X_test = X_test[None]\n",
        "y_test = y_test[None]\n",
        "\n",
        "# We convert the 'hour' variable to string\n",
        "X_train.hour = X_train.hour.astype(str)\n",
        "X_test.hour = X_test.hour.astype(str)\n",
        "\n",
        "# We convert the 'week_day' variable to string\n",
        "X_train.week_day = X_train.week_day.astype(str)\n",
        "X_test.week_day = X_test.week_day.astype(str)\n",
        "\n",
        "# We convert the 'month' variable to string\n",
        "X_train.month = X_train.month.astype(str)\n",
        "X_test.month = X_test.month.astype(str)\n",
        "\n",
        "X_train = X_train[['PM10_12','PM10_13', 'PM10_14', 'PM10_15', 'PM10_22', 'PM10_23', 'PM10_24',\n",
        "                   'PM10_48', 'PM10_72', 'PM10_96', 'PM10_120', 'PM10_144', 'PM10_168', \n",
        "                   'no_lab_days', 'hour', 'week_day', 'month']]\n",
        "\n",
        "X_test = X_test[['PM10_12','PM10_13', 'PM10_14', 'PM10_15', 'PM10_22', 'PM10_23', 'PM10_24',\n",
        "                   'PM10_48', 'PM10_72', 'PM10_96', 'PM10_120', 'PM10_144', 'PM10_168', \n",
        "                   'no_lab_days', 'hour', 'week_day', 'month']]\n",
        "\n",
        "\n",
        "\n",
        "X_train = pd.get_dummies(X_train)\n",
        "X_test  = pd.get_dummies(X_test)\n",
        "\n",
        "\n",
        "# Al hacer el one hot encoding el X_train y el X_test tienen distintas dimensiones. X_train tiene 47 variables y X_test 44. Por que? Porque el dataset de test tiene solo 9 meses, de enero a septiembre, y entonces la variable month solo se convierte en 9 variables, mientras que el dataset tendriamos 12, los 12 meses del anho. \n",
        "# Con el siguiente codigo solucionamos el problema (falta referencia)\n",
        "\n",
        "# Get missing columns in the training test\n",
        "missing_cols = set( X_train.columns ) - set( X_test.columns )\n",
        "# Add a missing column in test set with default value equal to 0\n",
        "for c in missing_cols:\n",
        "    X_test[c] = 0\n",
        "# Ensure the order of column in the test set is in the same order than in train set\n",
        "X_test = X_test[X_train.columns]\n",
        "# This code also ensure that column resulting from category in the test dataset but not present in the training dataset will be removed\n",
        "\n",
        "\n",
        "\n",
        "regXGB = XGBRegressor(n_estimators=500, min_samples_leaf=10,max_depth=2, random_state=42)\n",
        "regXGB.fit(X_train,y_train)\n",
        "\n",
        "\n",
        "# Compute train scores\n",
        "\n",
        "y_pred = regXGB.predict(X_train)\n",
        "\n",
        "r2_train = r2_score(y_train, y_pred)\n",
        "rmse_train = np.sqrt(mean_squared_error(y_train, y_pred))\n",
        "mae_train = mean_absolute_error(y_train, y_pred)\n",
        "r2_adjusted_train = 1 - (1-r2_score(y_train, y_pred))*(len(y_train)-1)/(len(y_train)-X_train.shape[1]-1)\n",
        "sd_train = std(y_train)\n",
        "\n",
        "print(\"R^2 train: {}\".format(r2_train))\n",
        "print(\"R^2 adjusted train: {}\".format(r2_adjusted_train))\n",
        "print(\"Mean Absolute Error train: {}\".format(mae_train))\n",
        "print(\"Root Mean Squared Error train: {}\".format(rmse_train)) \n",
        "print(\"Standard Deviation train: {}\".format(sd_train))  \n",
        "\n",
        "# Compute test scores\n",
        "\n",
        "y_pred = regXGB.predict(X_test)\n",
        "\n",
        "r2_test = r2_score(y_test, y_pred)\n",
        "rmse_test = np.sqrt(mean_squared_error(y_test, y_pred))\n",
        "mae_test = mean_absolute_error(y_test, y_pred)\n",
        "r2_adjusted_test = 1 - (1-r2_score(y_test, y_pred))*(len(y_test)-1)/(len(y_test)-X_test.shape[1]-1)\n",
        "sd_test = std(y_test)\n",
        "\n",
        "print(\"R^2 test: {}\".format(r2_test))\n",
        "print(\"R^2 adjusted test: {}\".format(r2_adjusted_test))\n",
        "print(\"Mean Absolute Error test: {}\".format(mae_test))\n",
        "print(\"Root Mean Squared Error test: {}\".format(rmse_test))\n",
        "print(\"Standard Deviation test: {}\".format(sd_test))  \n"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "R^2 train: 0.32493202522625597\n",
            "R^2 adjusted train: 0.3234149597631665\n",
            "Mean Absolute Error train: 8.389725768295612\n",
            "Root Mean Squared Error train: 12.170589109352777\n",
            "Standard Deviation train: PM10_0    14.812823\n",
            "dtype: float64\n",
            "R^2 test: 0.16328901405336615\n",
            "R^2 adjusted test: 0.15561519413165448\n",
            "Mean Absolute Error test: 7.379480929525691\n",
            "Root Mean Squared Error test: 9.832707431450373\n",
            "Standard Deviation test: PM10_0    10.749429\n",
            "dtype: float64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "WEwgalJwB2lw"
      },
      "cell_type": "markdown",
      "source": [
        "# PM10 forecasts 24 hours ahead"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "outputId": "69af72fa-7030-43c8-e4b5-68a8dac02a6b",
        "id": "ThpX0n9dB2lx",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        }
      },
      "cell_type": "code",
      "source": [
        "X_train = pyreadr.read_r(\"X_train_PM10_201401_201612_multivar.rds\")\n",
        "y_train = pyreadr.read_r(\"y_train_PM10_201401_201612_multivar.rds\")\n",
        "\n",
        "X_test = pyreadr.read_r(\"X_test_PM10_201701_201709_multivar.rds\")\n",
        "y_test = pyreadr.read_r(\"y_test_PM10_201701_201709_multivar.rds\")\n",
        "\n",
        "X_train = X_train[None]\n",
        "y_train = y_train[None]\n",
        "X_test = X_test[None]\n",
        "y_test = y_test[None]\n",
        "\n",
        "# We convert the 'hour' variable to string\n",
        "X_train.hour = X_train.hour.astype(str)\n",
        "X_test.hour = X_test.hour.astype(str)\n",
        "\n",
        "# We convert the 'week_day' variable to string\n",
        "X_train.week_day = X_train.week_day.astype(str)\n",
        "X_test.week_day = X_test.week_day.astype(str)\n",
        "\n",
        "# We convert the 'month' variable to string\n",
        "X_train.month = X_train.month.astype(str)\n",
        "X_test.month = X_test.month.astype(str)\n",
        "\n",
        "X_train = X_train[['PM10_24','PM10_25', 'PM10_26', 'PM10_27', 'PM10_48', 'PM10_72',\n",
        "                   'PM10_96', 'PM10_120', 'PM10_144', 'PM10_168',\n",
        "                   'no_lab_days', 'hour','week_day', 'month']]\n",
        "\n",
        "X_test = X_test[['PM10_24','PM10_25', 'PM10_26', 'PM10_27', 'PM10_48', 'PM10_72',\n",
        "                 'PM10_96', 'PM10_120', 'PM10_144', 'PM10_168',\n",
        "                 'no_lab_days', 'hour', 'week_day', 'month']]\n",
        "\n",
        "\n",
        "\n",
        "X_train = pd.get_dummies(X_train)\n",
        "X_test  = pd.get_dummies(X_test)\n",
        "\n",
        "\n",
        "# Al hacer el one hot encoding el X_train y el X_test tienen distintas dimensiones. X_train tiene 47 variables y X_test 44. Por que? Porque el dataset de test tiene solo 9 meses, de enero a septiembre, y entonces la variable month solo se convierte en 9 variables, mientras que el dataset tendriamos 12, los 12 meses del anho. \n",
        "# Con el siguiente codigo solucionamos el problema (falta referencia)\n",
        "\n",
        "# Get missing columns in the training test\n",
        "missing_cols = set( X_train.columns ) - set( X_test.columns )\n",
        "# Add a missing column in test set with default value equal to 0\n",
        "for c in missing_cols:\n",
        "    X_test[c] = 0\n",
        "# Ensure the order of column in the test set is in the same order than in train set\n",
        "X_test = X_test[X_train.columns]\n",
        "# This code also ensure that column resulting from category in the test dataset but not present in the training dataset will be removed\n",
        "\n",
        "\n",
        "\n",
        "regXGB = XGBRegressor(n_estimators=500, min_samples_leaf=10,max_depth=2, random_state=42)\n",
        "regXGB.fit(X_train,y_train)\n",
        "\n",
        "\n",
        "# Compute train scores\n",
        "\n",
        "y_pred = regXGB.predict(X_train)\n",
        "\n",
        "r2_train = r2_score(y_train, y_pred)\n",
        "rmse_train = np.sqrt(mean_squared_error(y_train, y_pred))\n",
        "mae_train = mean_absolute_error(y_train, y_pred)\n",
        "r2_adjusted_train = 1 - (1-r2_score(y_train, y_pred))*(len(y_train)-1)/(len(y_train)-X_train.shape[1]-1)\n",
        "sd_train = std(y_train)\n",
        "\n",
        "print(\"R^2 train: {}\".format(r2_train))\n",
        "print(\"R^2 adjusted train: {}\".format(r2_adjusted_train))\n",
        "print(\"Mean Absolute Error train: {}\".format(mae_train))\n",
        "print(\"Root Mean Squared Error train: {}\".format(rmse_train)) \n",
        "print(\"Standard Deviation train: {}\".format(sd_train))  \n",
        "\n",
        "# Compute test scores\n",
        "\n",
        "y_pred = regXGB.predict(X_test)\n",
        "\n",
        "r2_test = r2_score(y_test, y_pred)\n",
        "rmse_test = np.sqrt(mean_squared_error(y_test, y_pred))\n",
        "mae_test = mean_absolute_error(y_test, y_pred)\n",
        "r2_adjusted_test = 1 - (1-r2_score(y_test, y_pred))*(len(y_test)-1)/(len(y_test)-X_test.shape[1]-1)\n",
        "sd_test = std(y_test)\n",
        "\n",
        "print(\"R^2 test: {}\".format(r2_test))\n",
        "print(\"R^2 adjusted test: {}\".format(r2_adjusted_test))\n",
        "print(\"Mean Absolute Error test: {}\".format(mae_test))\n",
        "print(\"Root Mean Squared Error test: {}\".format(rmse_test))\n",
        "print(\"Standard Deviation test: {}\".format(sd_test))  \n"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "R^2 train: 0.28464814701162733\n",
            "R^2 adjusted train: 0.2831238810921185\n",
            "Mean Absolute Error train: 8.712622302391988\n",
            "Root Mean Squared Error train: 12.528460294007024\n",
            "Standard Deviation train: PM10_0    14.812823\n",
            "dtype: float64\n",
            "R^2 test: 0.08858207273456675\n",
            "R^2 adjusted test: 0.08065920470870958\n",
            "Mean Absolute Error test: 7.827284202333162\n",
            "Root Mean Squared Error test: 10.262287204288324\n",
            "Standard Deviation test: PM10_0    10.749429\n",
            "dtype: float64\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}