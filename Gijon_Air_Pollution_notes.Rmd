---
title: "Gijon_Air_Pollution"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Gijon Air Pollution notes

Notes about the development of my capstone final project of my Master on Data Science in KSchool.

### Project goals:

  - Construct a web dashboard to visualize the evolution of the main air pollution indicators of Gijon city. (Asturias; Spain).
  - Build a model to try to predict the probability of exceeding the pollution limits established by the EU in the city of Gijon (one day in advance).

#### References

- OpenAir package web: http://davidcarslaw.github.io/openair/
- Breezometer: https://breezometer.com/real-time-air-quality

#### Data gathering

Loading packages
```{r , warning= FALSE, message= FALSE}
library(readr)
library(dplyr)
library(tidyr)
library(openair) # http://davidcarslaw.github.io/openair/
library(purrr)
library(lubridate)
library(ggplot2)
library(stringr)

```


First of all I have to check if I will have the basic data to make the analysis. I need air pollution and weather data of the Gijon area. 
The town hall of Gijon has an open data web portal here https://transparencia.gijon.es/. We can download pollution air data on csv format from year 2000 to 2017 here: https://transparencia.gijon.es/search/risp_dataset/page/1808-catalogo-de-datos?utf8=%E2%9C%93&search=aire+&search_sector=&search_format=&commit=Buscar&authenticity_token=j8%2F3CvCuPcDkrRe%2F1NR5RBp0t%2FOOosiA7724w3T2mB4%3D

I downloaded 18 csv files with air pollution and weather data of Gijón from years 2000 to 2017. I saved them in the "data" folder.
I downloaded two more files from this web, a csv file with the description of the variables and another csv file with information about the measurement stations. 

We take a look to the information included in  the stations_info.csv file. It includes the stations addresses, longitude, latitude and their IDs and names. All this information, as we will see, is included in the csv files with pollution and weather data too. So, we are not going to use this file anymore.


```{r , warning= FALSE, message= FALSE}
stations <- read_delim('data/stations_info.csv',
                       delim = ';',
                       escape_double = FALSE, 
                       trim_ws = TRUE,
                       locale = locale(encoding = "ISO-8859-1"),
                       col_types = cols(.default = "c"))
stations



```

We can see on this image the location of each station. http://movil.asturias.es/medioambiente/articulos/ficheros/Informe%20de%20calidad%20del%20aire%20en%20Asturias%202016.pdf

![Source: "Informe de calidad del aire del Principado de Asturias (2016)".](imgs/gijon_stations_map.jpg)
ººº

The air_data_descriptors.csv file contains information about the nature of the elements measured by the stations. Names, descriptions and units.
```{r , warning= FALSE, message= FALSE}
variables <- read_csv('data/air_data_descriptors.csv', locale = locale(encoding = "ISO-8859-1"))
variables

```

In order to import the data from the 18 csv files we have to create a file list with them. 

```{r warning= FALSE, message= FALSE}
data_files <- list.files(path = "data", pattern = "air_data_20*")
```

Then, we map the function read_csv on this list in order to import every file and finally merge them in a unique dataframe (air_data_0) with reduce(rbind). 

```{r warning= FALSE, message= FALSE}
air_data_0 <- data_files %>% 
    map(function(x) {
        read_csv(paste0("./data/", x), locale = locale(encoding = "ISO-8859-1"), col_types = cols(.default = "c"))
    }) %>%
    reduce(rbind)
```

We change the names of some variables.

```{r warning= FALSE, message= FALSE}

# Variables names changing
air_data_1 <- air_data_0 %>% rename(station = `Estación`,
                                    station_name = `Título`,
                                    date_time_utc = `Fecha Solar (UTC)`,
                                    latitude = latitud,
                                    longitude = longitud)
```

We imported all the columns as characters in order to avoid problems with the format attributions. So, we have to make now some format variable changes.

We change the date_time_utc format from character to date time. 
```{r warning= FALSE, message= FALSE}

air_data_1$date_time_utc <- ymd_hms(air_data_1$date_time_utc)
```

We change the station and station_name formats from character to factor.
```{r warning= FALSE, message= FALSE}
air_data_1$station <- as.factor(air_data_1$station)
air_data_1$station_name <- as.factor(air_data_1$station_name)
```

We create a vector with all the variables we want to be numeric
```{r warning= FALSE, message= FALSE}
num <- colnames(air_data_1)[c(3, 4, 6:22)]
```
We make the conversion to numeric 
```{r warning= FALSE, message= FALSE}
air_data_1 <- air_data_1 %>% mutate_at(num, as.numeric)
```

We create a dictionary with an alias for each station in order to add a new variable with more
convenient station names
```{r warning= FALSE, message= FALSE}
alias_dict <- data.frame(
      station = c("1", "2", "3", "4", "10", "11"),
      station_alias = c("Constitución", "Argentina", "H. Felgueroso", "Castilla", "Montevil", "Santa Bárbara")
)
```
We join the alias dictionary to the air_data_1 data frame in order to add the new variable to the data 
set.
```{r warning= FALSE, message= FALSE}
air_data_1 <- air_data_1 %>% left_join(alias_dict, by = 'station')
```

We take a look to the data set
```{r warning= FALSE, message= FALSE}
glimpse(air_data_1)
summary(air_data_1)
```

There are several variables which minimun values are -9999. It is very likely to be an error. So, we replace these values by nas (to do: ask the owner of the data about this detail).
```{r warning = FALSE, message = FALSE}

air_data_2 <- air_data_1 %>% mutate(SO2 = replace(SO2, SO2 == -9999, NA),
                                    NO = replace(NO, NO == -9999, NA),
                                    NO2 = replace(NO2, NO2 == -9999, NA),
                                    PM10 = replace(PM10, PM10 == -9999, NA),
                                    O3 = replace(O3, O3 == -9999, NA))

summary(air_data_2)

```

We check again the output of summary. Some variables values are negative. We replace them by NAs (to do: ask the owner of the data about this detail).

```{r warning = FALSE, message = FALSE}
air_data_2 <- air_data_2 %>% mutate(SO2 = replace(SO2, SO2 < 0, NA),
                                    RS = replace(RS, RS < 0, NA),
                                    TOL = replace(TOL, TOL < 0, NA),
                                    MXIL = replace(MXIL, MXIL < 0, NA))

summary(air_data_2)

```

we take a look to the data completion. What proportion of nas do we have by variable, station, year, etc?
```{r warning = FALSE, message = FALSE}
nas <- air_data_2 %>% 
  group_by(station_alias, year(date_time_utc)) %>%
  select(everything()) %>%  
  summarise_all(funs(sum(is.na(.))))

nas_per <- air_data_2 %>% 
  group_by(station_alias, year(date_time_utc)) %>%
  select(everything()) %>%  
  summarise_all(funs(round(sum(is.na(.))/n(), 2)))

data_completion <- air_data_2 %>% 
  group_by(station_alias, year(date_time_utc)) %>%
  select(everything()) %>%  
  summarise_all(funs(round(sum(!is.na(.))/n(), 2)))

```


```{r warning = FALSE, message = FALSE}
constitucion_data <- data_completion %>% filter(station == '1')
# constitución: desde el anho 2000 tiene registrados datos de SO2, NO, NO2, CO, PM10, 03, dd, vv, TMP, 
# HR, PRB, HS y LL, 
# A partir del anho 2007 tambien existen datos de BEN, TOL y MXIL. Y a partir de 2009 se empieza a medir # las particulas PM25.
# en el anho 2008 desciende la completacion de los datos hasta el 88% de las variables dd, vv, TMP, 
# HR, PRB, HS, LL, BEN, TOL y MXIL (comprobar que no haya sido un problema de importacion de los datos)

argentina_data <- data_completion %>% filter(station == '2')
# argentina: datos desde el anho 2000. Solo de las variables SO2, NO, NO2, CO, PM10 y 03. 

felgueroso_data <- data_completion %>% filter(station == '3')
# felgueroso: datos desde el anho 2000. Solo de las variables SO2, NO, NO2, CO, PM10 y 03. 

castilla_data <- data_completion %>% filter(station == '4')
# castilla: datos desde el anho 2000. Solo de las variables SO2, NO, NO2, CO, PM10 y 03.

montevil_data <- data_completion %>% filter(station == '10')
# montevil: datos desde 2009. Solo datos de las variables SO2, NO, NO2, 03, dd, vv, TMP, HR, PRB, HS, 
# LL y PM25
# sin datos de las variables CO, PM10, BEN, TOL y MXIL

barbara_data <- data_completion %>% filter(station == '11')
# barbara: solo datos de 2016 y 2017 de las variables NO, NO2, CO, PM10, 03 y PM25

# air_data_2 <- map_df(data_files, read_csv,  "./data/", locale = locale(encoding = "ISO-8859-1"))

# We add a new variable with the year 

air_data_2$year <- year(air_data_2$date_time_utc)

observations_by_year <- air_data_2 %>% group_by(year) %>%
                        summarise(n = n())

# We remove the only 6 observations of 2018
air_data_2 <- air_data_2 %>% filter(year != '2018')

# We add variables for the month, month day and week day

air_data_2$month <- month(air_data_2$date_time_utc)
air_data_2$week_day <- wday(air_data_2$date_time_utc, week_start = getOption("lubridate.week.start", 1))
air_data_2$hour <- hour(air_data_2$date_time_utc)
air_data_2$year_month_day <- ymd(air_data_2$date_time_utc)

```

We take a look to the general trend of several indicators through the last 18 years

```{r warning = FALSE, message= FALSE, out.width= '\\textwidth'}
year_avgs <- air_data_2 %>% select(station_alias, date_time_utc, PM10, PM25, SO2, NO2, NO, O3, BEN, CO, MXIL, TOL) %>%
  group_by(station_alias, year = year(date_time_utc)) %>%
  summarise_all(funs(mean(., na.rm = TRUE))) %>% 
  select(-date_time_utc) # quito ahora esta variable, porque no tiene sentido que salga su media.

# lo ponemos en formato largo

year_avgs_largo <- gather(year_avgs, contaminante, value, 3:length(year_avgs))

# lo representamos en un grid

ggplot(year_avgs_largo, aes(x = year, y = value)) + 
  geom_line() + 
  facet_grid(contaminante~station_alias,scales="free_y") +
   theme(axis.text = element_text(size = 6))

```


Me quedo solo con las estaciones urbanas. Santa Barbara y Montevil tienen muchos menos datos y además
las variables se comportan de forma muy distinta. De momento las dejamos aparte.

```{r warning = FALSE, message= FALSE, out.width= '\\textwidth'}

air_data_3 <- air_data_2 %>% filter(station_alias != 'Montevil' , 
                                         station_alias != 'Santa Bárbara' )

```

```{r warning = FALSE, message= FALSE, out.width= '\\textwidth'}
year_avgs <- air_data_3 %>% select(station_alias, date_time_utc, PM10, PM25, SO2, NO2, NO, O3, BEN, CO, MXIL, TOL) %>%
  group_by(station_alias, year = year(date_time_utc)) %>%
  summarise_all(funs(mean(., na.rm = TRUE))) %>% 
  select(-date_time_utc) # quito ahora esta variable, porque no tiene sentido que salga su media.

# lo ponemos en formato largo

year_avgs_largo <- gather(year_avgs, contaminante, value, 3:length(year_avgs))

# lo representamos en un grid

ggplot(year_avgs_largo, aes(x = year, y = value)) + 
  geom_line() + 
  facet_grid(contaminante~station_alias,scales="free_y") +
   theme(axis.text = element_text(size = 6))

```


```{r warning = FALSE, message= FALSE, out.width= '\\textwidth'}
hour_avgs <- air_data_3 %>% select(station_alias, hour, PM10, PM25, SO2, NO2, NO, O3, BEN, CO, MXIL, TOL) %>%
  group_by(station_alias, hour) %>%
  summarise_all(funs(mean(., na.rm = TRUE)))  # quito ahora esta variable, porque no tiene sentido que salga su media.

# lo ponemos en formato largo

hour_avgs_largo <- gather(hour_avgs, contaminante, value, 3:length(hour_avgs))

# lo representamos en un grid

ggplot(hour_avgs_largo, aes(x = hour, y = value)) + 
  geom_line() + 
  facet_grid(contaminante~station_alias,scales="free_y") +
   theme(axis.text = element_text(size = 6))
```

```{r warning = FALSE, message= FALSE, out.width= '\\textwidth'}
month_avgs <- air_data_3 %>% select(station_alias, month, PM10, PM25, SO2, NO2, NO, O3, BEN, CO, MXIL, TOL) %>%
  group_by(station_alias, month) %>%
  summarise_all(funs(mean(., na.rm = TRUE)))  # quito ahora esta variable, porque no tiene sentido que salga su media.

# lo ponemos en formato largo

month_avgs_largo <- gather(month_avgs, contaminante, value, 3:length(month_avgs))

# lo representamos en un grid

ggplot(month_avgs_largo, aes(x = month, y = value)) + 
  geom_line() + 
  facet_grid(contaminante~station_alias,scales="free_y") +
   theme(axis.text = element_text(size = 6))
```

```{r warning = FALSE, message= FALSE, out.width= '\\textwidth'}
week_day_avgs <- air_data_3 %>% select(station_alias, week_day, PM10, PM25, SO2, NO2, NO, O3, BEN, CO, MXIL, TOL) %>%
  group_by(station_alias, week_day) %>%
  summarise_all(funs(mean(., na.rm = TRUE)))  # quito ahora esta variable, porque no tiene sentido que salga su media.

# lo ponemos en formato largo

week_day_avgs_largo <- gather(week_day_avgs, contaminante, value, 3:length(week_day_avgs))

# lo representamos en un grid

ggplot(week_day_avgs_largo, aes(x = week_day, y = value)) + 
  geom_line() + 
  facet_grid(contaminante~station_alias,scales="free_y") +
   theme(axis.text = element_text(size = 6))
```


