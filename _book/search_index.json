[
["index.html", "Gijón Air Pollution - An exercise of visualization and forecasting Preface", " Gijón Air Pollution - An exercise of visualization and forecasting Sergio Berdiales Preface My name is Sergio Berdiales and I am a Data Analyst with more than ten years experience in Customer Experience and Quality areas. If you want to know more about me or contact me you can visit my Linkedin profile or my Twitter account. This is my final project for the Kschool Master on Data Science (8th edition). The main objective of this project is to show I can apply the acquired knowledge during the master’s course in a practical way . The Master on Data Science of Kschool is a 230-hour course which includes Python and R programming, Statistics, Machine Learning methods, Visualization tools, a Deep Learning introduction and much more (use of Git / Github, linux command line, Jupyter and Google Collab notebooks, etc). And all of these in a very practical and useful way. If you are interested in becoming a Data Scientist this course could be your first step. Structure of this document This document is divided in two basic parts. Project Memory. The memory of the project spans from the “Preface” to the “References” section. The purpose of this part is to briefly explain what the objectives of this project are, which methodology I used in order to achieve these objectives, and what my final conclusions are. R and Python scripts. In this part, I included all the R code used (this R code is saved too as rmarkdown files in the Github project repository). The Python code is not included in this document but you have the links to the Google Collab notebooks at the Python scripts section. All the Python notebooks are in the Github repository project too as Jupyter notebooks. This is a work in progress and my intention is for it to be just the start of something bigger. The next step is to improve the forecasts of pollutants levels including the weather forecasts in the models. So, I think this models would give more accurate predictions. Then, I would put the models in production in order to give real time predictions via Twitter. I am learning. So, if you see something wrong in my code, my reasoning or anything else you think I could improve or fix, please, tell me. I would really appreciate your help. You can contact me via Linkedin profile, Twitter account or Gmail. If you are interested in learning about air pollution my advice is to start visiting any of these web sites: The site of the EU (European Union) on air pollution. The site of the EPA (The United States Environmental Protection Agency) on air pollution. The site of the WHO (World Health Organization) on air pollution. And if your interest is specifically about the situation of air quality in the city of Gijón I highly recommend you read these reports. “Plan de mejora de la calidad del aire en la aglomeración área de Gijón.” (pdf here). “Calidad del Aire y Salud en Asturias. Informe Epidemiológico 2016.” (pdf here). “Informe de calidad del aire en Asturias.”(pdf here). “Estudio de contribución de fuentes en las partículas PM10 en suspensión en la aglomeración área de Gijón y en la zona de Avilés.” (pdf here). “Modelización de la contaminación por partículas PM10 en la aglomeración de Gijón.” (pdf here). "],
["intro.html", "1 Introduction 1.1 Why 1.2 What 1.3 How", " 1 Introduction 1.1 Why Why did I choose “Air Pollution in the city of Gijón” as my final project for my Master’s in Data Science? I was born in Gijón and I was working in Madrid for 12 years. Both cities suffer from low levels of air quality. And in recent years air pollution has become a great source of public concern. Therefore, the idea came up in a very natural way. I then saw that the Town Hall of Gijón had an open data website where it had published 18 years of hourly data from its six air quality monitoring stations. That seemed like a sign. I had a topic. And, now, I had the data. 1.2 What The main objectives of this Data Science project are: 1. To construct and publish a web dashboard so as to visualize the evolution of the main air pollution indicators in the city of Gijón. It might seem trivial and hardly useful but the fact is that, after searching the web, I didn’t find any service where these kind of evolutions could be easily consulted. This lack of public information could be contributing to generating a very pessimistic vision of the air quality in the city of Gijón. It is true that Gijón presents air quality levels on some pollutants which are below the recommendations of the WHO. But, the fact is that the air quality in Gijón has improved drastically during the last two decades. I am probably being too optimistic, but I would like to think that through this work I’m helping to improve public understanding on the matter. In order to accomplish this objective I finally choose Tableau software and its free visualization service web publishing Tableau Public as my main tools. If you want to see the final result you can go to the chapter 4 “Visualizations”. 2. To build forecasting models in order to predict pollution levels. My second objective is to try to forecast hourly pollution levels one to twenty four hours in advance. Initially, my intention was to create models for every pollutant and every monitoring station. But, finally, I have focused my efforts on only one station (Constitución) and two of the pollutants, PM10 and NO2. 1.3 How The following is a list the software tools and services I used to develop this project: R for importing, cleaning, exploring and preparing the data for the prediction models. Python for making the models (except the ARIMA models, made with R and the fantastic Forecast package). Rmarkdown to write this document and the Bookdown package to build the html book. And I took advantage too from the publishing free service at Bookdown.org to publish the final document too.. Git and Github for control version of my work. The Kaggle platform to publish the final dataset with all the data. R-Studio on a Windows laptop (with Windows subsystem for Linux) to manage all the R code and Google Collab notebooks to write the Python code. Tableau Desktop (student license) to create the dashboards and Tableau Public to publish the final stories. Microsoft Excel to elaborate the csv file with the Gijón holiday dates and the table with the compilations of all the model scores. All the files and the code needed to replicate the entire work is saved in this Github repository, with the exception of the final csv file with all the data used by the Tableau Public visualizations (it exceeds the Github file size limits). This file can be downloaded from Kaggle. To reproduce the project all you need to do is to execute the following scripts in order. The rmarkdown files are locally executable, but the Python notebooks were created and executed in Google Colab. So, to assure their correct running my advice is to use the same platform: 10_Gathering_and_Cleaning_Data.rmd 11_Data_Exploration.rmd _10_1_train_test_PM10_AR_datasets.rmd _10_2_train_test_PM10_NO2_MULTIVAR_datasets.rmd 12_Forecasting_Models_ARIMA_PM10.rmd 21_Forecasting_Models_ML_PM10_AR.ipynb 22_Forecasting_Models_ML_PM10_MULTIVAR.ipynb 23_Forecasting_Models_ML_NO2_MULTIVAR.ipynb (ipynb notebooks to be executed on Google Colab. The links to this notebooks are avalaible in the section 4 of this document “Forecasting models”) And in order to render this html book you would have to install the Bookdown package on R and follow these instructions. "],
["the-data.html", "2 The Data", " 2 The Data “In God we trust. All others must bring data.” – W. Edwards Deming, statistician, professor and author. I gathered the data used in this project from the open data website of the Town Hall of Gijón https://transparencia.gijon.es/. The data can be downloaded from here: I downloaded 18 csv files with air pollution and weather data of Gijón from years 2000 to 2017. I saved them in the “data” project folder. I downloaded two more files from this web, a csv file with the description of the variables and another csv file with information about the measurement stations. There are more csv files, with new variables, created ad hoc for the visualizations on my Tableau Public site. They are described in the ‘Visualizations’ section of this document. All the data files are in the Github repository project, except the final dataset in csv format “air_data_2.csv”, because the Github file size limits (but there is a rds version of this file in the project folder “data_rds”). Nevertheless I uploaded this file to Kaggle.. Image source: “Informe de calidad del aire del Principado de Asturias (2016)”. These are the original fields from the 18 csv files downloaded: Estación: Station id. Título: Station name. latitud: Latitude. longitud: Longitude. date_time_utc: Date Time UTC. date_time_utc: Date Time UTC. SO2: SO2 concentration (µg/m³). NO: NO concentration (µg/m³). NO2: NO2 concentration (µg/m³). CO: NO2 concentration (mg/m³). PM10: Particulate Matter (&lt;10 µg/m³). O3: Ozone concentration (µg/m³). dd: Wind direction (degrees). vv: Wind speed (m/s). TMP: Dry temperature (ºC). HR: Relative humidity (%rh). PRB: Atmospheric pressure (mb). RS: Solar radiation (W/m²). LL: Rainfall (l/m²). BEN: Benzene concentration (µg/m³). TOL: Toluene concentration (µg/m³). MXIL: M-Xylene (µg/m³). PM25: Particulate Matter (&lt;2.5 µg/m³). And these are the fields of the final file ‘air_data_2.csv’ (or ‘air_data_2.rds’): station: Station id. station_name: Station name. latitude: Latitude. longitude: Longitude. date_time_utc: Date Time UTC. SO2: SO2 concentration (µg/m³). NO: NO concentration (µg/m³). NO2: NO2 concentration (µg/m³). CO: NO2 concentration (mg/m³). PM10: Particulate Matter (&lt;10 µg/m³). O3: Ozone concentration (µg/m³). dd: Wind direction (degrees). vv: Wind speed (m/s). TMP: Dry temperature (ºC). HR: Relative humidity (%rh). PRB: Atmospheric pressure (mb). RS: Solar radiation (W/m²). LL: Rainfall (l/m²). BEN: Benzene concentration (µg/m³). TOL: Toluene concentration (µg/m³). MXIL: M-Xylene (µg/m³). PM25: Particulate Matter (&lt;2.5 µg/m³). station_alias: Station alias (new variable). year: Year (new variable). month: Month (new variable). week_day: Week day (new variable). hour: Hour of the day (new variable). date: Date YYYY-MM-DD (new variable). lab: lab = working day / no_lab = no working day. wd: Wind direction in factor format. "],
["visualizations.html", "3 Visualizations", " 3 Visualizations In order to cover the first of the goals in this project, “to construct a web dashboard to visualize the evolution of the main air pollution indicators in the city of Gijón” I chose Tableau software as the main tool. I created a Tableau story for each pollutant with Tableau Desktop (student license). And I published them on my Tableau Public personal site. Each story shows a brief description of each pollutant, the evolution of its levels during the last two decades, the non-compliance with the EU standards or the WHO advice and several visualizations to show its seasonal components. All the stories are saved in the same Tableau workbook. Therefore, in order to access each pollutant dashboard you only have to click on the corresponding tab. The datasets used on these visualizations were prepared with R code. You can consult this code in the section “6 Gathering and Cleaning Data” of this document or in the rmd file “10_Gathering_and_Cleaning_Data” saved in the project Github repository. Tableau Public stories: If you want to consult the published stories on the Tableau site you only have to click on the link below: Gijón Air Pollution The data visualization is a basic but powerful tool for any data science project. So, beyond the Tableau dashboards, I used the graphic visualizations of data for very different purposes ranging from basic data exploration -looking for quality data problems-, to looking for data trends and seasonality or graphically checking the accuracy of a model. Some of these visualizations are included in this document but most of them are embedded in the R and Python code. "],
["forecasting-models.html", "4 Forecasting Models 4.1 PM10 forecasts 4.2 NO2 forecasts", " 4 Forecasting Models “Prediction is very difficult, especially if it’s about the future.” Nils Bohr, Nobel laureate in Physics As I already explained in the Introduction, one of the objectives of this project is to develop forecasting models which allow us to predict the pollution levels in the city of Gijón some hours in advance. Initially, I planned to create forecasting models for every monitoring station. But, as soon as I started work on the models I realized this goal was not very realistic. Therefore, I adjusted the scope of my project to just one station, the Constitución station and to only two pollutants, PM10 and NO2. I chose the Constitución station because it is the only station with published weather data and we focused on these two pollutants because they are the pollutants with the biggest impact on public health. Methodology. We make a first approach to the problem with the ARIMA methodology. Then, with the reference of these results we try to improve the forecasts with machine learning methods. I used R for the ARIMA models and to prepare the training and testing datasets for the Python models. And I used Python, on the Google Colab platform, to create the machine learning methods. All the R and Python scripts are saved in the github repository project: _10_1_train_test_PM10_AR_datasets.rmd _10_2_train_test_PM10_NO2_MULTIVAR_datasets.rmd 12_Forecasting_Models_ARIMA_PM10.rmd 21_Forecasting_Models_ML_PM10_AR.ipynb 22_Forecasting_Models_ML_PM10_MULTIVAR.ipynb 23_Forecasting_Models_ML_NO2_MULTIVAR.ipynb The R scripts are included in this document too, in the R scripts section. The Python notebooks are not included in this document but the links to the original Google Colab notebooks are in the Python scripts section. 4.1 PM10 forecasts ARIMA results “I have seen the future and it is very much like the present, only longer.” Kehlog Albran, The Profit R-markdown file “12_Forecasting_Models_ARIMA_PM10.rmd” The code used for this section is in the rmarkdown file “12_Forecasting_Models_ARIMA_PM10.rmd” You can consult it in the section 8 “Forecasting models. ARIMA” of this document. As a first step I created a very simple model to use as a base reference. This model takes the value from the previous hour as a prediction, forecasting just one hour ahead. Thus, the formula for this base model would be: Xt = Xt-1. Then, I generated three different seasonal (frequency: 24 hours) ARIMA models with three different training periods (the ARIMA model parameters were selected automatically by the auto.arima function from the ‘forecast’ R package). And I applied these three models to the testing period data (2017-01-01 - 2017-09-30) in order to obtain their prediction accuracy scores for the one hour ahead forecast. Finally, I obtained the prediction accuracy scores for the ARIMA with the three years training period for the 6 hours, 12 hours and 24 hours ahead forecasts. In the table below we can see the R-squared and the MAE obtained for each ARIMA model tested for the PM10 pollutant. Table 4.1: ARIMA models results for the PM10 pollutant Model type Prediction horizon Train period R-Squared MAE Model detail Auto regressive (Base model) 1 hour - 0.5327 5.15 PM10t = PM10(t-1) ARIMA 1 hour 201610-201612 0.5975 4.88 ARIMA(2,1,4)(0,0,2)[24] ARIMA 1 hour 201401-201612 0.6015 4.84 ARIMA(2,1,3)(0,0,2)[24] ARIMA 1 hour 200901_201612 0.5966 4.88 ARIMA(3,1,2)(0,0,2)[24] ARIMA 6 hours 201401-201612 0.2118 7.12 ARIMA(2,1,3)(0,0,2)[24] ARIMA 12 hours 201401-201612 0.1108 7.64 ARIMA(2,1,3)(0,0,2)[24] ARIMA 24 hours 201401-201612 0.0138 10.90 ARIMA(2,1,3)(0,0,2)[24] All the MAE and R-Squared showed in all the tables and graphs are from applying the model to the testing period 2017-01-01 - 2017-09-30. We are going to use the MAE (Mean Absolute Error) in order to compare the different models. We chose the MAE over the RMSE (Root Mean Square Error) because it is easier to interpret while also being more robust (less sensitive to outliers). The base model (Xt = Xt-1) explains 53.3% of the variability of the data from the test period (R-squared: 0.5327) and it has a MAE (Mean Absolute Error) of 5.15. And the ARIMA model with the best results is the one with the 3 years training period, which improves the Base model R-squaredin by almost 7 points , explaining 60.15% of the variation in the levels of PM10 (one hour ahead) and reduces the MAE to 4.84. Either way, the differences between the three years training model and the other two are minimal. Three months of training data explains almost the same than three or nine years. We can see this very clearly in the graph below, where we plot the monthly MAE of each model over the testing period. MAE monthly evolution (Testing data. Period 2017-01-01 - 2017-09-30). Forecasting 6, 12 and 24 hours ahead The forecasting accuracy of any model decays as we try to forecast further in the future. Therefore, we used the ARIMA model to forecast PM10 values 6, 12 and 24 hours ahead, and we measured its forecasting precision. We can see the results in the table below. Table 4.2: ARIMA models results for the PM10 pollutant Model type Prediction horizon Train period R-Squared MAE Model detail ARIMA 1 hour 201401-201612 0.6015 4.84 ARIMA(2,1,3)(0,0,2)[24] ARIMA 6 hours 201401-201612 0.2118 7.12 ARIMA(2,1,3)(0,0,2)[24] ARIMA 12 hours 201401-201612 0.1108 7.64 ARIMA(2,1,3)(0,0,2)[24] ARIMA 24 hours 201401-201612 0.0138 10.90 ARIMA(2,1,3)(0,0,2)[24] We plot the data on a graph in order to observe the differences more easily. As we see in the graph the explanatory power of the model decays very quickly as we try to forecast further into the future. In fact, the 24 hours prediction hardly explains anything about the variation of the PM10 levels (although we could probably improve the 24 hours forecasting results by modifying the seasonal elements of the ARIMA model ‘P, D, Q’). Machine Learning results xkcd comic The code used for this section is in following Jupyter notebook files: &quot;21_Forecasting_Models_ML_PM10_AR.ipynb&quot; Google Colab Notebook link “21_Forecasting_Models_ML_PM10_AR.ipynb” “22_Forecasting_Models_ML_PM10_MULTIVAR.ipynb” Google Colab Notebook link “21_Forecasting_Models_ML_PM10_AR.ipynb” “23_Forecasting_Models_ML_NO2_MULTIVAR” Google Colab Notebook link “21_Forecasting_Models_ML_PM10_AR.ipynb” The training, testing and validations dataset were prepared previously with R: Rmarkdown file “10_1_train_test_AR_datasets.rmd” Rmarkdown file “10_2_train_test_PM10_NO2_MULTIVAR_datasets Auto-regressive models In this part we try to emulate the ARIMA results with different auto-regressive machine learning models. So, we are only including lagged values of the target variable as input variables. In this case lagged values of the PM10 pollutant. We used Linear Regression, Random Forests and XGBoost algorithms, achieving the best results with the XGBoost models. (We selected the lagged variables through a Linear Regression model, that is why it appears in the table 4 rows of results, 3 with the 33 initial variables and one with the final 13 variables selected.) Table 4.3: ARIMA models results for the PM10 pollutant Model type Number of variables Prediction horizon Train period R-Squared adjusted MAE Linear regression 33 1 hour 201610-201612 0.5794 4.94 Linear regression 33 1 hour 201401-201612 0.5944 4.82 Linear regression 33 1 hour 200901-201612 0.5880 4.87 Linear regression 13 1 hour 201401-201612 0.5932 4.84 Random Forest Regressor 13 1 hour 201610-201612 0.5724 4.93 Random Forest Regressor 13 1 hour 201401-201612 0.5873 4.90 Random Forest Regressor 13 1 hour 200901-201612 0.5741 5.00 XGBoost 13 1 hour 201610-201612 0.5779 4.92 XGBoost 13 1 hour 201401-201612 0.5970 4.81 XGBoost 13 1 hour 200901-201612 0.5905 4.86 XGBoost 13 6 hours 201401-201612 0.2400 6.93 XGBoost 13 12 hours 201401-201612 0.1474 7.46 XGBoost 13 24 hours 201401-201612 0.0514 7.98 And as with the ARIMA models we got the smallest MAE using the three years period for the training dataset (2014-01-01 - 2016-12-31). Table 4.4: Machine learning models results for the PM10 pollutant Model type Number of variables Prediction horizon Train period R-Squared adjusted MAE Linear regression 13 1 hour 201401-201612 0.5932 4.84 Random Forest Regressor 13 1 hour 201401-201612 0.5873 4.90 XGBoost 13 1 hour 201401-201612 0.5970 4.81 Nevertheless, the results are very similar to the ARIMA ones for the one hour forecasts. But as we increase the forecast horizon the XGBoost obtains better results than the ARIMA model. Multi-variate models And finally, we added other variables to try to improve our forecasting model. In this part we used the XGBoost algorithm exclusively, because so far it is the algorithm which showed the best performance. And for the same reason we will use the three years training period (2014-01-01). We used two different kinds of variables: More lagged values of numerical variables, such as weather measurements or other pollutants levels. Categorical variables related to information about the target that we can anticipate, such as the hour of the day or the type of day (working days versus non-working days). We can see the results in the table below. Table 4.5: ARIMA models results for the PM10 pollutant Model type Prediction horizon Train period R-Squared adjusted MAE XGBoost MV 1 hour 201401-201612 0.6135 4.71 XGBoost MV 6 hours 201401-201612 0.2614 6.76 XGBoost MV 12 hours 201401-201612 0.1556 7.38 XGBoost MV 24 hours 201401-201612 0.0807 7.83 We compare the results of all the models graphically. The XGBoost multivariate models slightly increase the results of the XGBoost auto regressive ones, particularly at the prediction horizon of 24 hours. But in the end, the explanatory power and the errors of the models are very similar. Maybe the contribution from the added variables in the multivariate models are so limited because a big part of this information is already included in the lagged values of the PM10 variable. In order to improve the model, apart from a better feature engineering of the current variables or the inclusion of new lagged variables (for example: lagged values from other monitoring stations) we think the inclusion of weather forecasts would have a great effect on these pollution predictions. We would, thus, be including future conditions that would help to better anticipate PM10 levels (the wind and the rain have a great influence in the accumulation of air pollutants). 4.2 NO2 forecasts For the NO2 forecasts we skip the ARIMA, Linear Regression and Random Forest models to use the XGBoost algorithm directly, which is the one with better results so far. These are the auto regressive XGBoost models results (Testing data scores. Period: 2017-01-01 - 2017-09-30): Table 4.6: XGBoost auto regressive models results for the NO2 pollutant Model type Number of variables Prediction horizon Train period R-Squared adjusted MAE XGBoost 16 1 hour 201401-201612 0.7606 5.88 XGBoost 16 6 hours 201401-201612 0.3932 10.48 XGBoost 16 12 hours 201401-201612 0.3718 10.68 XGBoost 16 24 hours 201401-201612 0.3213 11.08 And these are the results for the XGBoost multivariate models (Testing data scores. Period: 2017-01-01 - 2017-09-30): Table 4.7: XGBoost multivariate models results for the NO2 pollutant Model type Prediction horizon Train period R-Squared adjusted MAE XGBoost MV 1 hour 201401-201612 0.7636 5.72 XGBoost MV 6 hours 201401-201612 0.4174 10.16 XGBoost MV 12 hours 201401-201612 0.4074 10.24 XGBoost MV 24 hours 201401-201612 0.3813 10.42 The differences between the auto regressive and multivariate coincide largely with what we have seen with the PM10 models. The differences are very limited and grow slightly as we increase the prediction horizon. But the most important difference with the previous PM10 models is that the NO2 models make much more precise forecasts in general. And this difference in precission grows as we increase the prediction horizon. We can see this effect very clearly in the next graph. Why these differences? Apart from the possible differences derived from a better or worse variable selection, featuring engineering, etc. we think the key to explain these differences lies on the own behaviour of each variable. Down below we can see the hourly levels of each pollutant during January 2017. We can clearly see how the hourly patterns of the PM10 levels (first grid of graphs)are much more erratic than the NO2 (second grid), which has a very recognisible pattern. The Constitución monitoring station is an urban station, very close to one of the busiest traffic areas in the city of Gijón. Therefore, the most of the NO2 measured at this station comes from the transformation of NO emitted by cars engines. The traffic has a very regular pattern, so it is natural than the NO2 measured by this station follows very clear patterns. Meanwhile, the PM10 levels, although they partly depend on the traffic too, has more variate sources and precursors, such as the industrial plants situated to the west of the city. In short, we are achieving better NO2 forecasts because it is a pollutant which is much easier to forecast than the PM10. "],
["conclusions.html", "5 Conclusions", " 5 Conclusions When I started this project I had two main objectives: 1. To construct and publish a web dashboard so as to visualize the evolution of the main air pollution indicators in the city of Gijón. 2. To build forecasting models in order to predict pollution levels. I think that the first goal of the project could be considered achieved. of the project could be considered achieved. Beyond the possible improvements of the current Tableau visualizations, I think that anyone who visits my Tableau web dashboards can easily get to know the basics on the evolution of air quality in the city of Gijón, namely: What the main pollutants measured by the monitoring stations are. The evolution of the levels of the main pollutants from the year 2000 to 2017 . The compliance or not with the European Union pollutants limits or the guiding levels of the WHO. The basic differences on the levels of pollutants among the 6 monitoring stations. The different patterns and seasonality of the pollutants levels and their variation among the stations. Besides all of this, the final dataset itself can also be consulted in the own Tableau workbook and in Kaggle, where I uploaded it. My objective was to construct a forecasting model which allows to predict hourly levels of pollutants from one to twenty four hours in advance. But the results I reached are far from the precission required to give useful forecasts. Nevertheless, I think it is a very good starting point in order to construct something more complex and precise. Regarding the results of the forecasting models we can mention the following conclusions: The results of the ARIMA models are only slightly worse than those achieved with the auto regressive Machine Learning models applied. But the differences increase as we try to forecast further into the future. In all cases, the best performance of all the algorithms tried was achieved by the XGBoost algorithm. The multivariate models exceed the results of the pure auto regressive models, but the differences are not very big. Maybe the contribution of the new variables is not as large as I expected because a great proportion of the information is already included in the lagged values of the target variable. We could see how the NO2 and the PM10 forecasting problems are very different tasks, at least on levels of complexity. The hourly levels of PM10 pollutant are much harder to forecast than the NO2 ones. Next steps: This is a work in progress. And my intention is to keep on working on this project with the objective of increasing the precission of my forecasts. And once I get good quality forecasts to put them in production (Example: via a Twitter bot). For this goal I have to do several things, such as: Test the inclusion of new variables in the models (Example: lagged values of variables from other nearby monitoring stations). Better featuring engineering. Try to transform current variables to improve their contribution in the models (Example: new variable which gives the number of days in a row without rain). To add weather forecasts to the models as input variables. To use different algorithms / methods (Example: use curves clustering for time series analysis with deep learning algorithms). To improve the quality of my R and Python code and remove repetition via functional programming. "],
["r-scripts.html", "R scripts", " R scripts I appended in the next three chapters the following R scripts: 10_Gathering_and_Cleaning_Data.rmd 11_Data_Exploration.rmd 12_Forecasting_Models_ARIMA_PM10.rmd "],
["gathering-and-cleaning-data.html", "6 Gathering and Cleaning Data 6.1 Data gathering 6.2 Data cleaning 6.3 Adding new variables", " 6 Gathering and Cleaning Data 6.1 Data gathering Loading packages library(readr) library(dplyr) library(tidyr) library(purrr) library(lubridate) library(ggplot2) library(stringr) library(knitr) library(xts) library(zoo) library(gridExtra) library(fpp2) library(RcppRoll) library(kableExtra) options(knitr.table.format = &quot;html&quot;) First of all I have to check if I will have the basic data to make the analysis. I need air pollution and weather data of the Gijon area. The town hall of Gijon has an open data web portal here https://transparencia.gijon.es/. We can download pollution air data on csv format from year 2000 to 2017 here: I downloaded 18 csv files with air pollution and weather data of Gijon from years 2000 to 2017. I saved them in the “data” folder. I downloaded two more files from this web, a csv file with the description of the variables and another csv file with information about the measurement stations. We take a look to the information included in the stations_info.csv file. It includes the stations addresses, longitude, latitude and their IDs and names. All this information, as we will see, is included in the csv files with pollution and weather data too. So, we are not going to use this file anymore. stations &lt;- read_delim(&#39;data/stations_info.csv&#39;, delim = &#39;;&#39;, escape_double = FALSE, trim_ws = TRUE, locale = locale(encoding = &quot;ISO-8859-1&quot;), col_types = cols(.default = &quot;c&quot;)) stations ## # A tibble: 6 x 6 ## `&quot;ID;&quot;&quot;Título&quot;&quot;` `&quot;&quot;Dirección&quot;&quot;` `&quot;&quot;Población&quot;&quot;` `&quot;&quot;Provincia&quot;&quot;` ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 &quot;\\&quot;1;\\&quot;\\&quot;Consti~ &quot;\\&quot;\\&quot;Avda. Con~ &quot;\\&quot;\\&quot;Gijón\\&quot;\\&quot;&quot; &quot;\\&quot;\\&quot;Asturias\\~ ## 2 &quot;\\&quot;2;\\&quot;\\&quot;Argent~ &quot;\\&quot;\\&quot;Avda. Arg~ &quot;\\&quot;\\&quot;Gijón\\&quot;\\&quot;&quot; &quot;\\&quot;\\&quot;Asturias\\~ ## 3 &quot;\\&quot;3;\\&quot;\\&quot;H. Fel~ &quot;\\&quot;\\&quot;H. Felgue~ &quot;\\&quot;\\&quot;Gijón\\&quot;\\&quot;&quot; &quot;\\&quot;\\&quot;Asturias\\~ ## 4 &quot;\\&quot;4;\\&quot;\\&quot;Castil~ &quot;\\&quot;\\&quot;Plaza Cas~ &quot;\\&quot;\\&quot;Gijón\\&quot;\\&quot;&quot; &quot;\\&quot;\\&quot;Asturias\\~ ## 5 &quot;\\&quot;10;\\&quot;\\&quot;Monte~ &quot;\\&quot;\\&quot;Montevil\\~ &quot;\\&quot;\\&quot;Gijón\\&quot;\\&quot;&quot; &quot;\\&quot;\\&quot;Asturias\\~ ## 6 &quot;\\&quot;11;\\&quot;\\&quot;Santa~ &quot;\\&quot;\\&quot;Santa Bár~ &quot;\\&quot;\\&quot;Gijón\\&quot;\\&quot;&quot; &quot;\\&quot;\\&quot;Asturias\\~ ## # ... with 2 more variables: `&quot;&quot;latitud&quot;&quot;` &lt;chr&gt;, `&quot;&quot;longitud&quot;&quot;&quot;,,` &lt;chr&gt; We can see on this image the location of each station. http://movil.asturias.es/medioambiente/articulos/ficheros/Informe%20de%20calidad%20del%20aire%20en%20Asturias%202016.pdf Image source: “Informe de calidad del aire del Principado de Asturias (2016)”. The air_data_descriptors.csv file contains information about the nature of the elements monitored by the stations. Names, descriptions and units. variables &lt;- read_csv(&#39;data/air_data_descriptors.csv&#39;, locale = locale(encoding = &quot;ISO-8859-1&quot;)) variables ## # A tibble: 17 x 4 ## Parametro `Descripción Parámetro` TAG Unidad ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 BEN Benceno BEN µg/m³ ## 2 CO Concentracion de CO CO mg/m³ ## 3 DD Direccion del viento DD Grados ## 4 HR Humedad relativa HR %hr ## 5 LL Precipitacion LL l/m² ## 6 MXIL MXileno MXIL µg/m³ ## 7 NO Concentracion de NO NO µg/m³ ## 8 NO2 Concentracion de NO2 NO2 µg/m³ ## 9 O3 Concentracion de Ozono O3 µg/m³ ## 10 PM10 Particulas en suspension &lt;10 µg/m³ PM10 µg/m³ ## 11 PM25 Particulas en Suspension PM 2,5 PM25 µg/m³ ## 12 PRB Presion Atmosferica PRB mb ## 13 RS Radiacion Solar RS W/m² ## 14 SO2 Concentracion de SO2 SO2 µg/m³ ## 15 TMP Temperatura Seca TMP ºC ## 16 TOL Tolueno TOL µg/m³ ## 17 VV Velocidad del viento VV m/s In order to import the data from the 18 csv files we list all the files in the object data_files. data_files &lt;- list.files(path = &quot;data&quot;, pattern = &quot;air_data_20*&quot;) Then, we map the function read_csv on this list in order to import every file and finally merge them in a unique dataframe (air_data_0) with reduce(rbind). air_data_0 &lt;- data_files %&gt;% map(function(x) { read_csv(paste0(&quot;./data/&quot;, x), locale = locale(encoding = &quot;ISO-8859-1&quot;), col_types = cols(.default = &quot;c&quot;)) }) %&gt;% reduce(rbind) We take a look to the dataset glimpse(air_data_0) ## Observations: 722,774 ## Variables: 22 ## $ Estación &lt;chr&gt; &quot;1&quot;, &quot;1&quot;, &quot;1&quot;, &quot;1&quot;, &quot;1&quot;, &quot;1&quot;, &quot;1&quot;, &quot;1&quot;, &quot;1... ## $ Título &lt;chr&gt; &quot;Estación Avenida Constitución&quot;, &quot;Estación... ## $ latitud &lt;chr&gt; &quot;43.529806&quot;, &quot;43.529806&quot;, &quot;43.529806&quot;, &quot;43... ## $ longitud &lt;chr&gt; &quot;-5.673428&quot;, &quot;-5.673428&quot;, &quot;-5.673428&quot;, &quot;-5... ## $ `Fecha Solar (UTC)` &lt;chr&gt; &quot;2000-01-01T00:00:00&quot;, &quot;2000-01-01T01:00:0... ## $ SO2 &lt;chr&gt; &quot;23&quot;, &quot;29&quot;, &quot;40&quot;, &quot;50&quot;, &quot;39&quot;, &quot;39&quot;, &quot;40&quot;, ... ## $ NO &lt;chr&gt; &quot;89&quot;, &quot;73&quot;, &quot;53&quot;, &quot;46&quot;, &quot;35&quot;, &quot;26&quot;, &quot;27&quot;, ... ## $ NO2 &lt;chr&gt; &quot;65&quot;, &quot;60&quot;, &quot;57&quot;, &quot;53&quot;, &quot;50&quot;, &quot;49&quot;, &quot;51&quot;, ... ## $ CO &lt;chr&gt; &quot;1.97&quot;, &quot;1.61&quot;, &quot;1.13&quot;, &quot;1.06&quot;, &quot;0.95&quot;, &quot;0... ## $ PM10 &lt;chr&gt; &quot;53&quot;, &quot;63&quot;, &quot;56&quot;, &quot;58&quot;, &quot;50&quot;, &quot;50&quot;, &quot;57&quot;, ... ## $ O3 &lt;chr&gt; &quot;9&quot;, &quot;8&quot;, &quot;7&quot;, &quot;5&quot;, &quot;6&quot;, &quot;7&quot;, &quot;7&quot;, &quot;4&quot;, &quot;5... ## $ dd &lt;chr&gt; &quot;245&quot;, &quot;222&quot;, &quot;228&quot;, &quot;239&quot;, &quot;244&quot;, &quot;218&quot;, ... ## $ vv &lt;chr&gt; &quot;0.34&quot;, &quot;1.06&quot;, &quot;0.71&quot;, &quot;0.84&quot;, &quot;0.89&quot;, &quot;0... ## $ TMP &lt;chr&gt; &quot;5.7&quot;, &quot;5.4&quot;, &quot;5.3&quot;, &quot;5.1&quot;, &quot;4.6&quot;, &quot;4.6&quot;, ... ## $ HR &lt;chr&gt; &quot;76&quot;, &quot;73&quot;, &quot;72&quot;, &quot;71&quot;, &quot;72&quot;, &quot;69&quot;, &quot;68&quot;, ... ## $ PRB &lt;chr&gt; &quot;1026&quot;, &quot;1025&quot;, &quot;1025&quot;, &quot;1025&quot;, &quot;1024&quot;, &quot;1... ## $ RS &lt;chr&gt; &quot;33&quot;, &quot;33&quot;, &quot;33&quot;, &quot;33&quot;, &quot;33&quot;, &quot;33&quot;, &quot;33&quot;, ... ## $ LL &lt;chr&gt; &quot;0&quot;, &quot;0&quot;, &quot;0&quot;, &quot;0&quot;, &quot;0&quot;, &quot;0&quot;, &quot;0&quot;, &quot;0&quot;, &quot;0... ## $ BEN &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA... ## $ TOL &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA... ## $ MXIL &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA... ## $ PM25 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA... We change some variables names. # Variables names changing air_data_1 &lt;- air_data_0 %&gt;% rename(station = &#39;Estación&#39;, station_name = &#39;Título&#39;, date_time_utc = &#39;Fecha Solar (UTC)&#39;, latitude = latitud, longitude = longitud, wd = dd, ws = vv) 6.2 Data cleaning We imported all the columns as characters in order to avoid problems with the format attributions. So, we have to make now some format variable changes. We change the date_time_utc format from character to date time. air_data_1$date_time_utc &lt;- ymd_hms(air_data_1$date_time_utc) We change the station and station_name formats from character to factor. air_data_1$station &lt;- as.factor(air_data_1$station) air_data_1$station_name &lt;- as.factor(air_data_1$station_name) We create a vector with all the variables we want to be numeric num &lt;- colnames(air_data_1)[c(3, 4, 6:22)] We make the conversion of this set of variables to numeric air_data_1 &lt;- air_data_1 %&gt;% mutate_at(num, as.numeric) We create a dictionary with an alias for each station in order to add a new variable with more convenient station names alias_dict &lt;- data.frame( station = c(&quot;1&quot;, &quot;2&quot;, &quot;3&quot;, &quot;4&quot;, &quot;10&quot;, &quot;11&quot;), station_alias = c(&quot;Constitucion&quot;, &quot;Argentina&quot;, &quot;H. Felgueroso&quot;, &quot;Castilla&quot;, &quot;Montevil&quot;, &quot;Santa Barbara&quot;) ) We join the alias dictionary to the air_data_1 data frame to add the new variable to the data set. air_data_1 &lt;- air_data_1 %&gt;% left_join(alias_dict, by = &#39;station&#39;) We call the summary function to inspect the data main indicators summary(air_data_1) ## station station_name latitude ## 1 :157727 Estación Avenida Argentina :157798 Min. :43.52 ## 10: 74630 Estación Avenida Castilla :157409 1st Qu.:43.53 ## 11: 17544 Estación Avenida Constitución :157727 Median :43.54 ## 2 :157798 Estación Avenida Hermanos Felgueroso:157666 Mean :43.53 ## 3 :157666 Estación de Montevil : 74630 3rd Qu.:43.54 ## 4 :157409 Estación Santa Bárbara : 17544 Max. :43.54 ## ## longitude date_time_utc SO2 ## Min. :-5.699 Min. :2000-01-01 00:00:00 Min. :-9999.00 ## 1st Qu.:-5.673 1st Qu.:2005-02-25 05:00:00 1st Qu.: 4.00 ## Median :-5.672 Median :2010-02-23 11:00:00 Median : 6.00 ## Mean :-5.670 Mean :2009-09-06 07:33:13 Mean : 9.77 ## 3rd Qu.:-5.658 3rd Qu.:2014-04-09 06:00:00 3rd Qu.: 11.00 ## Max. :-5.646 Max. :2018-01-01 00:00:00 Max. : 2662.00 ## NA&#39;s :33742 ## NO NO2 CO PM10 ## Min. :-9999.00 Min. :-9999.00 Min. : 0.00 Min. :-9999.00 ## 1st Qu.: 4.40 1st Qu.: 16.00 1st Qu.: 0.22 1st Qu.: 19.00 ## Median : 10.00 Median : 28.00 Median : 0.36 Median : 30.00 ## Mean : 21.37 Mean : 32.04 Mean : 0.49 Mean : 35.88 ## 3rd Qu.: 23.00 3rd Qu.: 45.00 3rd Qu.: 0.59 3rd Qu.: 46.00 ## Max. : 1248.00 Max. : 1003.20 Max. :58.20 Max. : 1000.00 ## NA&#39;s :16989 NA&#39;s :16446 NA&#39;s :90390 NA&#39;s :88598 ## O3 wd ws TMP ## Min. :-9999.00 Min. : 0.0 Min. : 0.0 Min. :-40.0 ## 1st Qu.: 17.00 1st Qu.: 96.0 1st Qu.: 0.2 1st Qu.: 10.9 ## Median : 37.00 Median :159.0 Median : 0.7 Median : 14.7 ## Mean : 38.97 Mean :161.8 Mean : 1.0 Mean : 14.6 ## 3rd Qu.: 57.00 3rd Qu.:228.0 3rd Qu.: 1.5 3rd Qu.: 18.4 ## Max. : 998.00 Max. :360.0 Max. :29.8 Max. : 47.4 ## NA&#39;s :31417 NA&#39;s :494134 NA&#39;s :493893 NA&#39;s :494151 ## HR PRB RS LL ## Min. : 0.0 Min. : 800 Min. : -1.0 Min. : 0.0 ## 1st Qu.: 69.0 1st Qu.:1007 1st Qu.: 17.0 1st Qu.: 0.0 ## Median : 80.0 Median :1013 Median : 46.0 Median : 0.0 ## Mean : 78.3 Mean :1012 Mean : 125.2 Mean : 0.1 ## 3rd Qu.: 89.0 3rd Qu.:1018 3rd Qu.: 149.0 3rd Qu.: 0.0 ## Max. :123.0 Max. :1282 Max. :1470.0 Max. :24.6 ## NA&#39;s :494176 NA&#39;s :494019 NA&#39;s :494273 NA&#39;s :494124 ## BEN TOL MXIL PM25 ## Min. : 0.0 Min. : -0.2 Min. : -0.3 Min. : 0.0 ## 1st Qu.: 0.1 1st Qu.: 0.4 1st Qu.: 0.2 1st Qu.: 5.0 ## Median : 0.3 Median : 1.0 Median : 0.3 Median : 9.0 ## Mean : 0.5 Mean : 2.5 Mean : 1.3 Mean : 11.3 ## 3rd Qu.: 0.5 3rd Qu.: 2.5 3rd Qu.: 0.9 3rd Qu.: 15.0 ## Max. :22.5 Max. :196.0 Max. :220.0 Max. :947.0 ## NA&#39;s :629358 NA&#39;s :629380 NA&#39;s :635123 NA&#39;s :554185 ## station_alias ## Argentina :157798 ## Castilla :157409 ## Constitucion :157727 ## H. Felgueroso:157666 ## Montevil : 74630 ## Santa Barbara: 17544 ## There are several variables which minimun values are -9999. kable(air_data_1 %&gt;% filter(SO2 == -9999 | NO == -9999 | NO2 == -9999 | PM10 == -9999 | O3 == -9999 )) %&gt;% kable_styling() station station_name latitude longitude date_time_utc SO2 NO NO2 CO PM10 O3 wd ws TMP HR PRB RS LL BEN TOL MXIL PM25 station_alias 3 Estación Avenida Hermanos Felgueroso 43.53506 -5.658123 2000-01-27 00:00:00 -9999 -9999 -9999 0 -9999 -9999 NA NA NA NA NA NA NA NA NA NA NA H. Felgueroso 3 Estación Avenida Hermanos Felgueroso 43.53506 -5.658123 2000-01-27 01:00:00 -9999 -9999 -9999 0 -9999 -9999 NA NA NA NA NA NA NA NA NA NA NA H. Felgueroso 3 Estación Avenida Hermanos Felgueroso 43.53506 -5.658123 2000-01-27 02:00:00 -9999 -9999 -9999 0 -9999 -9999 NA NA NA NA NA NA NA NA NA NA NA H. Felgueroso 3 Estación Avenida Hermanos Felgueroso 43.53506 -5.658123 2000-01-27 03:00:00 -9999 -9999 -9999 0 -9999 -9999 NA NA NA NA NA NA NA NA NA NA NA H. Felgueroso 3 Estación Avenida Hermanos Felgueroso 43.53506 -5.658123 2000-01-27 04:00:00 -9999 -9999 -9999 0 -9999 -9999 NA NA NA NA NA NA NA NA NA NA NA H. Felgueroso 3 Estación Avenida Hermanos Felgueroso 43.53506 -5.658123 2000-01-27 05:00:00 -9999 -9999 -9999 0 -9999 -9999 NA NA NA NA NA NA NA NA NA NA NA H. Felgueroso 3 Estación Avenida Hermanos Felgueroso 43.53506 -5.658123 2000-01-27 06:00:00 -9999 -9999 -9999 0 -9999 -9999 NA NA NA NA NA NA NA NA NA NA NA H. Felgueroso 3 Estación Avenida Hermanos Felgueroso 43.53506 -5.658123 2000-01-27 07:00:00 -9999 -9999 -9999 0 -9999 -9999 NA NA NA NA NA NA NA NA NA NA NA H. Felgueroso 3 Estación Avenida Hermanos Felgueroso 43.53506 -5.658123 2000-01-27 08:00:00 -9999 -9999 -9999 0 -9999 -9999 NA NA NA NA NA NA NA NA NA NA NA H. Felgueroso 3 Estación Avenida Hermanos Felgueroso 43.53506 -5.658123 2000-01-27 09:00:00 -9999 -9999 -9999 0 -9999 -9999 NA NA NA NA NA NA NA NA NA NA NA H. Felgueroso 3 Estación Avenida Hermanos Felgueroso 43.53506 -5.658123 2000-01-27 10:00:00 -9999 -9999 -9999 0 -9999 -9999 NA NA NA NA NA NA NA NA NA NA NA H. Felgueroso 3 Estación Avenida Hermanos Felgueroso 43.53506 -5.658123 2000-01-27 11:00:00 -9999 -9999 -9999 0 -9999 -9999 NA NA NA NA NA NA NA NA NA NA NA H. Felgueroso 3 Estación Avenida Hermanos Felgueroso 43.53506 -5.658123 2000-01-27 12:00:00 -9999 -9999 -9999 0 -9999 -9999 NA NA NA NA NA NA NA NA NA NA NA H. Felgueroso 3 Estación Avenida Hermanos Felgueroso 43.53506 -5.658123 2000-01-27 13:00:00 -9999 -9999 -9999 0 -9999 -9999 NA NA NA NA NA NA NA NA NA NA NA H. Felgueroso 3 Estación Avenida Hermanos Felgueroso 43.53506 -5.658123 2000-01-27 14:00:00 -9999 -9999 -9999 0 -9999 -9999 NA NA NA NA NA NA NA NA NA NA NA H. Felgueroso 3 Estación Avenida Hermanos Felgueroso 43.53506 -5.658123 2000-01-27 15:00:00 -9999 -9999 -9999 0 -9999 -9999 NA NA NA NA NA NA NA NA NA NA NA H. Felgueroso 3 Estación Avenida Hermanos Felgueroso 43.53506 -5.658123 2000-01-27 16:00:00 -9999 -9999 -9999 0 -9999 -9999 NA NA NA NA NA NA NA NA NA NA NA H. Felgueroso 3 Estación Avenida Hermanos Felgueroso 43.53506 -5.658123 2000-01-27 17:00:00 -9999 -9999 -9999 0 -9999 -9999 NA NA NA NA NA NA NA NA NA NA NA H. Felgueroso 3 Estación Avenida Hermanos Felgueroso 43.53506 -5.658123 2000-01-27 18:00:00 -9999 -9999 -9999 0 -9999 -9999 NA NA NA NA NA NA NA NA NA NA NA H. Felgueroso 3 Estación Avenida Hermanos Felgueroso 43.53506 -5.658123 2000-01-27 19:00:00 -9999 -9999 -9999 0 -9999 -9999 NA NA NA NA NA NA NA NA NA NA NA H. Felgueroso 3 Estación Avenida Hermanos Felgueroso 43.53506 -5.658123 2000-01-27 20:00:00 -9999 -9999 -9999 0 -9999 -9999 NA NA NA NA NA NA NA NA NA NA NA H. Felgueroso 3 Estación Avenida Hermanos Felgueroso 43.53506 -5.658123 2000-01-27 21:00:00 -9999 -9999 -9999 0 -9999 -9999 NA NA NA NA NA NA NA NA NA NA NA H. Felgueroso 3 Estación Avenida Hermanos Felgueroso 43.53506 -5.658123 2000-01-27 22:00:00 -9999 -9999 -9999 0 -9999 -9999 NA NA NA NA NA NA NA NA NA NA NA H. Felgueroso 3 Estación Avenida Hermanos Felgueroso 43.53506 -5.658123 2000-01-27 23:00:00 -9999 -9999 -9999 0 -9999 -9999 NA NA NA NA NA NA NA NA NA NA NA H. Felgueroso They are all from the same day (2000-01-27) and from the same station (‘H. Felgueroso’). We replace these values by NAs. air_data_2 &lt;- air_data_1 %&gt;% mutate(SO2 = replace(SO2, SO2 == -9999, NA), NO = replace(NO, NO == -9999, NA), NO2 = replace(NO2, NO2 == -9999, NA), PM10 = replace(PM10, PM10 == -9999, NA), O3 = replace(O3, O3 == -9999, NA)) We check again the output of the summary function. summary(air_data_2) ## station station_name latitude ## 1 :157727 Estación Avenida Argentina :157798 Min. :43.52 ## 10: 74630 Estación Avenida Castilla :157409 1st Qu.:43.53 ## 11: 17544 Estación Avenida Constitución :157727 Median :43.54 ## 2 :157798 Estación Avenida Hermanos Felgueroso:157666 Mean :43.53 ## 3 :157666 Estación de Montevil : 74630 3rd Qu.:43.54 ## 4 :157409 Estación Santa Bárbara : 17544 Max. :43.54 ## ## longitude date_time_utc SO2 ## Min. :-5.699 Min. :2000-01-01 00:00:00 Min. : -2.00 ## 1st Qu.:-5.673 1st Qu.:2005-02-25 05:00:00 1st Qu.: 4.00 ## Median :-5.672 Median :2010-02-23 11:00:00 Median : 6.00 ## Mean :-5.670 Mean :2009-09-06 07:33:13 Mean : 10.12 ## 3rd Qu.:-5.658 3rd Qu.:2014-04-09 06:00:00 3rd Qu.: 11.00 ## Max. :-5.646 Max. :2018-01-01 00:00:00 Max. :2662.00 ## NA&#39;s :33766 ## NO NO2 CO PM10 ## Min. : 0.00 Min. : 0.00 Min. : 0.00 Min. : 0.00 ## 1st Qu.: 4.40 1st Qu.: 16.00 1st Qu.: 0.22 1st Qu.: 19.00 ## Median : 10.00 Median : 28.00 Median : 0.36 Median : 30.00 ## Mean : 21.71 Mean : 32.38 Mean : 0.49 Mean : 36.26 ## 3rd Qu.: 23.00 3rd Qu.: 45.00 3rd Qu.: 0.59 3rd Qu.: 46.00 ## Max. :1248.00 Max. :1003.20 Max. :58.20 Max. :1000.00 ## NA&#39;s :17013 NA&#39;s :16470 NA&#39;s :90390 NA&#39;s :88622 ## O3 wd ws TMP ## Min. : 0.00 Min. : 0.0 Min. : 0.0 Min. :-40.0 ## 1st Qu.: 17.00 1st Qu.: 96.0 1st Qu.: 0.2 1st Qu.: 10.9 ## Median : 37.00 Median :159.0 Median : 0.7 Median : 14.7 ## Mean : 39.32 Mean :161.8 Mean : 1.0 Mean : 14.6 ## 3rd Qu.: 57.00 3rd Qu.:228.0 3rd Qu.: 1.5 3rd Qu.: 18.4 ## Max. :998.00 Max. :360.0 Max. :29.8 Max. : 47.4 ## NA&#39;s :31441 NA&#39;s :494134 NA&#39;s :493893 NA&#39;s :494151 ## HR PRB RS LL ## Min. : 0.0 Min. : 800 Min. : -1.0 Min. : 0.0 ## 1st Qu.: 69.0 1st Qu.:1007 1st Qu.: 17.0 1st Qu.: 0.0 ## Median : 80.0 Median :1013 Median : 46.0 Median : 0.0 ## Mean : 78.3 Mean :1012 Mean : 125.2 Mean : 0.1 ## 3rd Qu.: 89.0 3rd Qu.:1018 3rd Qu.: 149.0 3rd Qu.: 0.0 ## Max. :123.0 Max. :1282 Max. :1470.0 Max. :24.6 ## NA&#39;s :494176 NA&#39;s :494019 NA&#39;s :494273 NA&#39;s :494124 ## BEN TOL MXIL PM25 ## Min. : 0.0 Min. : -0.2 Min. : -0.3 Min. : 0.0 ## 1st Qu.: 0.1 1st Qu.: 0.4 1st Qu.: 0.2 1st Qu.: 5.0 ## Median : 0.3 Median : 1.0 Median : 0.3 Median : 9.0 ## Mean : 0.5 Mean : 2.5 Mean : 1.3 Mean : 11.3 ## 3rd Qu.: 0.5 3rd Qu.: 2.5 3rd Qu.: 0.9 3rd Qu.: 15.0 ## Max. :22.5 Max. :196.0 Max. :220.0 Max. :947.0 ## NA&#39;s :629358 NA&#39;s :629380 NA&#39;s :635123 NA&#39;s :554185 ## station_alias ## Argentina :157798 ## Castilla :157409 ## Constitucion :157727 ## H. Felgueroso:157666 ## Montevil : 74630 ## Santa Barbara: 17544 ## Some pollutant variables have as minimum negative values. It does not make much sense. We take a look to the data in order to quantify the problem. 30 SO2 observations between 2015-12-25 and 2015-12-28 from the Montevil station: (neg_SO2 &lt;- air_data_2 %&gt;% filter(SO2 &lt; 0) %&gt;% summarise(n = n())) ## # A tibble: 1 x 1 ## n ## &lt;int&gt; ## 1 30 2 RS observations from the Constitucion station: (neg_RS &lt;- air_data_2 %&gt;% filter(RS &lt; 0) %&gt;% summarise(n = n())) ## # A tibble: 1 x 1 ## n ## &lt;int&gt; ## 1 2 27 TOL observations between the 2008-12-11 and the 2008-12-15 from the Constitucion station: (neg_TOL &lt;- air_data_2 %&gt;% filter(TOL &lt; 0) %&gt;% summarise(n = n())) ## # A tibble: 1 x 1 ## n ## &lt;int&gt; ## 1 27 59 MXIL observations between the 2008-12-10 and the 2008-12-15 from the Constitucion station: (neg_MXIL &lt;- air_data_2 %&gt;% filter(MXIL &lt; 0) %&gt;% summarise(n = n())) ## # A tibble: 1 x 1 ## n ## &lt;int&gt; ## 1 59 There are not many cases. We replace them all by NAs and call again the summary function. air_data_2 &lt;- air_data_2 %&gt;% mutate(SO2 = replace(SO2, SO2 &lt; 0, NA), RS = replace(RS, RS &lt; 0, NA), TOL = replace(TOL, TOL &lt; 0, NA), MXIL = replace(MXIL, MXIL &lt; 0, NA)) summary(air_data_2) ## station station_name latitude ## 1 :157727 Estación Avenida Argentina :157798 Min. :43.52 ## 10: 74630 Estación Avenida Castilla :157409 1st Qu.:43.53 ## 11: 17544 Estación Avenida Constitución :157727 Median :43.54 ## 2 :157798 Estación Avenida Hermanos Felgueroso:157666 Mean :43.53 ## 3 :157666 Estación de Montevil : 74630 3rd Qu.:43.54 ## 4 :157409 Estación Santa Bárbara : 17544 Max. :43.54 ## ## longitude date_time_utc SO2 ## Min. :-5.699 Min. :2000-01-01 00:00:00 Min. : 0.00 ## 1st Qu.:-5.673 1st Qu.:2005-02-25 05:00:00 1st Qu.: 4.00 ## Median :-5.672 Median :2010-02-23 11:00:00 Median : 6.00 ## Mean :-5.670 Mean :2009-09-06 07:33:13 Mean : 10.12 ## 3rd Qu.:-5.658 3rd Qu.:2014-04-09 06:00:00 3rd Qu.: 11.00 ## Max. :-5.646 Max. :2018-01-01 00:00:00 Max. :2662.00 ## NA&#39;s :33796 ## NO NO2 CO PM10 ## Min. : 0.00 Min. : 0.00 Min. : 0.00 Min. : 0.00 ## 1st Qu.: 4.40 1st Qu.: 16.00 1st Qu.: 0.22 1st Qu.: 19.00 ## Median : 10.00 Median : 28.00 Median : 0.36 Median : 30.00 ## Mean : 21.71 Mean : 32.38 Mean : 0.49 Mean : 36.26 ## 3rd Qu.: 23.00 3rd Qu.: 45.00 3rd Qu.: 0.59 3rd Qu.: 46.00 ## Max. :1248.00 Max. :1003.20 Max. :58.20 Max. :1000.00 ## NA&#39;s :17013 NA&#39;s :16470 NA&#39;s :90390 NA&#39;s :88622 ## O3 wd ws TMP ## Min. : 0.00 Min. : 0.0 Min. : 0.0 Min. :-40.0 ## 1st Qu.: 17.00 1st Qu.: 96.0 1st Qu.: 0.2 1st Qu.: 10.9 ## Median : 37.00 Median :159.0 Median : 0.7 Median : 14.7 ## Mean : 39.32 Mean :161.8 Mean : 1.0 Mean : 14.6 ## 3rd Qu.: 57.00 3rd Qu.:228.0 3rd Qu.: 1.5 3rd Qu.: 18.4 ## Max. :998.00 Max. :360.0 Max. :29.8 Max. : 47.4 ## NA&#39;s :31441 NA&#39;s :494134 NA&#39;s :493893 NA&#39;s :494151 ## HR PRB RS LL ## Min. : 0.0 Min. : 800 Min. : 0.0 Min. : 0.0 ## 1st Qu.: 69.0 1st Qu.:1007 1st Qu.: 17.0 1st Qu.: 0.0 ## Median : 80.0 Median :1013 Median : 46.0 Median : 0.0 ## Mean : 78.3 Mean :1012 Mean : 125.2 Mean : 0.1 ## 3rd Qu.: 89.0 3rd Qu.:1018 3rd Qu.: 149.0 3rd Qu.: 0.0 ## Max. :123.0 Max. :1282 Max. :1470.0 Max. :24.6 ## NA&#39;s :494176 NA&#39;s :494019 NA&#39;s :494275 NA&#39;s :494124 ## BEN TOL MXIL PM25 ## Min. : 0.0 Min. : 0.0 Min. : 0.0 Min. : 0.0 ## 1st Qu.: 0.1 1st Qu.: 0.4 1st Qu.: 0.2 1st Qu.: 5.0 ## Median : 0.3 Median : 1.0 Median : 0.3 Median : 9.0 ## Mean : 0.5 Mean : 2.5 Mean : 1.3 Mean : 11.3 ## 3rd Qu.: 0.5 3rd Qu.: 2.5 3rd Qu.: 0.9 3rd Qu.: 15.0 ## Max. :22.5 Max. :196.0 Max. :220.0 Max. :947.0 ## NA&#39;s :629358 NA&#39;s :629407 NA&#39;s :635182 NA&#39;s :554185 ## station_alias ## Argentina :157798 ## Castilla :157409 ## Constitucion :157727 ## H. Felgueroso:157666 ## Montevil : 74630 ## Santa Barbara: 17544 ## We take a look to the data completeness. What proportion of nas do we have by variable, station, year, etc? data_completeness &lt;- air_data_2 %&gt;% group_by(station_alias, year = year(date_time_utc)) %&gt;% summarise_all(funs(round(sum(!is.na(.))/n(), 2))) %&gt;% # We obtain the proportion of &#39;not NAs&#39; select(-c(3:7, 25:28)) # These columns do not have any na. We exclude them. head(data_completeness, 10) %&gt;% kable() %&gt;% kable_styling() station_alias year SO2 NO NO2 CO PM10 O3 wd ws TMP HR PRB RS LL BEN TOL MXIL PM25 Argentina 2000 0.99 0.97 0.97 0.96 0.94 0.97 0 0 0 0 0 0 0 0 0 0 0 Argentina 2001 0.99 0.99 0.99 0.98 0.97 0.99 0 0 0 0 0 0 0 0 0 0 0 Argentina 2002 1.00 0.99 0.99 0.99 0.99 1.00 0 0 0 0 0 0 0 0 0 0 0 Argentina 2003 0.99 0.98 0.98 0.98 0.99 0.99 0 0 0 0 0 0 0 0 0 0 0 Argentina 2004 0.98 0.96 0.97 0.99 1.00 1.00 0 0 0 0 0 0 0 0 0 0 0 Argentina 2005 0.98 0.96 0.98 1.00 1.00 1.00 0 0 0 0 0 0 0 0 0 0 0 Argentina 2006 0.92 0.90 0.92 0.92 0.93 0.93 0 0 0 0 0 0 0 0 0 0 0 Argentina 2007 0.98 0.99 0.99 0.98 0.99 0.99 0 0 0 0 0 0 0 0 0 0 0 Argentina 2008 0.98 0.96 0.98 0.97 0.98 0.98 0 0 0 0 0 0 0 0 0 0 0 Argentina 2009 1.00 1.00 1.00 0.98 1.00 1.00 0 0 0 0 0 0 0 0 0 0 0 We are going to check the data completeness by station: Constitución: There is data registered from the variables SO2, NO, NO2, CO, PM10, 03, dd, vv, TMP, HR, PRB, HS and LL since the year 2000. There are measurements of the variables BEN, TOL and MXIL since the year 2006 (only 0.01% ). The PM25 particles are monitored since the year 2008 (2008: only covered 0,02% of the year). During the year 2008 the completeness of several variables (HR, PRB, HS, LL, BEN, TOL y MXIL) decrease until 88% (to do: check there was not caused by a data importing problem.) constitucion_data &lt;- data_completeness %&gt;% filter(station_alias == &#39;Constitucion&#39;) constitucion_data %&gt;% kable() %&gt;% kable_styling() station_alias year SO2 NO NO2 CO PM10 O3 wd ws TMP HR PRB RS LL BEN TOL MXIL PM25 Constitucion 2000 0.97 0.95 0.95 0.97 0.92 0.93 0.96 0.98 0.96 0.95 0.97 0.95 0.96 0.00 0.00 0.00 0.00 Constitucion 2001 0.99 0.99 0.99 0.98 0.99 0.99 1.00 1.00 1.00 0.99 1.00 1.00 1.00 0.00 0.00 0.00 0.00 Constitucion 2002 1.00 1.00 1.00 0.99 0.99 0.99 1.00 1.00 1.00 1.00 1.00 1.00 1.00 0.00 0.00 0.00 0.00 Constitucion 2003 0.99 0.99 0.99 0.98 0.99 0.99 0.99 0.99 0.99 0.99 0.99 0.99 0.99 0.00 0.00 0.00 0.00 Constitucion 2004 0.99 0.99 0.99 0.99 0.99 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 0.00 0.00 0.00 0.00 Constitucion 2005 0.98 0.99 0.99 0.99 0.99 0.99 0.99 0.99 0.99 0.99 0.99 0.99 0.99 0.00 0.00 0.00 0.00 Constitucion 2006 0.91 0.91 0.91 0.90 0.91 0.91 0.91 0.91 0.91 0.91 0.91 0.91 0.91 0.01 0.01 0.01 0.00 Constitucion 2007 0.98 0.99 0.99 0.97 0.99 0.99 0.99 0.99 0.99 0.99 0.99 0.99 0.99 0.99 0.99 0.99 0.00 Constitucion 2008 0.98 0.99 0.99 0.99 0.99 1.00 0.88 0.88 0.88 0.88 0.88 0.88 0.88 0.88 0.88 0.88 0.02 Constitucion 2009 0.99 0.99 0.99 0.99 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 Constitucion 2010 0.99 0.99 0.99 0.99 0.99 0.99 1.00 1.00 1.00 1.00 1.00 1.00 1.00 0.99 0.99 0.99 0.99 Constitucion 2011 0.99 0.99 0.99 0.99 0.99 0.99 0.99 0.99 0.99 0.99 0.99 0.99 0.99 0.98 0.98 0.98 0.99 Constitucion 2012 0.97 0.97 0.97 0.96 0.97 0.96 0.97 0.97 0.97 0.97 0.97 0.97 0.97 0.96 0.96 0.96 0.97 Constitucion 2013 0.99 0.99 0.99 0.99 1.00 0.99 1.00 1.00 1.00 1.00 1.00 1.00 1.00 0.99 0.99 0.99 1.00 Constitucion 2014 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 0.99 0.99 0.99 1.00 Constitucion 2015 0.98 0.98 0.98 0.98 0.99 0.98 0.99 0.99 0.99 0.99 0.99 0.99 0.99 0.98 0.98 0.32 0.98 Constitucion 2016 0.95 0.95 0.95 0.95 0.95 0.95 0.98 0.98 0.97 0.97 0.97 0.97 0.97 0.90 0.90 0.90 0.95 Constitucion 2017 0.99 0.99 0.99 0.99 1.00 0.99 1.00 1.00 1.00 1.00 1.00 1.00 1.00 0.99 0.99 0.99 1.00 Constitucion 2018 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 Argentina: data since the year 2000. Variables: SO2, NO, NO2, CO, PM10 and 03. argentina_data &lt;- data_completeness %&gt;% filter(station_alias == &#39;Argentina&#39;) argentina_data %&gt;% kable() %&gt;% kable_styling() station_alias year SO2 NO NO2 CO PM10 O3 wd ws TMP HR PRB RS LL BEN TOL MXIL PM25 Argentina 2000 0.99 0.97 0.97 0.96 0.94 0.97 0 0 0 0 0 0 0 0 0 0 0 Argentina 2001 0.99 0.99 0.99 0.98 0.97 0.99 0 0 0 0 0 0 0 0 0 0 0 Argentina 2002 1.00 0.99 0.99 0.99 0.99 1.00 0 0 0 0 0 0 0 0 0 0 0 Argentina 2003 0.99 0.98 0.98 0.98 0.99 0.99 0 0 0 0 0 0 0 0 0 0 0 Argentina 2004 0.98 0.96 0.97 0.99 1.00 1.00 0 0 0 0 0 0 0 0 0 0 0 Argentina 2005 0.98 0.96 0.98 1.00 1.00 1.00 0 0 0 0 0 0 0 0 0 0 0 Argentina 2006 0.92 0.90 0.92 0.92 0.93 0.93 0 0 0 0 0 0 0 0 0 0 0 Argentina 2007 0.98 0.99 0.99 0.98 0.99 0.99 0 0 0 0 0 0 0 0 0 0 0 Argentina 2008 0.98 0.96 0.98 0.97 0.98 0.98 0 0 0 0 0 0 0 0 0 0 0 Argentina 2009 1.00 1.00 1.00 0.98 1.00 1.00 0 0 0 0 0 0 0 0 0 0 0 Argentina 2010 0.99 0.99 1.00 0.99 1.00 1.00 0 0 0 0 0 0 0 0 0 0 0 Argentina 2011 0.98 0.99 0.99 0.98 0.99 0.99 0 0 0 0 0 0 0 0 0 0 0 Argentina 2012 0.99 0.96 0.96 0.96 1.00 1.00 0 0 0 0 0 0 0 0 0 0 0 Argentina 2013 0.99 0.99 0.99 0.99 1.00 0.99 0 0 0 0 0 0 0 0 0 0 0 Argentina 2014 1.00 0.99 0.99 1.00 1.00 1.00 0 0 0 0 0 0 0 0 0 0 0 Argentina 2015 0.99 0.99 0.99 0.99 0.99 0.99 0 0 0 0 0 0 0 0 0 0 0 Argentina 2016 0.99 0.99 0.99 0.99 0.99 0.99 0 0 0 0 0 0 0 0 0 0 0 Argentina 2017 0.99 0.99 0.99 0.99 0.99 0.99 0 0 0 0 0 0 0 0 0 0 0 Argentina 2018 1.00 1.00 1.00 1.00 1.00 1.00 0 0 0 0 0 0 0 0 0 0 0 H. Felgueroso: data since the year 2000. Variables: SO2, NO, NO2, CO, PM10 and 03. During the year 2006 the completeness of the data decrease until 88% (to do: check there was not caused by a data importing problem.) felgueroso_data &lt;- data_completeness %&gt;% filter(station_alias == &#39;H. Felgueroso&#39;) felgueroso_data %&gt;% kable() %&gt;% kable_styling() station_alias year SO2 NO NO2 CO PM10 O3 wd ws TMP HR PRB RS LL BEN TOL MXIL PM25 H. Felgueroso 2000 0.97 0.96 0.96 0.97 0.96 0.96 0 0 0 0 0 0 0 0 0 0 0 H. Felgueroso 2001 0.99 0.99 0.99 0.99 0.99 0.99 0 0 0 0 0 0 0 0 0 0 0 H. Felgueroso 2002 0.93 0.93 0.93 0.93 0.93 0.93 0 0 0 0 0 0 0 0 0 0 0 H. Felgueroso 2003 0.98 0.98 0.98 0.97 0.98 0.98 0 0 0 0 0 0 0 0 0 0 0 H. Felgueroso 2004 0.98 0.97 0.97 0.99 0.99 0.99 0 0 0 0 0 0 0 0 0 0 0 H. Felgueroso 2005 0.97 0.96 0.96 0.99 0.99 0.99 0 0 0 0 0 0 0 0 0 0 0 H. Felgueroso 2006 0.88 0.87 0.87 0.90 0.90 0.90 0 0 0 0 0 0 0 0 0 0 0 H. Felgueroso 2007 0.98 0.99 0.99 0.99 0.99 0.99 0 0 0 0 0 0 0 0 0 0 0 H. Felgueroso 2008 0.98 0.99 0.99 0.99 0.99 0.99 0 0 0 0 0 0 0 0 0 0 0 H. Felgueroso 2009 1.00 1.00 1.00 1.00 1.00 1.00 0 0 0 0 0 0 0 0 0 0 0 H. Felgueroso 2010 0.99 0.99 0.99 0.99 0.98 0.99 0 0 0 0 0 0 0 0 0 0 0 H. Felgueroso 2011 0.99 0.99 0.99 1.00 0.99 0.99 0 0 0 0 0 0 0 0 0 0 0 H. Felgueroso 2012 0.96 0.97 0.97 0.97 0.97 0.97 0 0 0 0 0 0 0 0 0 0 0 H. Felgueroso 2013 0.99 0.99 0.99 0.99 0.99 0.99 0 0 0 0 0 0 0 0 0 0 0 H. Felgueroso 2014 0.98 0.98 0.98 0.99 0.99 0.98 0 0 0 0 0 0 0 0 0 0 0 H. Felgueroso 2015 1.00 1.00 1.00 1.00 1.00 0.99 0 0 0 0 0 0 0 0 0 0 0 H. Felgueroso 2016 0.99 0.99 0.99 0.99 0.98 0.99 0 0 0 0 0 0 0 0 0 0 0 H. Felgueroso 2017 0.99 0.99 0.99 0.99 0.99 0.99 0 0 0 0 0 0 0 0 0 0 0 H. Felgueroso 2018 1.00 1.00 1.00 1.00 1.00 1.00 0 0 0 0 0 0 0 0 0 0 0 Castilla: data since the year 2000. Variables: SO2, NO, NO2, CO, PM10 and 03. During the year 2015 the completeness of the data decrease until 77% (to do: check there was not caused by a data importing problem.) castilla_data &lt;- data_completeness %&gt;% filter(station_alias == &#39;Castilla&#39;) castilla_data %&gt;% kable() %&gt;% kable_styling() station_alias year SO2 NO NO2 CO PM10 O3 wd ws TMP HR PRB RS LL BEN TOL MXIL PM25 Castilla 2000 0.97 0.97 0.97 0.97 0.97 0.95 0 0 0 0 0 0 0 0 0 0 0 Castilla 2001 0.98 0.99 0.99 0.98 0.99 0.99 0 0 0 0 0 0 0 0 0 0 0 Castilla 2002 0.99 0.99 0.99 0.97 0.99 0.99 0 0 0 0 0 0 0 0 0 0 0 Castilla 2003 0.99 0.99 0.99 0.98 0.99 0.99 0 0 0 0 0 0 0 0 0 0 0 Castilla 2004 0.99 0.99 0.99 0.98 0.99 0.99 0 0 0 0 0 0 0 0 0 0 0 Castilla 2005 0.99 0.95 0.95 0.98 1.00 1.00 0 0 0 0 0 0 0 0 0 0 0 Castilla 2006 0.91 0.91 0.91 0.91 0.92 0.93 0 0 0 0 0 0 0 0 0 0 0 Castilla 2007 0.99 1.00 1.00 0.99 1.00 1.00 0 0 0 0 0 0 0 0 0 0 0 Castilla 2008 0.95 0.96 0.96 0.95 0.96 0.96 0 0 0 0 0 0 0 0 0 0 0 Castilla 2009 0.99 0.99 0.99 0.99 0.99 1.00 0 0 0 0 0 0 0 0 0 0 0 Castilla 2010 0.92 0.93 0.93 0.93 0.93 0.93 0 0 0 0 0 0 0 0 0 0 0 Castilla 2011 0.97 0.99 0.99 0.98 0.99 0.99 0 0 0 0 0 0 0 0 0 0 0 Castilla 2012 0.97 0.98 0.98 0.98 0.98 0.98 0 0 0 0 0 0 0 0 0 0 0 Castilla 2013 1.00 0.99 0.99 1.00 1.00 1.00 0 0 0 0 0 0 0 0 0 0 0 Castilla 2014 0.99 0.99 0.99 0.99 1.00 0.99 0 0 0 0 0 0 0 0 0 0 0 Castilla 2015 0.77 0.76 0.76 0.77 0.76 0.77 0 0 0 0 0 0 0 0 0 0 0 Castilla 2016 0.98 0.99 0.99 0.99 0.97 0.98 0 0 0 0 0 0 0 0 0 0 0 Castilla 2017 0.97 0.99 0.99 0.99 0.98 0.97 0 0 0 0 0 0 0 0 0 0 0 Castilla 2018 1.00 1.00 1.00 1.00 1.00 1.00 0 0 0 0 0 0 0 0 0 0 0 Montevil: Data since the year 2009. Variables: SO2, NO, NO2, 03, dd, vv, TMP, HR, PRB, HS, LL and PM25. montevil_data &lt;- data_completeness %&gt;% filter(station_alias == &#39;Montevil&#39;) montevil_data %&gt;% kable() %&gt;% kable_styling() station_alias year SO2 NO NO2 CO PM10 O3 wd ws TMP HR PRB RS LL BEN TOL MXIL PM25 Montevil 2009 0.91 0.93 0.93 0 0 0.93 0.93 0.93 0.93 0.93 0.93 0.93 0.93 0 0 0 0.93 Montevil 2010 0.99 1.00 1.00 0 0 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 0 0 0 0.92 Montevil 2011 0.99 0.99 0.99 0 0 0.99 1.00 1.00 1.00 1.00 1.00 1.00 1.00 0 0 0 1.00 Montevil 2012 1.00 1.00 1.00 0 0 1.00 0.98 0.98 1.00 1.00 1.00 1.00 1.00 0 0 0 1.00 Montevil 2013 1.00 1.00 1.00 0 0 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 0 0 0 1.00 Montevil 2014 1.00 1.00 1.00 0 0 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 0 0 0 1.00 Montevil 2015 0.99 1.00 1.00 0 0 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 0 0 0 1.00 Montevil 2016 0.99 0.99 0.99 0 0 0.99 1.00 1.00 1.00 1.00 1.00 1.00 1.00 0 0 0 1.00 Montevil 2017 0.99 0.99 0.99 0 0 0.99 0.99 0.99 0.99 0.99 0.99 0.99 0.99 0 0 0 0.99 Montevil 2018 1.00 1.00 1.00 0 0 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 0 0 0 1.00 Santa Bárbara: Data since the year 2016. Variables: NO, NO2, CO, PM10, 03 and PM25 barbara_data &lt;- data_completeness %&gt;% filter(station_alias == &#39;Santa Barbara&#39;) barbara_data %&gt;% kable() %&gt;% kable_styling() station_alias year SO2 NO NO2 CO PM10 O3 wd ws TMP HR PRB RS LL BEN TOL MXIL PM25 Santa Barbara 2016 0 0.97 0.97 0.98 0.98 0 0 0 0 0 0 0 0 0 0 0 0.98 Santa Barbara 2017 0 0.98 0.98 0.99 1.00 0 0 0 0 0 0 0 0 0 0 0 1.00 Santa Barbara 2018 0 1.00 1.00 1.00 1.00 0 0 0 0 0 0 0 0 0 0 0 1.00 All the stations have 2018 data, but it is just 6 observations. We drop them to avoid problems when visualising the data. observations_per_year &lt;- air_data_2 %&gt;% group_by(year = year(date_time_utc)) %&gt;% summarise(n = n()) observations_per_year %&gt;% kable() %&gt;% kable_styling() year n 2000 35136 2001 35040 2002 35040 2003 35040 2004 35136 2005 35040 2006 34939 2007 34921 2008 35136 2009 39541 2010 43800 2011 43800 2012 43920 2013 43800 2014 43800 2015 43416 2016 52703 2017 52560 2018 6 air_data_2$year &lt;- year(air_data_2$date_time_utc) air_data_2 &lt;- air_data_2 %&gt;% filter(year != &#39;2018&#39;) 6.3 Adding new variables 6.3.1 Time variables We add to the dataset several more time variables. air_data_2$month &lt;- month(air_data_2$date_time_utc) air_data_2$date &lt;- as.Date(air_data_2$date_time_utc) air_data_2$week_day &lt;- wday(air_data_2$date_time_utc, week_start = getOption(&quot;lubridate.week.start&quot;, 1)) air_data_2$hour &lt;- hour(air_data_2$date_time_utc) 6.3.2 Laboral dates And we add a variable with the with the ‘non-working days’ of Gijon city from 2014 to 2017. holydays &lt;- read_csv(&#39;data/holiday_dates.csv&#39;, locale = locale(encoding = &quot;ISO-8859-1&quot;)) air_data_2 &lt;- left_join(air_data_2, holydays, by = c(&quot;date&quot; = &quot;holiday_date&quot;)) air_data_2 &lt;- air_data_2 %&gt;% mutate(no_lab_days = ifelse((week_day &lt; 6 &amp; !is.na(holiday_type)) | (week_day &gt;=6), &quot;no_lab&quot;, &quot;lab&quot;)) %&gt;% mutate(no_lab_days=replace(no_lab_days, date &lt; &#39;2014-01-01&#39;, NA)) 6.3.3 Wind direction We create another variable to have a factor version of the ‘dd’ variable (wind direction in degrees). I took this snippet of code from here: https://community.rstudio.com/t/convert-wind-direction-degrees-into-factors-in-a-data-frame/14636/4 I made some changes because this code caused a problem when I tried to publish the document on bookdown rose_breaks &lt;- c(0, 360/32, (1/32 + (1:15 / 16)) * 360, 360) # The problem was the repetition of the level &quot;N&quot;. # So I splited this level in two, &quot;N1&quot; and &quot;N2&quot;. rose_labs &lt;- c( &quot;N1&quot;, &quot;NNE&quot;, &quot;NE&quot;, &quot;ENE&quot;, &quot;E&quot;, &quot;ES&quot;, &quot;SE&quot;, &quot;SSE&quot;, &quot;S&quot;, &quot;SSW&quot;, &quot;SW&quot;, &quot;WS&quot;, &quot;W&quot;, &quot;WNW&quot;, &quot;NW&quot;, &quot;NNW&quot;, &quot;N2&quot; ) air_data_2 &lt;- air_data_2 %&gt;% mutate( wd_code = cut( wd, breaks = rose_breaks, labels = rose_labs, right = FALSE, include.lowest = TRUE ) ) # And I recoded to &quot;N&quot; air_data_2 &lt;- air_data_2 %&gt;% mutate(wd_code = recode(wd_code, N1 = &quot;N&quot;, N2 = &quot;N&quot;)) We save the final dataset as a rds object. saveRDS(air_data_2, file = &quot;data_rds/air_data_2.rds&quot;) 6.3.4 Tables preparation for Tableau dashboards We are going to prepare some tables for the Tableau dashboards. First of all we export the whole table to a csv file. I am not saving this file in the “data_final_csvs” folder because it exceeds the Github file limit size (100mb)(pendiente exportar a google drive) I save the air_data_2.csv outside the project directory because it exceeds the 100mb github limit. # write_csv(air_data_2,&quot;C:/Users/SErgio/OneDrive/00_master_data_science/TFM/air_data_2.csv&quot;) 6.3.4.1 CO tables We create a CO dataset with CO Moving averages (each 8 hours). It is needed to measure the accomplishment of UE limits for this pollutant co_data &lt;- air_data_2 %&gt;% select(station_alias, date_time_utc, CO) %&gt;% mutate(ma_co_8 = roll_mean(CO, 8, fill=0)) hist(co_data$ma_co_8) summary(co_data$ma_co_8) ## Min. 1st Qu. Median Mean 3rd Qu. Max. NA&#39;s ## 0.00 0.25 0.39 0.48 0.60 24.34 116415 plot(co_data$ma_co_8) # pending na treatment saveRDS(co_data, file = &quot;data_rds/co_data.rds&quot;) write_csv(co_data, &quot;data_final_csvs/co_data.csv&quot;) 6.3.4.2 O3 tables We create a O3 dataset with O3 Moving averages (each 8 hours). It is needed to measure the accomplishment of UE limits for this pollutant o3_data &lt;- air_data_2 %&gt;% select(station_alias, date_time_utc, O3) %&gt;% mutate(ma_o3_8 = roll_mean(O3, 8, fill=0), o3_8_acc = ifelse(ma_o3_8 &gt; 125, &#39;no&#39;, &#39;yes&#39;)) hist(o3_data$ma_o3_8) summary(o3_data$ma_o3_8) ## Min. 1st Qu. Median Mean 3rd Qu. Max. NA&#39;s ## 0.00 21.50 37.50 39.34 54.10 998.00 41435 plot(o3_data$ma_o3_8) # pending na treatment saveRDS(o3_data, file = &quot;data_rds/o3_data.rds&quot;) write_csv(o3_data, &quot;data_final_csvs/o3_data.csv&quot;) 6.3.4.3 SO2 tables RD 102/2011 Hourly limit: 350 ug/m3 (1 hour). &lt;= 24 times / year. Daily limit: 125 ug/m3 (24 hours). &lt;= 3 times / year. Alert threshold: 500 ug/m3 (3 hours). so2_data &lt;- air_data_2 %&gt;% select(station_alias, date_time_utc, SO2) saveRDS(so2_data, file = &quot;data_rds/so2_data.rds&quot;) write_csv(so2_data, &quot;data_final_csvs/so2_data.csv&quot;) # How many times was the Hourly limit exceeded during the last 18 years? so2_hourly_limit &lt;- so2_data %&gt;% group_by(station_alias, year = year(date_time_utc), day = date(date_time_utc)) %&gt;% filter(SO2 &gt; 350) %&gt;% summarise(n = n()) %&gt;% arrange(year) so2_hourly_limit ## # A tibble: 14 x 4 ## # Groups: station_alias, year [9] ## station_alias year day n ## &lt;fct&gt; &lt;dbl&gt; &lt;date&gt; &lt;int&gt; ## 1 Castilla 2001 2001-10-20 2 ## 2 H. Felgueroso 2001 2001-10-20 2 ## 3 Argentina 2004 2004-01-27 2 ## 4 Argentina 2004 2004-01-28 12 ## 5 Constitucion 2007 2007-05-30 1 ## 6 Argentina 2008 2008-09-25 1 ## 7 Argentina 2008 2008-11-27 1 ## 8 Castilla 2008 2008-11-17 1 ## 9 Castilla 2008 2008-12-25 4 ## 10 Castilla 2008 2008-12-26 7 ## 11 Castilla 2009 2009-01-05 1 ## 12 Castilla 2011 2011-06-07 6 ## 13 Castilla 2011 2011-06-08 1 ## 14 Constitucion 2011 2011-01-13 3 saveRDS(so2_hourly_limit, file = &quot;data_rds/so2_hourly_limit.rds&quot;) write_csv(so2_hourly_limit, &quot;data_final_csvs/so2_hourly_limit.csv&quot;) # How many times was the Daily limit exceeded during the last 18 years? so2_daily_limit &lt;- so2_data %&gt;% group_by(station_alias, date = date(date_time_utc), year = year(date_time_utc)) %&gt;% summarise(avg = mean(SO2, na.rm = TRUE)) %&gt;% ungroup %&gt;% filter(avg &gt; 125) %&gt;% group_by(station_alias, year, date) %&gt;% summarise(n = n()) %&gt;% arrange(year) so2_daily_limit ## # A tibble: 6 x 4 ## # Groups: station_alias, year [3] ## station_alias year date n ## &lt;fct&gt; &lt;dbl&gt; &lt;date&gt; &lt;int&gt; ## 1 Argentina 2004 2004-01-28 1 ## 2 Castilla 2008 2008-11-17 1 ## 3 Castilla 2008 2008-12-25 1 ## 4 Castilla 2008 2008-12-26 1 ## 5 Castilla 2011 2011-06-07 1 ## 6 Castilla 2011 2011-06-08 1 saveRDS(so2_daily_limit, file = &quot;data_rds/so2_daily_limit.rds&quot;) write_csv(so2_daily_limit, &quot;data_final_csvs/so2_daily_limit.csv&quot;) "],
["data-exploration.html", "7 Data Exploration 7.1 Trends exploration 7.2 PM10 Constitucion Station 7.3 NO2 Constitucion Station 7.4 Relationships between variables", " 7 Data Exploration Loading packages library(readr) library(dplyr) library(tidyr) library(openair) # http://davidcarslaw.github.io/openair/ library(purrr) library(lubridate) library(ggplot2) library(stringr) library(knitr) library(xts) library(zoo) library(gridExtra) library(astsa) library(rvest) library(fpp2) library(ranger) library(broom) library(RcppRoll) library(reshape2) Data loading air_data_2 &lt;- readRDS(&quot;data_rds/air_data_2.rds&quot;) 7.1 Trends exploration We take a look to the general trend of several indicators through the last 18 years # We calcule the yearly mean of the pollutants levels. year_avgs &lt;- air_data_2 %&gt;% select(station_alias, date_time_utc, PM10, PM25, SO2, NO2, NO, O3, BEN, CO, MXIL, TOL) %&gt;% group_by(station_alias, year = year(date_time_utc)) %&gt;% summarise_all(funs(mean(., na.rm = TRUE))) %&gt;% select(-date_time_utc) # We drop this variable # We export the years_avgs as a csv file write_csv(year_avgs, &quot;data_final_csvs/year_avgs.csv&quot;) # We convert the table to long format year_avgs_long &lt;- gather(year_avgs, contaminante, value, 3:length(year_avgs)) %&gt;% filter(!(grepl(&#39;Constit&#39;, station_alias) &amp; year == &#39;2006&#39; &amp; contaminante %in% c(&#39;BEN&#39;, &#39;MXIL&#39;, &#39;TOL&#39;))) %&gt;% # We filter this data because is only completed in 0.01% filter(!(grepl(&#39;Constit&#39;, station_alias) &amp; year == &#39;2008&#39; &amp; contaminante == &#39;PM25&#39;)) # We filter this data because is only completed in 0.02% # We present the data in a grid of graphs ggplot(year_avgs_long, aes(x = year, y = value)) + geom_line() + facet_grid(contaminante~station_alias,scales=&quot;free_y&quot;) + theme(axis.text = element_text(size = 6)) # We calcule the hourly mean of the pollutants levels. hour_avgs &lt;- air_data_2 %&gt;% select(station_alias, hour, PM10, PM25, SO2, NO2, NO, O3, BEN, CO, MXIL, TOL) %&gt;% group_by(station_alias, hour) %&gt;% summarise_all(funs(mean(., na.rm = TRUE))) # quito ahora esta variable, porque no tiene sentido que salga su media. # We convert the table to long format hour_avgs_long &lt;- gather(hour_avgs, contaminante, value, 3:length(hour_avgs)) # We present the data in a grid of graphs ggplot(hour_avgs_long, aes(x = hour, y = value)) + geom_line() + facet_grid(contaminante~station_alias,scales=&quot;free_y&quot;) + theme(axis.text = element_text(size = 6)) # We calcule the monthly mean of the pollutants levels. month_avgs &lt;- air_data_2 %&gt;% select(station_alias, month, PM10, PM25, SO2, NO2, NO, O3, BEN, CO, MXIL, TOL) %&gt;% group_by(station_alias, month) %&gt;% summarise_all(funs(mean(., na.rm = TRUE))) # quito ahora esta variable, porque no tiene sentido que salga su media. # We convert the table to long format month_avgs_long &lt;- gather(month_avgs, contaminante, value, 3:length(month_avgs)) # We present the data in a grid of graphs ggplot(month_avgs_long, aes(x = month, y = value)) + geom_line() + facet_grid(contaminante~station_alias,scales=&quot;free_y&quot;) + theme(axis.text = element_text(size = 6)) # We calcule the weekly mean of the pollutants levels. week_day_avgs &lt;- air_data_2 %&gt;% select(station_alias, week_day, PM10, PM25, SO2, NO2, NO, O3, BEN, CO, MXIL, TOL) %&gt;% group_by(station_alias, week_day) %&gt;% summarise_all(funs(mean(., na.rm = TRUE))) # quito ahora esta variable, porque no tiene sentido que salga su media. # We convert the table to long format week_day_avgs_long &lt;- gather(week_day_avgs, contaminante, value, 3:length(week_day_avgs)) # We present the data in a grid of graphs ggplot(week_day_avgs_long, aes(x = week_day, y = value)) + geom_line() + facet_grid(contaminante~station_alias,scales=&quot;free_y&quot;) + theme(axis.text = element_text(size = 6)) We take a look to the distributions hist_table &lt;- air_data_2 %&gt;% filter(year(date_time_utc) == &#39;2017&#39;) %&gt;% select(station_alias, PM10, PM25, SO2, NO2, NO, O3, BEN, CO, MXIL, TOL) # We convert the table to long format hist_table_long &lt;- hist_table %&gt;% gather(pollutant, value, 2:length(hist_table)) # We present the data in a grid of graphs ggplot(hist_table_long, aes(x = value)) + geom_histogram() + xlim(c(0, 150)) + facet_grid(pollutant~station_alias,scales=&quot;free_y&quot;) + theme(axis.text = element_text(size = 6)) 7.2 PM10 Constitucion Station We create the dataset pm10 with PM10 values from the Constitución Station and we execute a summary pm10 &lt;- air_data_2 %&gt;% filter(station == &#39;1&#39;) %&gt;% select(date_time_utc, PM10) summary(pm10) ## date_time_utc PM10 ## Min. :2000-01-01 00:00:00 Min. : 0.00 ## 1st Qu.:2004-06-30 23:15:00 1st Qu.: 19.00 ## Median :2009-01-02 00:30:00 Median : 29.00 ## Mean :2008-12-31 18:50:45 Mean : 34.39 ## 3rd Qu.:2013-07-02 23:45:00 3rd Qu.: 44.00 ## Max. :2017-12-31 23:00:00 Max. :888.00 ## NA&#39;s :3106 25% of the values are between 44.00 and 888.00. 888.00 is a value really extreme. How many extreme values (outliers) do we have in this series? We plot all the values to visualise this: ggplot(pm10, aes(x = date_time_utc, y = PM10)) + geom_point(alpha = 0.1) We have very few values greater than 250. So, it doesn’t seem we have a problem with the outliers. We filter out the most extreme values to improve the visualization, but pm10_no_outliers &lt;- pm10 %&gt;% filter(PM10 &lt;= 300) ggplot(pm10_no_outliers, aes(x = date_time_utc, y = PM10)) + geom_point(alpha = 0.1) ggplot(pm10, aes(x = date_time_utc, y = PM10)) + geom_point(alpha = 0.1, size = 0.2) + scale_y_continuous(trans=&#39;log2&#39;) PM10_2017 &lt;- pm10 %&gt;% filter(year(date_time_utc) == &#39;2017&#39;) ggplot(PM10_2017, aes(x = date_time_utc, y = PM10)) + geom_point(alpha = 0.1, size = 1) + scale_y_continuous(trans=&#39;log2&#39;) Daily averages We create a new dataset with the PM10 daily averages and we plot them in a new graphic. We add a trend line too. There is a clear downward trend in the measurements and we have many fewer extreme values during the last decade. It seems like we have two very clear “epochs” in the data, with a clear change in the data structure starting somewhere around 2009. pm10_day_avg &lt;- pm10 %&gt;% group_by(day = date(date_time_utc)) %&gt;% summarise(day_avg = mean(PM10, na.rm = TRUE)) ggplot(pm10_day_avg, aes(x = day, y = day_avg, , colour = day_avg)) + geom_point(alpha = 0.5) + geom_smooth(color = &quot;grey&quot;, alpha = 0.2) + scale_colour_gradientn(colours = terrain.colors(10)) + theme(legend.position = c(0.3, 0.9), legend.background = element_rect(colour = &quot;transparent&quot;, fill = NA), legend.direction = &quot;horizontal&quot;) + labs(colour = &quot;PM10 daily average (colour scale)&quot;, x = &quot;Year&quot;, y = &quot;PM10 daily average&quot;, title = &quot;PM10 daily average - 2000-2017 evolution (Constitucion station)&quot;) We plot the same data but through a box plot graph. Now we can see very clearly how since 2009 the behaviour of the data is sustantially different from the precedent years. The PM10 day levels are smaller, the variability is significantly less pronounced and the trend is smoother too. pm10_day_avg &lt;- pm10 %&gt;% group_by(day = date(date_time_utc)) %&gt;% summarise(day_avg = mean(PM10, na.rm = TRUE)) ggplot(pm10_day_avg, aes(y = day_avg, x = as.factor(year(day)), colour = day_avg)) + geom_boxplot(alpha = 0.5) We identify a very clear trend through the years on the last graph. But, as we already saw before on the grid graphs there are other things happening at the same time. year_const &lt;- year_avgs_long %&gt;% filter(grepl(&#39;Constit&#39;, station_alias), contaminante == &#39;PM10&#39;) plot1 &lt;- ggplot(year_const, aes(x = year, y = value)) + geom_line() month_const &lt;- month_avgs_long %&gt;% filter(grepl(&#39;Constit&#39;, station_alias), contaminante == &#39;PM10&#39;) plot2 &lt;- ggplot(month_const, aes(x = month, y = value)) + geom_line() week_day_const &lt;- week_day_avgs_long %&gt;% filter(grepl(&#39;Constit&#39;, station_alias), contaminante == &#39;PM10&#39;) plot3 &lt;- ggplot(week_day_const, aes(x = week_day, y = value)) + geom_line() hour_const &lt;- hour_avgs_long %&gt;% filter(grepl(&#39;Constit&#39;, station_alias), contaminante == &#39;PM10&#39;) plot4 &lt;- ggplot(hour_const, aes(x = hour, y = value)) + geom_line() grid.arrange(plot1, plot2, plot3, plot4, ncol = 2) 7.3 NO2 Constitucion Station We create the dataset pm10 with PM10 values from the Constitución Station and we execute a summary NO2 &lt;- air_data_2 %&gt;% filter(station == &#39;1&#39;) %&gt;% select(date_time_utc, NO2) summary(NO2) ## date_time_utc NO2 ## Min. :2000-01-01 00:00:00 Min. : 0.00 ## 1st Qu.:2004-06-30 23:15:00 1st Qu.: 20.00 ## Median :2009-01-02 00:30:00 Median : 34.00 ## Mean :2008-12-31 18:50:45 Mean : 37.26 ## 3rd Qu.:2013-07-02 23:45:00 3rd Qu.: 51.00 ## Max. :2017-12-31 23:00:00 Max. :408.00 ## NA&#39;s :2930 NO2_day_avg &lt;- NO2 %&gt;% group_by(day = date(date_time_utc)) %&gt;% summarise(day_avg = mean(NO2, na.rm = TRUE)) ggplot(NO2_day_avg, aes(x = day, y = day_avg, , colour = day_avg)) + geom_point(alpha = 0.5) + geom_smooth(color = &quot;grey&quot;, alpha = 0.2) + scale_colour_gradientn(colours = terrain.colors(10)) + theme(legend.position = c(0.3, 0.9), legend.background = element_rect(colour = &quot;transparent&quot;, fill = NA), legend.direction = &quot;horizontal&quot;) + labs(colour = &quot;PM10 daily average (colour scale)&quot;, x = &quot;Year&quot;, y = &quot;PM10 daily average&quot;, title = &quot;NO2 daily average - 2000-2017 evolution (Constitucion station)&quot;) significantly less pronounced and the trend is smoother too. NO2_day_avg &lt;- NO2 %&gt;% group_by(day = date(date_time_utc)) %&gt;% summarise(day_avg = mean(NO2, na.rm = TRUE)) ggplot(NO2_day_avg, aes(y = day_avg, x = as.factor(year(day)), colour = day_avg)) + geom_boxplot(alpha = 0.5) year_const &lt;- year_avgs_long %&gt;% filter(grepl(&#39;Constit&#39;, station_alias), contaminante == &#39;NO2&#39;) plot1 &lt;- ggplot(year_const, aes(x = year, y = value)) + geom_line() month_const &lt;- month_avgs_long %&gt;% filter(grepl(&#39;Constit&#39;, station_alias), contaminante == &#39;NO2&#39;) plot2 &lt;- ggplot(month_const, aes(x = month, y = value)) + geom_line() week_day_const &lt;- week_day_avgs_long %&gt;% filter(grepl(&#39;Constit&#39;, station_alias), contaminante == &#39;NO2&#39;) plot3 &lt;- ggplot(week_day_const, aes(x = week_day, y = value)) + geom_line() hour_const &lt;- hour_avgs_long %&gt;% filter(grepl(&#39;Constit&#39;, station_alias), contaminante == &#39;NO2&#39;) plot4 &lt;- ggplot(hour_const, aes(x = hour, y = value)) + geom_line() grid.arrange(plot1, plot2, plot3, plot4, ncol = 2) 7.4 Relationships between variables The Constitucion Station is the only station with meteorological data. So, we are going to focus our efforts of data exploration on this station. Reference: http://www.sthda.com/english/wiki/ggplot2-quick-correlation-matrix-heatmap-r-software-and-data-visualization Pollutants correlations matrix constitucion_data &lt;- readRDS(&quot;data_rds/constitucion_data.rds&quot;) ### Pollutants correlation matrix # We select the pollutants variables pollutants &lt;- constitucion_data %&gt;% select(PM10, PM25, NO2, NO, SO2, CO, O3, MXIL, TOL) %&gt;% na.omit() # We create the pollutants correlation matrix cor_matrix &lt;- round(cor(pollutants), 2) # We transform the table to long format to be handled by ggplot2 long_cor_matrix &lt;- melt(cor_matrix) # Get lower triangle of the correlation matrix get_lower_tri&lt;-function(cor_matrix){ cor_matrix[upper.tri(cor_matrix)] &lt;- NA return(cor_matrix) } # Get upper triangle of the correlation matrix get_upper_tri &lt;- function(cor_matrix){ cor_matrix[lower.tri(cor_matrix)]&lt;- NA return(cor_matrix) } upper_tri &lt;- get_upper_tri(cor_matrix) # Melt the correlation matrix library(reshape2) long_cor_matrix &lt;- melt(upper_tri, na.rm = TRUE) # Create a ggheatmap ggheatmap &lt;- ggplot(long_cor_matrix, aes(Var2, Var1, fill = value))+ geom_tile(color = &quot;white&quot;)+ scale_fill_gradient2(low = &quot;blue&quot;, high = &quot;red&quot;, mid = &quot;white&quot;, midpoint = 0, limit = c(-1,1), space = &quot;Lab&quot;, name=&quot;Pearson\\nCorrelation&quot;) + theme_minimal()+ # minimal theme theme(axis.text.x = element_text(angle = 45, vjust = 1, size = 12, hjust = 1))+ coord_fixed() pollutants_heatmap &lt;- ggheatmap + geom_text(aes(Var2, Var1, label = value), color = &quot;black&quot;, size = 4) + theme( axis.title.x = element_blank(), axis.title.y = element_blank(), panel.grid.major = element_blank(), panel.border = element_blank(), panel.background = element_blank(), axis.ticks = element_blank(), legend.justification = c(1, 0), legend.position = c(0.6, 0.7), legend.direction = &quot;horizontal&quot;)+ guides(fill = guide_colorbar(barwidth = 7, barheight = 1, title.position = &quot;top&quot;, title.hjust = 0.5)) print(pollutants_heatmap) Pollutants-weather data correlations matrix constitucion_data &lt;- readRDS(&quot;data_rds/constitucion_data.rds&quot;) ### Pollutants correlation matrix # We select the pollutants variables pollutants_weather &lt;- constitucion_data %&gt;% select(PM10, PM25, NO2, NO, SO2, CO, O3, MXIL, TOL, dd, vv, TMP, PRB, LL, HR, RS) %&gt;% na.omit() # We create the pollutants correlation matrix cor_matrix &lt;- round(cor(pollutants_weather), 2) # We transform the table to long format to be handled by ggplot2 long_cor_matrix &lt;- melt(cor_matrix) # Get lower triangle of the correlation matrix get_lower_tri&lt;-function(cor_matrix){ cor_matrix[upper.tri(cor_matrix)] &lt;- NA return(cor_matrix) } # Get upper triangle of the correlation matrix get_upper_tri &lt;- function(cor_matrix){ cor_matrix[lower.tri(cor_matrix)]&lt;- NA return(cor_matrix) } upper_tri &lt;- get_upper_tri(cor_matrix) # Melt the correlation matrix library(reshape2) long_cor_matrix &lt;- melt(upper_tri, na.rm = TRUE) # Create a ggheatmap ggheatmap &lt;- ggplot(long_cor_matrix, aes(Var2, Var1, fill = value))+ geom_tile(color = &quot;white&quot;)+ scale_fill_gradient2(low = &quot;blue&quot;, high = &quot;red&quot;, mid = &quot;white&quot;, midpoint = 0, limit = c(-1,1), space = &quot;Lab&quot;, name=&quot;Pearson\\nCorrelation&quot;) + theme_minimal()+ # minimal theme theme(axis.text.x = element_text(angle = 45, vjust = 1, size = 12, hjust = 1))+ coord_fixed() pollutants_heatmap &lt;- ggheatmap + geom_text(aes(Var2, Var1, label = value), color = &quot;black&quot;, size = 2) + theme( axis.title.x = element_blank(), axis.title.y = element_blank(), panel.grid.major = element_blank(), panel.border = element_blank(), panel.background = element_blank(), axis.ticks = element_blank(), legend.justification = c(1, 0), legend.position = c(0.6, 0.7), legend.direction = &quot;horizontal&quot;)+ guides(fill = guide_colorbar(barwidth = 7, barheight = 1, title.position = &quot;top&quot;, title.hjust = 0.5)) print(pollutants_heatmap) The openair package is a R package especialized in the visualizations of air quality data. Wind visualizations (openair package) windRose(air_data_2) Pollution rose ((openair package)) pollutionRose(air_data_2, pollutant = &quot;PM10&quot;) "],
["forecasting-models-arima.html", "8 Forecasting models. ARIMA 8.1 Data loading 8.2 Train, test and validation data (PM10 models) 8.3 Data Exploration 8.4 Base model. 8.5 PM10 ARIMA models", " 8 Forecasting models. ARIMA In this notebook we are going to use ARIMA models to forecast hourly levels of the PM10 pollutant. We are going to focus on the Constitucion station, which is the only station we have meteorological data. We are not going to use the meteorological data in the ARIMA models, but we will use them later with machine learning models. Loading packages library(readr) library(dplyr) library(tidyr) library(purrr) library(lubridate) library(ggplot2) library(stringr) library(knitr) library(xts) library(zoo) library(gridExtra) library(astsa) library(rvest) library(fpp2) library(ranger) library(broom) library(RcppRoll) library(caret) 8.1 Data loading air_data_2 &lt;- readRDS(&quot;data_rds/air_data_2.rds&quot;) constitucion_data &lt;- air_data_2 %&gt;% filter(station == &quot;1&quot;) 8.2 Train, test and validation data (PM10 models) We have 18 years of avalaible data. But we are not going to use all the data. We are going to test three different periods for the training of the models, 2009-01-01 - 2016-12-31, 2014-01-01 - 2016-12-31 and 2016-10-01 - 2016-12-31. We will use the 2017-01-01 - 2017-09-30 period for testing and the 2017-10-01 - 2017-12-31 one for validation. train_201401_201612 &lt;- constitucion_data %&gt;% filter(date_time_utc &gt;= &#39;2014-01-01 00:00:00&#39;, date_time_utc &lt;= &#39;2016-12-31 23:00:00&#39;) %&gt;% select(PM10) %&gt;% mutate(PM10 = replace_na(PM10, mean(PM10, na.rm = TRUE))) %&gt;% # replacing NAs by the mean. rename(PM10_0 = PM10) %&gt;% ts(frequency = 24) # We generate a smaller training dataset with the last three months of 2016 train_201610_201612 &lt;- constitucion_data %&gt;% filter(date_time_utc &gt;= &#39;2016-10-01 00:00:00&#39;, date_time_utc &lt;= &#39;2016-12-31 23:00:00&#39;) %&gt;% select(PM10) %&gt;% mutate(PM10 = replace_na(PM10, mean(PM10, na.rm = TRUE))) %&gt;% rename(PM10_0 = PM10) %&gt;% ts(frequency = 24) # We generate a bigger training dataset with 9 years (2009-2017) train_200901_201612 &lt;- constitucion_data %&gt;% filter(date_time_utc &gt;= &#39;2009-01-01 00:00:00&#39;, date_time_utc &lt;= &#39;2016-12-31 23:00:00&#39;) %&gt;% select(PM10) %&gt;% mutate(PM10 = replace_na(PM10, mean(PM10, na.rm = TRUE))) %&gt;% rename(PM10_0 = PM10) %&gt;% ts(frequency = 24) # We generate the test dataset test_201701_201709 &lt;- constitucion_data %&gt;% filter(date_time_utc &gt;= &#39;2017-01-01 00:00:00&#39;, date_time_utc &lt;= &#39;2017-09-30 23:00:00&#39;) %&gt;% select(PM10) %&gt;% mutate(PM10 = replace_na(PM10, mean(PM10, na.rm = TRUE))) %&gt;% rename(PM10_0 = PM10) %&gt;% ts(frequency = 24) # We generate a smaller testing dataset with the first two weeks of 2017 (for visualization purposes) test_20170101_20170114 &lt;- constitucion_data %&gt;% filter(date_time_utc &gt;= &#39;2017-01-01 00:00:00&#39;, date_time_utc &lt;= &#39;2017-01-14 23:00:00&#39;) %&gt;% select(PM10) %&gt;% mutate(PM10 = replace_na(PM10, mean(PM10, na.rm = TRUE))) %&gt;% rename(PM10_0 = PM10) %&gt;% ts(frequency = 24) # And the validation period validation_201710_201712 &lt;- constitucion_data %&gt;% filter(date_time_utc &gt;= &#39;2017-10-01 00:00:00&#39;, date_time_utc &lt;= &#39;2017-12-31 23:00:00&#39;) %&gt;% select(PM10) %&gt;% mutate(PM10 = replace_na(PM10, mean(PM10, na.rm = TRUE))) %&gt;% rename(PM10_0 = PM10) %&gt;% ts(frequency = 24) 8.3 Data Exploration The reason we are not using data before 2009 is because, in general, as we could see in the Data Exploration part, the levels of the pollutants, their variability, and even their trends and patterns are very different from now. We recover this PM10 evolution graph as example. PM10_day_avg &lt;- constitucion_data %&gt;% select(date_time_utc, PM10) %&gt;% group_by(day = date(date_time_utc)) %&gt;% summarise(day_avg = mean(PM10, na.rm = TRUE)) ggplot(PM10_day_avg, aes(x = day, y = day_avg, , colour = day_avg)) + geom_point(alpha = 0.5) + geom_smooth(color = &quot;grey&quot;, alpha = 0.2) + scale_colour_gradientn(colours = terrain.colors(10)) + theme(legend.position = c(0.3, 0.9), legend.background = element_rect(colour = &quot;transparent&quot;, fill = NA), legend.direction = &quot;horizontal&quot;) + labs(colour = &quot;PM10 daily average (colour scale)&quot;, x = &quot;Year&quot;, y = &quot;PM10 daily average&quot;, title = &quot;PM10 daily average - 2000-2017 evolution (Constitucion station)&quot;) We obtain the main descriptive statistics of each period sum_train_2009_2016 &lt;- as.data.frame(train_200901_201612) %&gt;% summarise(min. = min(PM10_0), q25 = quantile(PM10_0, 0.25), avg = round(mean(PM10_0), 2), median = median(PM10_0), max. = max(PM10_0), q75 = quantile(PM10_0, 0.75), sd = round(sd(PM10_0), 2)) %&gt;% mutate(period = &quot;2009-01-2016-12&quot;) sum_train_2014_2016 &lt;- as.data.frame(train_201401_201612) %&gt;% summarise(min. = min(PM10_0), q25 = quantile(PM10_0, 0.25), avg = round(mean(PM10_0), 2), median = median(PM10_0), max. = max(PM10_0), q75 = quantile(PM10_0, 0.75), sd = round(sd(PM10_0), 2)) %&gt;% mutate(period = &quot;2014-01-2016-12&quot;) sum_train_201610_201612 &lt;- as.data.frame(train_201610_201612) %&gt;% summarise(min. = min(PM10_0), q25 = quantile(PM10_0, 0.25), avg = round(mean(PM10_0), 2), median = median(PM10_0), max. = max(PM10_0), q75 = quantile(PM10_0, 0.75), sd = round(sd(PM10_0), 2)) %&gt;% mutate(period = &quot;2016-10-2016-12&quot;) sum_test_201701_201709 &lt;- as.data.frame(test_201701_201709) %&gt;% summarise(min. = min(PM10_0), q25 = quantile(PM10_0, 0.25), avg = round(mean(PM10_0), 2), median = median(PM10_0), max. = max(PM10_0), q75 = quantile(PM10_0, 0.75), sd = round(sd(PM10_0), 2)) %&gt;% mutate(period = &quot;2017-01-2017-09&quot;) sum_validation_201710_201712 &lt;- as.data.frame(validation_201710_201712) %&gt;% summarise(min. = min(PM10_0), q25 = quantile(PM10_0, 0.25), avg = round(mean(PM10_0), 2), median = median(PM10_0), max. = max(PM10_0), q75 = quantile(PM10_0, 0.75), sd = round(sd(PM10_0), 2)) %&gt;% mutate(period = &quot;2017-10-2017-12&quot;) periods_summary &lt;- bind_rows(sum_train_2009_2016, sum_train_2014_2016, sum_train_201610_201612, sum_test_201701_201709, sum_validation_201710_201712) %&gt;% select(period, everything()) # I move the &quot;period&quot; column to the first position periods_summary ## period min. q25 avg median max. q75 sd ## 1 2009-01-2016-12 0 16 25.92 23 888 32 17.01 ## 2 2014-01-2016-12 0 15 24.73 22 422 30 14.83 ## 3 2016-10-2016-12 0 11 20.10 18 189 26 13.06 ## 4 2017-01-2017-09 1 13 20.66 19 100 26 10.90 ## 5 2017-10-2017-12 1 13 20.79 17 172 25 13.35 8.4 Base model. In order to create a base model we are going to take as prediction the value from the previous hour, forecasting just one hour ahead. # As we don&#39;t need any training, because we have already defined the model as Xt = Xt-1, we only need to create a testing dataset. We use the period defined before (2017-01-01 - 2017-09-30) but without the time series format (ts). test_201701_201709_2 &lt;- constitucion_data %&gt;% filter(date_time_utc &gt;= &#39;2017-01-01 00:00:00&#39;, date_time_utc &lt; &#39;2017-10-01 00:00:00&#39;) %&gt;% select(PM10, date_time_utc) %&gt;% mutate(PM10 = replace_na(PM10, mean(PM10, na.rm = TRUE))) # We replace the nas (36) by the mean. base_model &lt;- test_201701_201709_2 %&gt;% mutate(y_pred = lag(PM10, 1)) %&gt;% # We create the column y_pred with the lagged value of PM10 (one hour). rename(y_test = PM10) %&gt;% # We change the name of the PM10 column to y_test na.omit() # We remove the observations with nas (just the first row) # We extract the y_test and y_pred datasets y_test &lt;- base_model$y_test y_pred &lt;- base_model$y_pred # And we obtain some statistics scores to measure the goodness of the model # Root mean square error RMSE &lt;- RMSE(y_test, y_pred) # Mean absolute error MAE &lt;- MAE(y_test, y_pred) # R-squared rss &lt;- sum((y_test - y_pred) ** 2) tss &lt;- sum((y_test - mean(y_test)) ** 2) R_squared &lt;- 1 - rss/tss paste(c(&quot;R-squared:&quot;, round(R_squared, 4), &quot;MAE:&quot;, round(MAE, 2), &quot;RMSE:&quot;, round(RMSE, 2))) ## [1] &quot;R-squared:&quot; &quot;0.5327&quot; &quot;MAE:&quot; &quot;5.15&quot; &quot;RMSE:&quot; ## [6] &quot;7.45&quot; So, for the one hour ahead PM10 prediction if we take as prediction the previous PM10 hour level we would have a R-squared of 0.5327. So, the model is explaining 53% of the variability of the target variable. Estimation of errors. We are going to use the MAE (Mean Absolute Error) in order to compare the different models. We choose the MAE over the RMSE (Root Mean Square Error) because it is easier to interpret and at the same time it is more robust (less sensitive to outliers). Either way, we are going to calculate the RMSE too, precisely because its sensitivity to outliers. It will give us useful information about the behaviour of each model. We plot two lines with the predictions and the actual values. We have a problem of overplotting. test_201701_201709_2 ## # A tibble: 6,551 x 2 ## PM10 date_time_utc ## &lt;dbl&gt; &lt;dttm&gt; ## 1 46 2016-12-31 23:00:00 ## 2 20.7 2017-01-01 00:00:00 ## 3 38 2017-01-01 01:00:00 ## 4 35 2017-01-01 02:00:00 ## 5 36 2017-01-01 03:00:00 ## 6 31 2017-01-01 04:00:00 ## 7 22 2017-01-01 05:00:00 ## 8 32 2017-01-01 06:00:00 ## 9 21 2017-01-01 07:00:00 ## 10 20 2017-01-01 08:00:00 ## # ... with 6,541 more rows autoplot(ts(base_model$y_pred), series=&quot;1-step fitted values&quot;) + autolayer(ts(base_model$y_test), series=&quot;Test data&quot;) + theme_minimal() + theme(legend.position=&quot;top&quot;) To avoid the overplotting we plot just the first 14 days of 2017. two_weeks &lt;- base_model %&gt;% slice(1:336) # 336 corresponds to 24 hours * 14 days. two_weeks_base_model_graph &lt;- autoplot(ts(two_weeks$y_pred), series=&quot;1-step fitted values&quot;) + autolayer(ts(two_weeks$y_test), series=&quot;Test data&quot;) + theme_minimal() + theme(legend.position=&quot;top&quot;) two_weeks_base_model_graph And as expected, we get two identical lines. But one of them, the prediction, one step forward than the line with the actual data. We plot in a graph the actual versus the predicted values df &lt;- bind_cols(as.data.frame(y_pred), as.data.frame(y_test)) y_pred_y_test_base_model_graph &lt;- ggplot(data = df, aes(x = y_test, y = y_pred)) + geom_point(alpha = 0.5) + theme_minimal() We create another graph with the distribution of the residuals residual_distribution_base_model_graph &lt;- ggplot(data = df, aes(x = y_pred, y = (y_test - y_pred))) + geom_point() + geom_hline(yintercept=0) + geom_point(alpha = 0.5) + theme_minimal() And a histogram with the distribution of the errors residual_histogram_base_model_graph &lt;- ggplot(data = df, aes(x = y_test - y_pred)) + geom_histogram() + theme_minimal() And the evolution of the residuals during the test period date_time &lt;- constitucion_data %&gt;% select(date_time_utc) %&gt;% filter(date_time_utc &gt; &#39;2017-01-01 00:00:00&#39;, date_time_utc &lt;= &#39;2017-09-30 23:00:00&#39;) y_pred &lt;- as.data.frame(y_pred) y_test &lt;- as.data.frame(y_test) residuals_dates &lt;- bind_cols(date_time, y_pred, y_test) %&gt;% mutate(residuals = y_test - y_pred) %&gt;% select(date_time_utc, residuals) residuals_date_time_base_model_graph &lt;- ggplot(data = residuals_dates, aes(x = date_time_utc, y = residuals))+ geom_line() + theme_minimal() residuals_date_time_base_model_graph It seems at first sight there is not much variation in the residuals along time. But daily_mae &lt;- bind_cols(date_time, y_pred, y_test) %&gt;% group_by(date(date_time_utc)) %&gt;% mutate(mae = MAE(y_pred, y_test)) %&gt;% select(date_time_utc, mae) daily_mae_base_model_graph &lt;- ggplot(data = daily_mae, aes(x = date(date_time_utc), y = mae))+ geom_line() + theme_minimal() + ylim(0, 9) daily_mae_base_model_graph Monthly mae evolution weekly_mae &lt;- bind_cols(date_time, y_pred, y_test) %&gt;% group_by(week(date_time_utc)) %&gt;% mutate(mae = MAE(y_pred, y_test)) %&gt;% select(date_time_utc, mae) weekly_mae_base_model_graph &lt;- ggplot(data = weekly_mae, aes(x = week(date_time_utc), y = mae))+ geom_line() + theme_minimal() + ylim(0, 9) weekly_mae_base_model_graph monthly_mae_base_model &lt;- bind_cols(date_time, y_pred, y_test) %&gt;% group_by(month(date_time_utc)) %&gt;% mutate(mae = MAE(y_pred, y_test)) %&gt;% select(date_time_utc, mae) monthly_mae_base_model_graph &lt;- ggplot(data = monthly_mae_base_model, aes(x = month(date_time_utc), y = mae))+ geom_line() + theme_minimal() + ylim(0, 8) monthly_mae_base_model_graph And we arrange the four plots in one grid grid.arrange(y_pred_y_test_base_model_graph, residual_distribution_base_model_graph, residual_histogram_base_model_graph, monthly_mae_base_model_graph, ncol = 2) 8.5 PM10 ARIMA models To fit our first ARIMA model we are going to use the auto.arima function from the Forecast package. This function fits several ARIMA models, with different parameters, and selects the model with the best performance. To do this the function auto.arima uses some approximations to speed up the search of the best model. More info about the algorithm applied here. We set the parameter seasonal=TRUE because we want the function looks for seasonal elements (24 hours). We are going to save all the models fitted as rds objects in the “data_rds” folder of the project. 8.5.1 PM10_model_arima_3m We generate our first ARIMA model using the three months training period 2016-10-01 - 2016-12-31 # PM10_model_arima_3m = auto.arima(train_201610_201612,seasonal=TRUE,trace=TRUE) # # saveRDS(PM10_model_arima_3m, &quot;data_rds/PM10_model_arima_3m.rds&quot;) PM10_model_arima_3m &lt;- readRDS(&quot;data_rds/PM10_model_arima_3m.rds&quot;) summary(PM10_model_arima_3m) ## Series: train_201610_201612 ## ARIMA(2,1,4)(0,0,2)[24] ## ## Coefficients: ## ar1 ar2 ma1 ma2 ma3 ma4 sma1 sma2 ## 0.1006 0.547 -0.5222 -0.6079 0.1543 -0.0107 0.0977 0.1135 ## s.e. NaN NaN NaN NaN NaN 0.0184 0.0222 0.0215 ## ## sigma^2 estimated as 71.56: log likelihood=-7844.97 ## AIC=15707.94 AICc=15708.02 BIC=15759.24 ## ## Training set error measures: ## ME RMSE MAE MPE MAPE MASE ACF1 ## Training set 0.1536203 8.442183 5.17907 -Inf Inf 0.545021 -0.0004040565 We obtain the R-squared y_train &lt;- forecast(PM10_model_arima_3m, h = 1)$fitted # We make a forecast one hour ahead and we extract the fitted values from the object forecast. x_train &lt;- train_201610_201612 rss &lt;- sum((y_train - x_train) ** 2) tss &lt;- sum((x_train - mean(x_train)) ** 2) R_squared &lt;- 1 - rss/tss paste(c(&quot;R-squared:&quot;, round(R_squared, 4))) ## [1] &quot;R-squared:&quot; &quot;0.5816&quot; The R-squared has increased from 0.5327 to 0.5816. But both, RMSE (8.44) and MAE (5.17) (ARIMA summary output), are greater than the scores obtained with the Base Model (although the MAE is very similar). But we are comparing two different periods, the testing period (Base Model; 2017-01 - 2017-09) versus the training period (ARIMA model; 2016-10 - 2016-12). To make a fair comparison we will have to compare the same periods. For this we are going to apply the ARIMA model PM10_model_arima_3m on the testing data. Doing so we will be able to get the fitted values from this period and we will be able to obtain its error scores. We apply the model to the testing data y_pred &lt;- forecast(test_201701_201709, model = PM10_model_arima_3m, h=1)$fitted # We call the forecast function passing the testing data through the ARIMA model fitted with the training data and we extract the fitted values. y_test &lt;- test_201701_201709 sd_test &lt;- sd(y_test) RMSE &lt;- RMSE(y_test, y_pred) MAE &lt;- MAE(y_test, y_pred) rss &lt;- sum((y_test - y_pred) ** 2) tss &lt;- sum((y_test - mean(y_test)) ** 2) R_squared &lt;- 1 - rss/tss paste(c(&quot;R-squared:&quot;, round(R_squared, 4), &quot;MAE:&quot;, round(MAE, 2), &quot;RMSE:&quot;, round(RMSE, 2), &quot;Standard Deviation (test data):&quot;, round(sd_test, 2))) ## [1] &quot;R-squared:&quot; &quot;0.5975&quot; ## [3] &quot;MAE:&quot; &quot;4.88&quot; ## [5] &quot;RMSE:&quot; &quot;6.92&quot; ## [7] &quot;Standard Deviation (test data):&quot; &quot;10.9&quot; We confirm that we are obtaining a better R-squared: 0.5975 versus the 0.5327 obtained by the Base Model. The errors are sustantially better too. The ARIMA model obtains a MAE of 4.88 (Base Model: 5.15) and a RMSE of 6.92 (Base Model: 7.45). We plot in a graph the actual versus the predicted values y_pred &lt;- as.data.frame(y_pred) %&gt;% rename(y_pred = x) y_test &lt;- as.data.frame(y_test) %&gt;% rename(y_test = PM10_0) df &lt;- bind_cols(y_pred, y_test) y_pred_y_test_arima_3m_graph &lt;- ggplot(data = df, aes(x = y_test, y = y_pred)) + geom_point(alpha = 0.5) + ylim(0, 100) + theme_minimal() residual_distribution_arima_3m_graph &lt;- ggplot(data = df, aes(x = y_pred, y = (y_test - y_pred))) + geom_point() + geom_hline(yintercept=0) + geom_point(alpha = 0.5) + theme_minimal() residual_histogram_arima_3m_graph &lt;- ggplot(data = df, aes(x = y_test - y_pred)) + geom_histogram() + theme_minimal() date_time &lt;- constitucion_data %&gt;% select(date_time_utc) %&gt;% filter(date_time_utc &gt; &#39;2017-01-01 00:00:00&#39;, date_time_utc &lt;= &#39;2017-10-01 00:00:00&#39;) monthly_mae_3m &lt;- bind_cols(date_time, y_pred, y_test) %&gt;% group_by(month(date_time_utc)) %&gt;% mutate(mae = MAE(y_pred, y_test)) %&gt;% select(date_time_utc, mae) monthly_mae_arima_3m_graph &lt;- ggplot(data = monthly_mae_3m, aes(x = month(date_time_utc), y = mae))+ geom_line() + theme_minimal() + ylim(0, 8) monthly_mae_arima_3m_graph grid.arrange(y_pred_y_test_arima_3m_graph, residual_distribution_arima_3m_graph, residual_histogram_arima_3m_graph, monthly_mae_arima_3m_graph, ncol = 2) grid.arrange(y_pred_y_test_base_model_graph + ggtitle(&quot;Base model&quot;), y_pred_y_test_arima_3m_graph + ggtitle(&quot;ARIMA 2016-10 - 2016-12&quot;), ncol=2) grid.arrange(residual_distribution_base_model_graph + ggtitle(&quot;Base model&quot;), residual_distribution_arima_3m_graph + ggtitle(&quot;ARIMA 2016-10 - 2016-12&quot;), ncol=2) monthly_mae_3m_2 &lt;- monthly_mae_3m %&gt;% select(&#39;month(date_time_utc)&#39;, mae) %&gt;% unique() monthly_mae_base_model_2 &lt;- monthly_mae_base_model %&gt;% select(&#39;month(date_time_utc)&#39;, mae) %&gt;% unique() monthly_mae_comparison &lt;- left_join(monthly_mae_base_model_2, monthly_mae_3m_2, by = &#39;month(date_time_utc)&#39;) %&gt;% rename(month = &#39;month(date_time_utc)&#39;, mae_base_model = mae.x, mae_arima_3m = mae.y) monthly_mae_comparison$month &lt;- as.factor(monthly_mae_comparison$month) monthly_mae_comparison_long &lt;- monthly_mae_comparison %&gt;% gather(model, mae, 2:3) monthly_mae_base_model_vs_arima3m_graph &lt;- ggplot(data = monthly_mae_comparison_long, aes(x = month, y = mae, col = model, group = model)) + geom_line() + theme_minimal() + ylim(0, 8) monthly_mae_base_model_vs_arima3m_graph 8.5.2 PM10_model_arima_3y We are going to see if we manage to improve the results of the ARIMA model using a longer period of training, the 2014-01-01 - 2016-12-31 period. # PM10_model_arima_3y = auto.arima(train_201401_201612,seasonal=TRUE,trace=TRUE) # saveRDS(PM10_model_arima_3y, &quot;data_rds/PM10_model_arima_3y.rds&quot;) PM10_model_arima_3y &lt;- readRDS(&quot;data_rds/PM10_model_arima_3y.rds&quot;) summary(PM10_model_arima_3y) ## Series: train_201401_201612 ## ARIMA(2,1,3)(0,0,2)[24] ## ## Coefficients: ## ar1 ar2 ma1 ma2 ma3 sma1 sma2 ## 0.0991 0.5519 -0.5228 -0.6175 0.1642 0.0564 0.0392 ## s.e. NaN NaN NaN NaN NaN 0.0063 0.0061 ## ## sigma^2 estimated as 87.28: log likelihood=-96095.71 ## AIC=192207.4 AICc=192207.4 BIC=192272.8 ## ## Training set error measures: ## ME RMSE MAE MPE MAPE MASE ACF1 ## Training set 0.003353175 9.341125 5.774614 -Inf Inf 0.5111664 0.002213004 The model selected by the auto.arima function is very similar to the three months of training model. Pending: explicar las diferencias. train_201610_201612: ARIMA(2,1,4)(0,0,2)[24] train_201401_201612: ARIMA(2,1,3)(0,0,2)[24] Coefficients “train_201610_201612”: ar1 ar2 ma1 ma2 ma3 ma4 sma1 sma2 0.1006 0.547 -0.5222 -0.6079 0.1543 -0.0107 0.0977 0.1135 Coefficients “train_201401_201612”: ar1 ar2 ma1 ma2 ma3 sma1 sma2 0.0991 0.5519 -0.5228 -0.6175 0.1642 0.0564 0.0392 We apply the model to the test data and we obtain the accuracy scores. y_pred &lt;- forecast(test_201701_201709, model = PM10_model_arima_3y, h=1)$fitted # We call the forecast function passing the testing data through the ARIMA model fitted with the training data and we extract the fitted values. y_test &lt;- test_201701_201709 sd_test &lt;- sd(y_test) RMSE &lt;- RMSE(y_test, y_pred) MAE &lt;- MAE(y_test, y_pred) rss &lt;- sum((y_test - y_pred) ** 2) tss &lt;- sum((y_test - mean(y_test)) ** 2) R_squared &lt;- 1 - rss/tss paste(c(&quot;R-squared:&quot;, round(R_squared, 4), &quot;MAE:&quot;, round(MAE, 2), &quot;RMSE:&quot;, round(RMSE, 2), &quot;Standard Deviation (test data):&quot;, round(sd_test, 2))) ## [1] &quot;R-squared:&quot; &quot;0.6015&quot; ## [3] &quot;MAE:&quot; &quot;4.84&quot; ## [5] &quot;RMSE:&quot; &quot;6.88&quot; ## [7] &quot;Standard Deviation (test data):&quot; &quot;10.9&quot; The model improves a little its results, but not very much. We get a MAE of 4.84, just 0.04 less than the three months model. And the R-squared grows until 0.6015, an increment of 0.0040. We plot the fitted values and the test data. autoplot(y_test, series=&quot;Test data&quot;) + autolayer(y_pred, series=&quot;1-step fitted values&quot;) + theme_minimal() + theme(legend.position=&quot;top&quot;) We plot in a graph the actual versus the predicted values y_pred &lt;- as.data.frame(y_pred) %&gt;% rename(y_pred = x) y_test &lt;- as.data.frame(y_test) %&gt;% rename(y_test = PM10_0) df &lt;- bind_cols(y_pred, y_test) y_pred_y_test_arima_3y_graph &lt;- ggplot(data = df, aes(x = y_test, y = y_pred)) + geom_point(alpha = 0.5) + ylim(0, 100) + theme_minimal() residual_distribution_arima_3y_graph &lt;- ggplot(data = df, aes(x = y_pred, y = (y_test - y_pred))) + geom_point() + geom_hline(yintercept=0) + geom_point(alpha = 0.5) + theme_minimal() residual_histogram_arima_3y_graph &lt;- ggplot(data = df, aes(x = y_test - y_pred)) + geom_histogram() + theme_minimal() date_time &lt;- constitucion_data %&gt;% select(date_time_utc) %&gt;% filter(date_time_utc &gt; &#39;2017-01-01 00:00:00&#39;, date_time_utc &lt;= &#39;2017-10-01 00:00:00&#39;) monthly_mae_3y &lt;- bind_cols(date_time, y_pred, y_test) %&gt;% group_by(month(date_time_utc)) %&gt;% mutate(mae = MAE(y_pred, y_test)) %&gt;% select(date_time_utc, mae) monthly_mae_arima_3y_graph &lt;- ggplot(data = monthly_mae_3y, aes(x = month(date_time_utc), y = mae))+ geom_line() + theme_minimal() + ylim(0, 8) grid.arrange(y_pred_y_test_arima_3y_graph, residual_distribution_arima_3y_graph, residual_histogram_arima_3y_graph, monthly_mae_arima_3y_graph, ncol = 2) grid.arrange(y_pred_y_test_base_model_graph + ggtitle(&quot;Base model&quot;), y_pred_y_test_arima_3m_graph + ggtitle(&quot;ARIMA 2016-10 - 2016-12&quot;), y_pred_y_test_arima_3y_graph + ggtitle(&quot;ARIMA 2014-01 - 2016-12&quot;), ncol=2) grid.arrange(residual_distribution_base_model_graph + ggtitle(&quot;Base model&quot;), residual_distribution_arima_3m_graph + ggtitle(&quot;ARIMA 2016-10 - 2016-12&quot;), residual_distribution_arima_3y_graph+ ggtitle(&quot;ARIMA 2014-01 - 2016-12&quot;), ncol=2) monthly_mae_3y_2 &lt;- monthly_mae_3y %&gt;% select(&#39;month(date_time_utc)&#39;, mae) %&gt;% unique() %&gt;% rename(month = &#39;month(date_time_utc)&#39;, model_arima_3y = mae) %&gt;% ungroup() %&gt;% mutate(month = as.factor(month)) monthly_mae_comparison &lt;- left_join(monthly_mae_comparison, monthly_mae_3y_2, by = &#39;month&#39;) monthly_mae_comparison_long &lt;- monthly_mae_comparison %&gt;% gather(model, mae, 2:4) monthly_mae_base_model_vs_arima3m_3y_graph &lt;- ggplot(data = monthly_mae_comparison_long, aes(x = month, y = mae, col = model, group = model)) + geom_line() + theme_minimal() + ylim(0, 8) monthly_mae_base_model_vs_arima3m_3y_graph 8.5.3 PM10_model_arima_9y Finally, we are going to try to improve the result taking as training period 9 years of data: From 2009-01-01 to 2016-12-31. # PM10_model_arima_9y = auto.arima(train_200901_201612,seasonal=TRUE,trace=TRUE) #saveRDS(PM10_model_arima_9y, &quot;data_rds/PM10_model_arima_9y.rds&quot;) #summary(PM10_model_arima_9y) PM10_model_arima_9y &lt;- readRDS(&quot;data_rds/PM10_model_arima_9y.rds&quot;) summary(PM10_model_arima_9y) ## Series: train_200901_201612 ## ARIMA(3,1,2)(0,0,2)[24] ## ## Coefficients: ## ar1 ar2 ar3 ma1 ma2 sma1 sma2 ## 0.0878 0.3272 0.1539 -0.4929 -0.4748 0.0572 0.0330 ## s.e. 0.0266 0.0161 0.0042 0.0269 0.0257 0.0039 0.0037 ## ## sigma^2 estimated as 126.3: log likelihood=-269164.4 ## AIC=538344.8 AICc=538344.8 BIC=538418.1 ## ## Training set error measures: ## ME RMSE MAE MPE MAPE MASE ## Training set -4.331726e-05 11.23784 6.325201 -Inf Inf 0.5096805 ## ACF1 ## Training set -0.0003654974 y_pred &lt;- forecast(test_201701_201709, model = PM10_model_arima_9y, h=1)$fitted # We call the forecast function passing the testing data through the ARIMA model fitted with the training data and we extract the fitted values. y_test &lt;- test_201701_201709 sd_test &lt;- sd(y_test) RMSE &lt;- RMSE(y_test, y_pred) MAE &lt;- MAE(y_test, y_pred) rss &lt;- sum((y_test - y_pred) ** 2) tss &lt;- sum((y_test - mean(y_test)) ** 2) R_squared &lt;- 1 - rss/tss paste(c(&quot;R-squared:&quot;, round(R_squared, 4), &quot;MAE:&quot;, round(MAE, 2), &quot;RMSE:&quot;, round(RMSE, 2), &quot;Standard Deviation (test data):&quot;, round(sd_test, 2))) ## [1] &quot;R-squared:&quot; &quot;0.5966&quot; ## [3] &quot;MAE:&quot; &quot;4.88&quot; ## [5] &quot;RMSE:&quot; &quot;6.93&quot; ## [7] &quot;Standard Deviation (test data):&quot; &quot;10.9&quot; The model, with 6 more years of data doesn’t change too much. But it worsens slightly its results. The MAE increases in 0.04 points and the R-squared decreases in 0.0049 points. y_pred &lt;- as.data.frame(y_pred) %&gt;% rename(y_pred = x) y_test &lt;- as.data.frame(y_test) %&gt;% rename(y_test = PM10_0) df &lt;- bind_cols(y_pred, y_test) y_pred_y_test_arima_9y_graph &lt;- ggplot(data = df, aes(x = y_test, y = y_pred)) + geom_point(alpha = 0.5) + ylim(0, 100) + theme_minimal() residual_distribution_arima_9y_graph &lt;- ggplot(data = df, aes(x = y_pred, y = (y_test - y_pred))) + geom_point() + geom_hline(yintercept=0) + geom_point(alpha = 0.5) + theme_minimal() residual_histogram_arima_9y_graph &lt;- ggplot(data = df, aes(x = y_test - y_pred)) + geom_histogram() + theme_minimal() date_time &lt;- constitucion_data %&gt;% select(date_time_utc) %&gt;% filter(date_time_utc &gt; &#39;2017-01-01 00:00:00&#39;, date_time_utc &lt;= &#39;2017-10-01 00:00:00&#39;) monthly_mae_9y &lt;- bind_cols(date_time, y_pred, y_test) %&gt;% group_by(month(date_time_utc)) %&gt;% mutate(mae = MAE(y_pred, y_test)) %&gt;% select(date_time_utc, mae) monthly_mae_arima_9y_graph &lt;- ggplot(data = monthly_mae_9y, aes(x = month(date_time_utc), y = mae))+ geom_line() + theme_minimal() + ylim(0, 8) grid.arrange(y_pred_y_test_arima_9y_graph, residual_distribution_arima_9y_graph, residual_histogram_arima_9y_graph, monthly_mae_arima_9y_graph, ncol = 2) df &lt;- bind_cols(as.data.frame(y_pred), as.data.frame(y_test)) y_pred_y_test_arima_9y_graph &lt;- ggplot(data = df, aes(x = y_test, y = y_pred)) + geom_point(alpha = 0.5) + ylim(0, 100) + theme_minimal() grid.arrange(y_pred_y_test_base_model_graph + ggtitle(&quot;Base model&quot;), y_pred_y_test_arima_3m_graph + ggtitle(&quot;ARIMA 2016-10 - 2016-12&quot;), y_pred_y_test_arima_3y_graph + ggtitle(&quot;ARIMA 2014-01 - 2016-12&quot;), y_pred_y_test_arima_9y_graph + ggtitle(&quot;ARIMA 2009-01 - 2016-12&quot;), ncol=2) residual_distribution_arima_9y_graph &lt;- ggplot(data = df, aes(x = y_pred, y = (y_test - y_pred))) + geom_point() + geom_hline(yintercept=0) + geom_point(alpha = 0.5) + theme_minimal() grid.arrange(residual_distribution_base_model_graph + ggtitle(&quot;Base model&quot;), residual_distribution_arima_3m_graph + ggtitle(&quot;ARIMA 2016-10 - 2016-12&quot;), residual_distribution_arima_3y_graph+ ggtitle(&quot;ARIMA 2014-01 - 2016-12&quot;), residual_distribution_arima_9y_graph+ ggtitle(&quot;ARIMA 2009-01 - 2016-12&quot;), ncol=2) monthly_mae_9y_2 &lt;- monthly_mae_9y %&gt;% select(&#39;month(date_time_utc)&#39;, mae) %&gt;% unique() %&gt;% rename(month = &#39;month(date_time_utc)&#39;, model_arima_9y = mae) %&gt;% ungroup() %&gt;% mutate(month = as.factor(month)) monthly_mae_comparison &lt;- left_join(monthly_mae_comparison, monthly_mae_9y_2, by = &#39;month&#39;) monthly_mae_comparison_long &lt;- monthly_mae_comparison %&gt;% gather(model, mae, 2:5) monthly_mae_base_model_vs_arima3m_3y_9y_graph &lt;- ggplot(data = monthly_mae_comparison_long, aes(x = month, y = mae, col = model, group = model)) + geom_line() + theme_minimal() + ylim(0, 8) monthly_mae_base_model_vs_arima3m_3y_9y_graph ggsave(&quot;imgs/monthly_mae_base_model_vs_arima3m_3y_9y_graph.png&quot;) ggsave(&quot;imgs/monthly_mae_base_model_vs_arima3m_3y_9y_graph.jpg&quot;) 8.5.4 PM10 h = 6 So far, we made forecasts for one hour ahead and we estimated their precission. But what happens when we try to forecast more distant values? We use the model with better results. The PM10_model_arima_3y model (train: 2014-01-01 - 2016-12-31). PM10_model_arima_3y &lt;- readRDS(&quot;data_rds/PM10_model_arima_3y.rds&quot;) # We create the object arima.test with the Arima function arima.test &lt;- Arima(test_201701_201709, model=PM10_model_arima_3y) And with the fitted function, setting its parameter to 6, we fit and extract the fitted values corresponding to the forecast 6 hours ahead. # PM10_h6 &lt;- fitted(arima.test, h = 6) # It takes a lot of time # saveRDS(PM10_h6, &quot;data_rds/PM10_arima_model_3y_test_fitted_values_h6.rds&quot;) # We save the final object as a rds file fitted_values_h6 &lt;- readRDS(&quot;data_rds/PM10_arima_model_3y_test_fitted_values_h6.rds&quot;) We assign to y_test and y_pred the test dataset and its predictions. y_test &lt;- test_201701_201709 y_pred &lt;- fitted_values_h6 The first rows of y_pred are NAs. That is because we are making prediction 6 hours ahead. head(y_pred, 10) ## Time Series: ## Start = c(1, 1) ## End = c(1, 10) ## Frequency = 24 ## x ## [1,] NA ## [2,] NA ## [3,] NA ## [4,] NA ## [5,] NA ## [6,] NA ## [7,] NA ## [8,] 31.67340 ## [9,] 36.69984 ## [10,] 36.44485 So, we remove the NAs from the y_pred time series, and the equivalent rows from the y_test object. y_pred &lt;- y_pred %&gt;% na.omit() y_test &lt;- y_test %&gt;% subset(start = 8) And we obtain the scores to know the goodness of the model of 6 hours ahead RMSE &lt;- RMSE(y_test, y_pred) MAE &lt;- MAE(y_test, y_pred) rss &lt;- sum((y_test - y_pred) ** 2) tss &lt;- sum((y_test - mean(y_test)) ** 2) R_squared &lt;- 1 - rss/tss paste(c(&quot;R-squared:&quot;, round(R_squared, 4), &quot;MAE:&quot;, round(MAE, 2), &quot;RMSE:&quot;, round(RMSE, 2), &quot;Standard Deviation (test data):&quot;, round(sd_test, 2))) ## [1] &quot;R-squared:&quot; &quot;0.2118&quot; ## [3] &quot;MAE:&quot; &quot;7.12&quot; ## [5] &quot;RMSE:&quot; &quot;9.68&quot; ## [7] &quot;Standard Deviation (test data):&quot; &quot;10.9&quot; R-squared: 0.2118. When we try to predict the levels of PM10 6 hours ahead this Arima model is only able to explain a 21% of the variability. And consequentely the errors grow too. y_pred &lt;- as.data.frame(y_pred) %&gt;% rename(y_pred = x) y_test &lt;- as.data.frame(y_test) %&gt;% rename(y_test = x) df &lt;- bind_cols(y_pred, y_test) y_pred_y_test_arima_h6_graph &lt;- ggplot(data = df, aes(x = y_test, y = y_pred)) + geom_point(alpha = 0.5) + ylim(0, 100) + theme_minimal() residual_distribution_arima_h6_graph &lt;- ggplot(data = df, aes(x = y_pred, y = (y_test - y_pred))) + geom_point() + geom_hline(yintercept=0) + geom_point(alpha = 0.5) + theme_minimal() residual_histogram_arima_h6_graph &lt;- ggplot(data = df, aes(x = y_test - y_pred)) + geom_histogram() + theme_minimal() date_time &lt;- constitucion_data %&gt;% select(date_time_utc) %&gt;% filter(date_time_utc &gt; &#39;2017-01-01 00:00:00&#39;, date_time_utc &lt;= &#39;2017-10-01 00:00:00&#39;) %&gt;% slice(8:n()) monthly_mae_h6 &lt;- bind_cols(date_time, df) monthly_mae_h6$y_pred &lt;- as.numeric(monthly_mae_h6$y_pred) monthly_mae_h6$y_test &lt;- as.numeric(monthly_mae_h6$y_test) monthly_mae_h6 &lt;- monthly_mae_h6 %&gt;% group_by(month(date_time_utc)) %&gt;% mutate(mae = MAE(y_pred, y_test)) %&gt;% select(date_time_utc, mae) monthly_mae_arima_h6_graph &lt;- ggplot(data = monthly_mae_h6, aes(x = month(date_time_utc), y = mae))+ geom_line() + theme_minimal() + ylim(0, 10) grid.arrange(y_pred_y_test_arima_h6_graph, residual_distribution_arima_h6_graph, residual_histogram_arima_h6_graph, monthly_mae_arima_h6_graph, ncol = 2) 8.5.5 PM10 h = 12 # PM10_h12 &lt;- fitted(arima.test, h = 12) # It takes a lot of time # saveRDS(PM10_h12, &quot;data_rds/PM10_arima_model_3y_test_fitted_values_h12.rds&quot;) # We save the final object as a rds file fitted_values_h12 &lt;- readRDS(&quot;data_rds/PM10_arima_model_3y_test_fitted_values_h12.rds&quot;) # We assign to y_test and y_pred the test dataset and its predictions. y_test &lt;- test_201701_201709 y_pred &lt;- fitted_values_h12 # So, we remove the NAs from the y_pred time series, and the equivalent rows from the y_test object. y_pred &lt;- y_pred %&gt;% na.omit() y_test &lt;- y_test %&gt;% subset(start = 14) # And we obtain the scores to know the goodness of the model of 6 hours ahead RMSE &lt;- RMSE(y_test, y_pred) MAE &lt;- MAE(y_test, y_pred) rss &lt;- sum((y_test - y_pred) ** 2) tss &lt;- sum((y_test - mean(y_test)) ** 2) R_squared &lt;- 1 - rss/tss paste(c(&quot;R-squared:&quot;, round(R_squared, 4), &quot;MAE:&quot;, round(MAE, 2), &quot;RMSE:&quot;, round(RMSE, 2), &quot;Standard Deviation (test data):&quot;, round(sd_test, 2))) ## [1] &quot;R-squared:&quot; &quot;0.1108&quot; ## [3] &quot;MAE:&quot; &quot;7.64&quot; ## [5] &quot;RMSE:&quot; &quot;10.28&quot; ## [7] &quot;Standard Deviation (test data):&quot; &quot;10.9&quot; y_pred &lt;- as.data.frame(y_pred) %&gt;% rename(y_pred = x) y_test &lt;- as.data.frame(y_test) %&gt;% rename(y_test = x) df &lt;- bind_cols(y_pred, y_test) y_pred_y_test_arima_h12_graph &lt;- ggplot(data = df, aes(x = y_test, y = y_pred)) + geom_point(alpha = 0.5) + ylim(0, 100) + theme_minimal() residual_distribution_arima_h12_graph &lt;- ggplot(data = df, aes(x = y_pred, y = (y_test - y_pred))) + geom_point() + geom_hline(yintercept=0) + geom_point(alpha = 0.5) + theme_minimal() residual_histogram_arima_h12_graph &lt;- ggplot(data = df, aes(x = y_test - y_pred)) + geom_histogram() + theme_minimal() date_time &lt;- constitucion_data %&gt;% select(date_time_utc) %&gt;% filter(date_time_utc &gt; &#39;2017-01-01 00:00:00&#39;, date_time_utc &lt;= &#39;2017-10-01 00:00:00&#39;) %&gt;% slice(14:n()) monthly_mae_h12 &lt;- bind_cols(date_time, y_pred, y_test) monthly_mae_h12$y_pred &lt;- as.numeric(monthly_mae_h12$y_pred) monthly_mae_h12$y_test &lt;- as.numeric(monthly_mae_h12$y_test) monthly_mae_h12 &lt;- monthly_mae_h12 %&gt;% group_by(month(date_time_utc)) %&gt;% mutate(mae = MAE(y_pred, y_test)) %&gt;% select(date_time_utc, mae) monthly_mae_arima_h12_graph &lt;- ggplot(data = monthly_mae_h12, aes(x = month(date_time_utc), y = mae))+ geom_line() + theme_minimal() + ylim(0, 12) grid.arrange(y_pred_y_test_arima_h12_graph, residual_distribution_arima_h12_graph, residual_histogram_arima_h12_graph, monthly_mae_arima_h12_graph, ncol = 2) 8.5.6 PM10 h = 24 # PM10_h24 &lt;- fitted(arima.test, h = 24) # It takes a lot of time # saveRDS(PM10_h24, &quot;data_rds/PM10_arima_model_3y_test_fitted_values_h24.rds&quot;) # We save the final object as a rds file fitted_values_h24 &lt;- readRDS(&quot;data_rds/PM10_arima_model_3y_test_fitted_values_h24.rds&quot;) # We assign to y_test and y_pred the test dataset and its predictions. y_test &lt;- test_201701_201709 y_pred &lt;- fitted_values_h24 # So, we remove the NAs from the y_pred time series, and the equivalent rows from the y_test object. y_pred &lt;- y_pred %&gt;% na.omit() y_test &lt;- y_test %&gt;% subset(start = 26) # And we obtain the scores to know the goodness of the model of 6 hours ahead RMSE &lt;- RMSE(y_test, y_pred) MAE &lt;- MAE(y_test, y_pred) rss &lt;- sum((y_test - y_pred) ** 2) tss &lt;- sum((y_test - mean(y_test)) ** 2) R_squared &lt;- 1 - rss/tss paste(c(&quot;R-squared:&quot;, round(R_squared, 4), &quot;MAE:&quot;, round(MAE, 2), &quot;RMSE:&quot;, round(RMSE, 2), &quot;Standard Deviation (test data):&quot;, round(sd_test, 2))) ## [1] &quot;R-squared:&quot; &quot;0.0138&quot; ## [3] &quot;MAE:&quot; &quot;8.12&quot; ## [5] &quot;RMSE:&quot; &quot;10.83&quot; ## [7] &quot;Standard Deviation (test data):&quot; &quot;10.9&quot; y_pred &lt;- as.data.frame(y_pred) %&gt;% rename(y_pred = x) y_test &lt;- as.data.frame(y_test) %&gt;% rename(y_test = x) df &lt;- bind_cols(y_pred, y_test) y_pred_y_test_arima_h24_graph &lt;- ggplot(data = df, aes(x = y_test, y = y_pred)) + geom_point(alpha = 0.5) + ylim(0, 100) + theme_minimal() residual_distribution_arima_h24_graph &lt;- ggplot(data = df, aes(x = y_pred, y = (y_test - y_pred))) + geom_point() + geom_hline(yintercept=0) + geom_point(alpha = 0.5) + theme_minimal() residual_histogram_arima_h24_graph &lt;- ggplot(data = df, aes(x = y_test - y_pred)) + geom_histogram() + theme_minimal() date_time &lt;- constitucion_data %&gt;% select(date_time_utc) %&gt;% filter(date_time_utc &gt; &#39;2017-01-01 00:00:00&#39;, date_time_utc &lt;= &#39;2017-10-01 00:00:00&#39;) %&gt;% slice(26:n()) monthly_mae_h24 &lt;- bind_cols(date_time, y_pred, y_test) monthly_mae_h24$y_pred &lt;- as.numeric(monthly_mae_h24$y_pred) monthly_mae_h24$y_test &lt;- as.numeric(monthly_mae_h24$y_test) monthly_mae_h24 &lt;- monthly_mae_h24 %&gt;% group_by(month(date_time_utc)) %&gt;% mutate(mae = MAE(y_pred, y_test)) %&gt;% select(date_time_utc, mae) monthly_mae_arima_h24_graph &lt;- ggplot(data = monthly_mae_h24, aes(x = month(date_time_utc), y = mae))+ geom_line() + theme_minimal() + ylim(0, 15) grid.arrange(y_pred_y_test_arima_h24_graph, residual_distribution_arima_h24_graph, residual_histogram_arima_h24_graph, monthly_mae_arima_h24_graph, ncol = 2) PM10_ARIMA_results &lt;- read_csv(&quot;data_final_csvs/PM10_ARIMA_results.csv&quot;) PM10_ARIMA_results_table &lt;- kable( PM10_ARIMA_results, booktabs = TRUE, caption = &#39;ARIMA models results for the PM10 pollutant&#39; ) PM10_ARIMA_results_table Table 8.1: ARIMA models results for the PM10 pollutant Model type Target variable Prediction horizon Train period Test period R-Squared MAE Model detail Auto regressive (Base model) PM10 1 hour 201701-201709 0.5327 5.15 PM10t = PM10(t-1) ARIMA PM10 1 hour 201610-201612 201701-201709 0.5975 4.88 ARIMA(2,1,4)(0,0,2)[24] ARIMA PM10 1 hour 201401-201612 201701-201709 0.6015 4.84 ARIMA(2,1,3)(0,0,2)[24] ARIMA PM10 1 hour 200901_201612 201701-201709 0.5966 4.88 ARIMA(3,1,2)(0,0,2)[24] ARIMA PM10 6 hours 201401-201612 201701-201709 0.2118 7.12 ARIMA(2,1,3)(0,0,2)[24] ARIMA PM10 12 hours 201401-201612 201701-201709 0.1108 7.64 ARIMA(2,1,3)(0,0,2)[24] ARIMA PM10 24 hours 201401-201612 201701-201709 0.0138 10.90 ARIMA(2,1,3)(0,0,2)[24] "],
["python-scripts.html", "Python scripts", " Python scripts “21_Forecasting_Models_ML_PM10_AR.ipynb” Google Colab Notebook link “21_Forecasting_Models_ML_PM10_AR.ipynb” “22_Forecasting_Models_ML_PM10_MULTIVAR.ipynb” Google Colab Notebook link “21_Forecasting_Models_ML_PM10_AR.ipynb” “23_Forecasting_Models_ML_NO2_MULTIVAR” Google Colab Notebook link “21_Forecasting_Models_ML_PM10_AR.ipynb” "]
]
