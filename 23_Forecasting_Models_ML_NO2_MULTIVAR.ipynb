{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "23_Forecasting_Models_ML_NO2_MULTIVAR.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sergioberdiales/TFM_KSchool_Gijon_Air_Pollution/blob/master/23_Forecasting_Models_ML_NO2_MULTIVAR.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "C2KUABWEp4T6",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "In this notebook we are going to try to improve the forecasts creating multivariate models. \n",
        "We will use the XGBoost algorithm and the three years training period (2014-01-01 - 2016-12-31).\n",
        "Testing period: 2017-01-01 - 2017-09-30. "
      ]
    },
    {
      "metadata": {
        "id": "i-4Gs37dWIA0",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### We import the libraries we need to run the algorithms"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "outputId": "ede1e58f-d7fc-4780-ebce-c0d12664ce1c",
        "id": "OxJRU8VLpp9W",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "cell_type": "code",
      "source": [
        "%pylab inline\n",
        "import pandas as pd\n",
        "\n",
        "# We install and import pyreadr, in order to read rds objects.  \n",
        "# https://github.com/ofajardo/pyreadr\n",
        "\n",
        "!pip install pyreadr\n",
        "import pyreadr\n",
        "\n",
        "\n",
        "# Importing models\n",
        "\n",
        "\n",
        "import statsmodels.api as sm\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from xgboost import XGBRegressor\n",
        "import os\n",
        "os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\"\n",
        "\n",
        "# Importing metrics\n",
        "\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "from sklearn.metrics import r2_score\n",
        "\n",
        "# Model selection\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# Variable selection\n",
        "\n",
        "import sklearn\n",
        "from sklearn.feature_selection import f_regression\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Populating the interactive namespace from numpy and matplotlib\n",
            "Requirement already satisfied: pyreadr in /usr/local/lib/python3.6/dist-packages (0.1.6)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/compat/pandas.py:56: FutureWarning: The pandas.core.datetools module is deprecated and will be removed in a future version. Please use the pandas.tseries module instead.\n",
            "  from pandas.core import datetools\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "adowIIZEus6d",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "Dh0qqPFMpp9d"
      },
      "cell_type": "markdown",
      "source": [
        "We upload the train and test data. All rds files from this folder  ~\\`TFM_KSchool_Gijon_Air_Pollution\\train_test\\\n",
        "Forecasting_Models_ML_NO2\n",
        "\n",
        "The train and test datasets were generated running this rmd file \"_10_2_train_test_MULTIVAR_datasets.rmd\""
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "gWOu3DSopp9e",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "uploaded = files.upload()\n",
        "\n",
        "for fn in uploaded.keys():\n",
        "  print('User uploaded file \"{name}\" with length {length} bytes'.format(\n",
        "      name=fn, length=len(uploaded[fn])))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kV-EfqxNtTqI",
        "colab_type": "code",
        "outputId": "58a03ec2-4385-4908-c4bb-1041f66b6685",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "sample_data\n",
            "X_test_NO2_20170101_20170114_multivar.rds\n",
            "X_test_NO2_201701_201709_multivar.rds\n",
            "X_train_NO2_200901_201612_multivar.rds\n",
            "X_train_NO2_201401_201612_multivar.rds\n",
            "X_train_NO2_201610_201612_multivar.rds\n",
            "X_validation_NO2_201710_201712_multivar.rds\n",
            "y_test_NO2_20170101_20170114_multivar.rds\n",
            "y_test_NO2_201701_201709_multivar.rds\n",
            "y_train_NO2_200901_201612_multivar.rds\n",
            "y_train_NO2_201401_201612_multivar.rds\n",
            "y_train_NO2_201610_201612_multivar.rds\n",
            "y_validation_NO2_201710_201712_multivar.rds\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "hmOhVnHk4lGx",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### aLL THE VARIABLES "
      ]
    },
    {
      "metadata": {
        "id": "oytAsB0os3OL",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# NO2 forecasts auto regressive models\n",
        "Only NO2 lagged values"
      ]
    },
    {
      "metadata": {
        "id": "kK1hRo93OzCi",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### XGBOOST"
      ]
    },
    {
      "metadata": {
        "id": "BJQ_OmsOwo6a",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Variables selection"
      ]
    },
    {
      "metadata": {
        "id": "CYJF87J0dres",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1072
        },
        "outputId": "991d6ac5-f630-41aa-a678-fbf9633ba639"
      },
      "cell_type": "code",
      "source": [
        "X_train = pyreadr.read_r(\"X_train_NO2_201401_201612_multivar.rds\")\n",
        "y_train = pyreadr.read_r(\"y_train_NO2_201401_201612_multivar.rds\")\n",
        "\n",
        "X_test = pyreadr.read_r(\"X_test_NO2_201701_201709_multivar.rds\")\n",
        "y_test = pyreadr.read_r(\"y_test_NO2_201701_201709_multivar.rds\")\n",
        "\n",
        "X_train = X_train[None]\n",
        "y_train = y_train[None]\n",
        "X_test = X_test[None]\n",
        "y_test = y_test[None]\n",
        "\n",
        "# We select only the lagged variables of the NO2 pollutant\n",
        "X_train = X_train.loc[:, X_train.columns.str.startswith('NO2')]\n",
        "\n",
        "X_test = X_test.loc[:, X_train.columns.str.startswith('NO2')]\n",
        "\n",
        "\n",
        "results = sm.OLS(y_train, X_train).fit()\n",
        "\n",
        "results_summary = results.summary()\n",
        "\n",
        "# We extract the table with the variables, coefficientes, p-values, etc.\n",
        "\n",
        "results_as_html = results_summary.tables[1].as_html()\n",
        "table_p = pd.read_html(results_as_html, header=0, index_col=0)[0]\n",
        "table_p\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>coef</th>\n",
              "      <th>std err</th>\n",
              "      <th>t</th>\n",
              "      <th>P&gt;|t|</th>\n",
              "      <th>[0.025</th>\n",
              "      <th>0.975]</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>NO2_1</th>\n",
              "      <td>0.8980</td>\n",
              "      <td>0.006</td>\n",
              "      <td>143.597</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.886</td>\n",
              "      <td>0.910</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>NO2_2</th>\n",
              "      <td>-0.1225</td>\n",
              "      <td>0.008</td>\n",
              "      <td>-14.620</td>\n",
              "      <td>0.000</td>\n",
              "      <td>-0.139</td>\n",
              "      <td>-0.106</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>NO2_3</th>\n",
              "      <td>0.0083</td>\n",
              "      <td>0.008</td>\n",
              "      <td>0.985</td>\n",
              "      <td>0.325</td>\n",
              "      <td>-0.008</td>\n",
              "      <td>0.025</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>NO2_4</th>\n",
              "      <td>-0.0122</td>\n",
              "      <td>0.008</td>\n",
              "      <td>-1.459</td>\n",
              "      <td>0.145</td>\n",
              "      <td>-0.029</td>\n",
              "      <td>0.004</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>NO2_5</th>\n",
              "      <td>0.0160</td>\n",
              "      <td>0.008</td>\n",
              "      <td>1.907</td>\n",
              "      <td>0.056</td>\n",
              "      <td>-0.000</td>\n",
              "      <td>0.032</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>NO2_6</th>\n",
              "      <td>-0.0119</td>\n",
              "      <td>0.008</td>\n",
              "      <td>-1.422</td>\n",
              "      <td>0.155</td>\n",
              "      <td>-0.028</td>\n",
              "      <td>0.005</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>NO2_7</th>\n",
              "      <td>0.0001</td>\n",
              "      <td>0.008</td>\n",
              "      <td>0.013</td>\n",
              "      <td>0.990</td>\n",
              "      <td>-0.016</td>\n",
              "      <td>0.017</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>NO2_8</th>\n",
              "      <td>0.0094</td>\n",
              "      <td>0.008</td>\n",
              "      <td>1.119</td>\n",
              "      <td>0.263</td>\n",
              "      <td>-0.007</td>\n",
              "      <td>0.026</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>NO2_9</th>\n",
              "      <td>-0.0032</td>\n",
              "      <td>0.008</td>\n",
              "      <td>-0.379</td>\n",
              "      <td>0.705</td>\n",
              "      <td>-0.020</td>\n",
              "      <td>0.013</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>NO2_10</th>\n",
              "      <td>0.0366</td>\n",
              "      <td>0.008</td>\n",
              "      <td>4.374</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.020</td>\n",
              "      <td>0.053</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>NO2_11</th>\n",
              "      <td>0.0188</td>\n",
              "      <td>0.008</td>\n",
              "      <td>2.236</td>\n",
              "      <td>0.025</td>\n",
              "      <td>0.002</td>\n",
              "      <td>0.035</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>NO2_12</th>\n",
              "      <td>0.0042</td>\n",
              "      <td>0.008</td>\n",
              "      <td>0.499</td>\n",
              "      <td>0.618</td>\n",
              "      <td>-0.012</td>\n",
              "      <td>0.021</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>NO2_13</th>\n",
              "      <td>-0.0016</td>\n",
              "      <td>0.008</td>\n",
              "      <td>-0.195</td>\n",
              "      <td>0.845</td>\n",
              "      <td>-0.018</td>\n",
              "      <td>0.015</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>NO2_14</th>\n",
              "      <td>-0.0132</td>\n",
              "      <td>0.008</td>\n",
              "      <td>-1.569</td>\n",
              "      <td>0.117</td>\n",
              "      <td>-0.030</td>\n",
              "      <td>0.003</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>NO2_15</th>\n",
              "      <td>-0.0222</td>\n",
              "      <td>0.008</td>\n",
              "      <td>-2.646</td>\n",
              "      <td>0.008</td>\n",
              "      <td>-0.039</td>\n",
              "      <td>-0.006</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>NO2_16</th>\n",
              "      <td>-0.0118</td>\n",
              "      <td>0.008</td>\n",
              "      <td>-1.407</td>\n",
              "      <td>0.159</td>\n",
              "      <td>-0.028</td>\n",
              "      <td>0.005</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>NO2_17</th>\n",
              "      <td>0.0027</td>\n",
              "      <td>0.008</td>\n",
              "      <td>0.325</td>\n",
              "      <td>0.745</td>\n",
              "      <td>-0.014</td>\n",
              "      <td>0.019</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>NO2_18</th>\n",
              "      <td>0.0077</td>\n",
              "      <td>0.008</td>\n",
              "      <td>0.916</td>\n",
              "      <td>0.360</td>\n",
              "      <td>-0.009</td>\n",
              "      <td>0.024</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>NO2_19</th>\n",
              "      <td>0.0077</td>\n",
              "      <td>0.008</td>\n",
              "      <td>0.917</td>\n",
              "      <td>0.359</td>\n",
              "      <td>-0.009</td>\n",
              "      <td>0.024</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>NO2_20</th>\n",
              "      <td>-0.0066</td>\n",
              "      <td>0.008</td>\n",
              "      <td>-0.788</td>\n",
              "      <td>0.430</td>\n",
              "      <td>-0.023</td>\n",
              "      <td>0.010</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>NO2_21</th>\n",
              "      <td>0.0035</td>\n",
              "      <td>0.008</td>\n",
              "      <td>0.415</td>\n",
              "      <td>0.678</td>\n",
              "      <td>-0.013</td>\n",
              "      <td>0.020</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>NO2_22</th>\n",
              "      <td>0.0572</td>\n",
              "      <td>0.008</td>\n",
              "      <td>6.810</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.041</td>\n",
              "      <td>0.074</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>NO2_23</th>\n",
              "      <td>0.0578</td>\n",
              "      <td>0.008</td>\n",
              "      <td>6.866</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.041</td>\n",
              "      <td>0.074</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>NO2_24</th>\n",
              "      <td>0.0614</td>\n",
              "      <td>0.008</td>\n",
              "      <td>7.280</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.045</td>\n",
              "      <td>0.078</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>NO2_25</th>\n",
              "      <td>-0.0426</td>\n",
              "      <td>0.008</td>\n",
              "      <td>-5.056</td>\n",
              "      <td>0.000</td>\n",
              "      <td>-0.059</td>\n",
              "      <td>-0.026</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>NO2_26</th>\n",
              "      <td>-0.0306</td>\n",
              "      <td>0.008</td>\n",
              "      <td>-3.641</td>\n",
              "      <td>0.000</td>\n",
              "      <td>-0.047</td>\n",
              "      <td>-0.014</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>NO2_27</th>\n",
              "      <td>-0.0462</td>\n",
              "      <td>0.006</td>\n",
              "      <td>-7.545</td>\n",
              "      <td>0.000</td>\n",
              "      <td>-0.058</td>\n",
              "      <td>-0.034</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>NO2_48</th>\n",
              "      <td>0.0240</td>\n",
              "      <td>0.004</td>\n",
              "      <td>6.586</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.017</td>\n",
              "      <td>0.031</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>NO2_72</th>\n",
              "      <td>0.0157</td>\n",
              "      <td>0.004</td>\n",
              "      <td>4.338</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.009</td>\n",
              "      <td>0.023</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>NO2_96</th>\n",
              "      <td>0.0150</td>\n",
              "      <td>0.004</td>\n",
              "      <td>4.158</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.008</td>\n",
              "      <td>0.022</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>NO2_120</th>\n",
              "      <td>0.0104</td>\n",
              "      <td>0.004</td>\n",
              "      <td>2.870</td>\n",
              "      <td>0.004</td>\n",
              "      <td>0.003</td>\n",
              "      <td>0.017</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>NO2_144</th>\n",
              "      <td>0.0236</td>\n",
              "      <td>0.004</td>\n",
              "      <td>6.551</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.017</td>\n",
              "      <td>0.031</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>NO2_168</th>\n",
              "      <td>0.0455</td>\n",
              "      <td>0.004</td>\n",
              "      <td>12.965</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.039</td>\n",
              "      <td>0.052</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           coef  std err        t  P>|t|  [0.025  0.975]\n",
              "NO2_1    0.8980    0.006  143.597  0.000   0.886   0.910\n",
              "NO2_2   -0.1225    0.008  -14.620  0.000  -0.139  -0.106\n",
              "NO2_3    0.0083    0.008    0.985  0.325  -0.008   0.025\n",
              "NO2_4   -0.0122    0.008   -1.459  0.145  -0.029   0.004\n",
              "NO2_5    0.0160    0.008    1.907  0.056  -0.000   0.032\n",
              "NO2_6   -0.0119    0.008   -1.422  0.155  -0.028   0.005\n",
              "NO2_7    0.0001    0.008    0.013  0.990  -0.016   0.017\n",
              "NO2_8    0.0094    0.008    1.119  0.263  -0.007   0.026\n",
              "NO2_9   -0.0032    0.008   -0.379  0.705  -0.020   0.013\n",
              "NO2_10   0.0366    0.008    4.374  0.000   0.020   0.053\n",
              "NO2_11   0.0188    0.008    2.236  0.025   0.002   0.035\n",
              "NO2_12   0.0042    0.008    0.499  0.618  -0.012   0.021\n",
              "NO2_13  -0.0016    0.008   -0.195  0.845  -0.018   0.015\n",
              "NO2_14  -0.0132    0.008   -1.569  0.117  -0.030   0.003\n",
              "NO2_15  -0.0222    0.008   -2.646  0.008  -0.039  -0.006\n",
              "NO2_16  -0.0118    0.008   -1.407  0.159  -0.028   0.005\n",
              "NO2_17   0.0027    0.008    0.325  0.745  -0.014   0.019\n",
              "NO2_18   0.0077    0.008    0.916  0.360  -0.009   0.024\n",
              "NO2_19   0.0077    0.008    0.917  0.359  -0.009   0.024\n",
              "NO2_20  -0.0066    0.008   -0.788  0.430  -0.023   0.010\n",
              "NO2_21   0.0035    0.008    0.415  0.678  -0.013   0.020\n",
              "NO2_22   0.0572    0.008    6.810  0.000   0.041   0.074\n",
              "NO2_23   0.0578    0.008    6.866  0.000   0.041   0.074\n",
              "NO2_24   0.0614    0.008    7.280  0.000   0.045   0.078\n",
              "NO2_25  -0.0426    0.008   -5.056  0.000  -0.059  -0.026\n",
              "NO2_26  -0.0306    0.008   -3.641  0.000  -0.047  -0.014\n",
              "NO2_27  -0.0462    0.006   -7.545  0.000  -0.058  -0.034\n",
              "NO2_48   0.0240    0.004    6.586  0.000   0.017   0.031\n",
              "NO2_72   0.0157    0.004    4.338  0.000   0.009   0.023\n",
              "NO2_96   0.0150    0.004    4.158  0.000   0.008   0.022\n",
              "NO2_120  0.0104    0.004    2.870  0.004   0.003   0.017\n",
              "NO2_144  0.0236    0.004    6.551  0.000   0.017   0.031\n",
              "NO2_168  0.0455    0.004   12.965  0.000   0.039   0.052"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "metadata": {
        "id": "UVoTWIfZyHds",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        ""
      ]
    },
    {
      "metadata": {
        "id": "ISmFPWzzdqXe",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 1 **hour** ahead"
      ]
    },
    {
      "metadata": {
        "id": "a-qac8vAo_dy",
        "colab_type": "code",
        "outputId": "fe47f1c6-a168-4b6a-e626-364810c2611d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "cell_type": "code",
      "source": [
        "X_train = pyreadr.read_r(\"X_train_NO2_201401_201612_multivar.rds\")\n",
        "y_train = pyreadr.read_r(\"y_train_NO2_201401_201612_multivar.rds\")\n",
        "\n",
        "X_test = pyreadr.read_r(\"X_test_NO2_201701_201709_multivar.rds\")\n",
        "y_test = pyreadr.read_r(\"y_test_NO2_201701_201709_multivar.rds\")\n",
        "\n",
        "X_train = X_train[None]\n",
        "y_train = y_train[None]\n",
        "X_test = X_test[None]\n",
        "y_test = y_test[None]\n",
        "\n",
        "X_train = X_train[['NO2_1', 'NO2_2', 'NO2_10', 'NO2_11', 'NO2_22', 'NO2_23', 'NO2_24',\n",
        "                   'NO2_25', 'NO2_26', 'NO2_27','NO2_48', 'NO2_72', 'NO2_96', 'NO2_120', 'NO2_144', 'NO2_168']]\n",
        "X_test = X_test[['NO2_1', 'NO2_2', 'NO2_10', 'NO2_11',  'NO2_22', 'NO2_23', 'NO2_24',\n",
        "                   'NO2_25', 'NO2_26', 'NO2_27','NO2_48', 'NO2_72', 'NO2_96', 'NO2_120', 'NO2_144', 'NO2_168']]\n",
        "\n",
        "\n",
        "\n",
        "regXGB = XGBRegressor(n_estimators=100, min_samples_leaf=10,max_depth=2, random_state=42)\n",
        "regXGB.fit(X_train,y_train)\n",
        "\n",
        "\n",
        "# Compute train scores\n",
        "\n",
        "y_pred = regXGB.predict(X_train)\n",
        "\n",
        "r2_train = r2_score(y_train, y_pred)\n",
        "rmse_train = np.sqrt(mean_squared_error(y_train, y_pred))\n",
        "mae_train = mean_absolute_error(y_train, y_pred)\n",
        "r2_adjusted_train = 1 - (1-r2_score(y_train, y_pred))*(len(y_train)-1)/(len(y_train)-X_train.shape[1]-1)\n",
        "sd_train = std(y_train)\n",
        "\n",
        "print(\"R^2 train: {}\".format(r2_train))\n",
        "print(\"R^2 adjusted train: {}\".format(r2_adjusted_train))\n",
        "print(\"Mean Absolute Error train: {}\".format(mae_train))\n",
        "print(\"Root Mean Squared Error train: {}\".format(rmse_train)) \n",
        "print(\"Standard Deviation train: {}\".format(sd_train))  \n",
        "\n",
        "# Compute test scores\n",
        "\n",
        "y_pred = regXGB.predict(X_test)\n",
        "\n",
        "r2_test = r2_score(y_test, y_pred)\n",
        "rmse_test = np.sqrt(mean_squared_error(y_test, y_pred))\n",
        "mae_test = mean_absolute_error(y_test, y_pred)\n",
        "r2_adjusted_test = 1 - (1-r2_score(y_test, y_pred))*(len(y_test)-1)/(len(y_test)-X_test.shape[1]-1)\n",
        "sd_test = std(y_test)\n",
        "\n",
        "print(\"R^2 test: {}\".format(r2_test))\n",
        "print(\"R^2 adjusted test: {}\".format(r2_adjusted_test))\n",
        "print(\"Mean Absolute Error test: {}\".format(mae_test))\n",
        "print(\"Root Mean Squared Error test: {}\".format(rmse_test))\n",
        "print(\"Standard Deviation test: {}\".format(sd_test))  \n"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "R^2 train: 0.8196088276734563\n",
            "R^2 adjusted train: 0.8194971778820663\n",
            "Mean Absolute Error train: 4.612765113046078\n",
            "Root Mean Squared Error train: 6.587182227288358\n",
            "Standard Deviation train: NO2_0    15.509294\n",
            "dtype: float64\n",
            "R^2 test: 0.7611771043535913\n",
            "R^2 adjusted test: 0.7605768583073547\n",
            "Mean Absolute Error test: 5.877690026111055\n",
            "Root Mean Squared Error test: 9.019362585841288\n",
            "Standard Deviation test: NO2_0    18.456012\n",
            "dtype: float64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "tPEnjv9ChFzl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "21b3aa45-1627-494c-ee8f-3c548f3735f7"
      },
      "cell_type": "code",
      "source": [
        "X_train = pyreadr.read_r(\"X_train_NO2_201401_201612_multivar.rds\")\n",
        "y_train = pyreadr.read_r(\"y_train_NO2_201401_201612_multivar.rds\")\n",
        "\n",
        "X_test = pyreadr.read_r(\"X_test_NO2_201701_201709_multivar.rds\")\n",
        "y_test = pyreadr.read_r(\"y_test_NO2_201701_201709_multivar.rds\")\n",
        "\n",
        "X_train = X_train[None]\n",
        "y_train = y_train[None]\n",
        "X_test = X_test[None]\n",
        "y_test = y_test[None]\n",
        "\n",
        "X_train = X_train[['NO2_1', 'NO2_2', 'NO2_10', 'NO2_11', 'NO2_22', 'NO2_23', 'NO2_24',\n",
        "                   'NO2_25', 'NO2_26', 'NO2_27','NO2_48', 'NO2_72', 'NO2_96', 'NO2_120', 'NO2_144', 'NO2_168']]\n",
        "X_test = X_test[['NO2_1', 'NO2_2', 'NO2_10', 'NO2_11',  'NO2_22', 'NO2_23', 'NO2_24',\n",
        "                   'NO2_25', 'NO2_26', 'NO2_27','NO2_48', 'NO2_72', 'NO2_96', 'NO2_120', 'NO2_144', 'NO2_168']]\n",
        "\n",
        "\n",
        "\n",
        "regXGB = XGBRegressor(n_estimators=100, min_samples_leaf=10,max_depth=2, random_state=42)\n",
        "regXGB.fit(X_train,y_train)\n",
        "\n",
        "\n",
        "# Compute train scores\n",
        "\n",
        "y_pred = regXGB.predict(X_train)\n",
        "\n",
        "r2_train = r2_score(y_train, y_pred)\n",
        "rmse_train = np.sqrt(mean_squared_error(y_train, y_pred))\n",
        "mae_train = mean_absolute_error(y_train, y_pred)\n",
        "r2_adjusted_train = 1 - (1-r2_score(y_train, y_pred))*(len(y_train)-1)/(len(y_train)-X_train.shape[1]-1)\n",
        "sd_train = std(y_train)\n",
        "\n",
        "print(\"R^2 train: {}\".format(r2_train))\n",
        "print(\"R^2 adjusted train: {}\".format(r2_adjusted_train))\n",
        "print(\"Mean Absolute Error train: {}\".format(mae_train))\n",
        "print(\"Root Mean Squared Error train: {}\".format(rmse_train)) \n",
        "print(\"Standard Deviation train: {}\".format(sd_train))  \n",
        "\n",
        "# Compute test scores\n",
        "\n",
        "y_pred = regXGB.predict(X_test)\n",
        "\n",
        "r2_test = r2_score(y_test, y_pred)\n",
        "rmse_test = np.sqrt(mean_squared_error(y_test, y_pred))\n",
        "mae_test = mean_absolute_error(y_test, y_pred)\n",
        "r2_adjusted_test = 1 - (1-r2_score(y_test, y_pred))*(len(y_test)-1)/(len(y_test)-X_test.shape[1]-1)\n",
        "sd_test = std(y_test)\n",
        "\n",
        "print(\"R^2 test: {}\".format(r2_test))\n",
        "print(\"R^2 adjusted test: {}\".format(r2_adjusted_test))\n",
        "print(\"Mean Absolute Error test: {}\".format(mae_test))\n",
        "print(\"Root Mean Squared Error test: {}\".format(rmse_test))\n",
        "print(\"Standard Deviation test: {}\".format(sd_test))  "
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "R^2 train: 0.8196088276734563\n",
            "R^2 adjusted train: 0.8194971778820663\n",
            "Mean Absolute Error train: 4.612765113046078\n",
            "Root Mean Squared Error train: 6.587182227288358\n",
            "Standard Deviation train: NO2_0    15.509294\n",
            "dtype: float64\n",
            "R^2 test: 0.7611771043535913\n",
            "R^2 adjusted test: 0.7605768583073547\n",
            "Mean Absolute Error test: 5.877690026111055\n",
            "Root Mean Squared Error test: 9.019362585841288\n",
            "Standard Deviation test: NO2_0    18.456012\n",
            "dtype: float64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "kwzb51Vaw3yk",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 2 hours ahead"
      ]
    },
    {
      "metadata": {
        "id": "BTz7Rp_sw376",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "27fc4e74-f578-41e0-d4f5-50968b2db5ab"
      },
      "cell_type": "code",
      "source": [
        "X_train = pyreadr.read_r(\"X_train_NO2_201401_201612_multivar.rds\")\n",
        "y_train = pyreadr.read_r(\"y_train_NO2_201401_201612_multivar.rds\")\n",
        "\n",
        "X_test = pyreadr.read_r(\"X_test_NO2_201701_201709_multivar.rds\")\n",
        "y_test = pyreadr.read_r(\"y_test_NO2_201701_201709_multivar.rds\")\n",
        "\n",
        "X_train = X_train[None]\n",
        "y_train = y_train[None]\n",
        "X_test = X_test[None]\n",
        "y_test = y_test[None]\n",
        "\n",
        "# We convert the 'hour' variable to string\n",
        "X_train.hour = X_train.hour.astype(str)\n",
        "X_test.hour = X_test.hour.astype(str)\n",
        "\n",
        "# We convert the 'week_day' variable to string\n",
        "X_train.week_day = X_train.week_day.astype(str)\n",
        "X_test.week_day = X_test.week_day.astype(str)\n",
        "\n",
        "# We convert the 'month' variable to string\n",
        "X_train.month = X_train.month.astype(str)\n",
        "X_test.month = X_test.month.astype(str)\n",
        "\n",
        "X_train = X_train[[ 'NO2_2', 'NO2_10', 'NO2_11', 'NO2_22', 'NO2_23', 'NO2_24',\n",
        "                   'NO2_25', 'NO2_26', 'NO2_27','NO2_48', 'NO2_72', 'NO2_96', 'NO2_120', 'NO2_144', 'NO2_168']]\n",
        "\n",
        "X_test = X_test[['NO2_2', 'NO2_10', 'NO2_11', 'NO2_22', 'NO2_23', 'NO2_24',\n",
        "                   'NO2_25', 'NO2_26', 'NO2_27','NO2_48', 'NO2_72', 'NO2_96', 'NO2_120', 'NO2_144', 'NO2_168']]\n",
        "\n",
        "X_train = pd.get_dummies(X_train)\n",
        "X_test  = pd.get_dummies(X_test)\n",
        "\n",
        "\n",
        "# Al hacer el one hot encoding el X_train y el X_test tienen distintas dimensiones. X_train tiene 47 variables y X_test 44. Por que? Porque el dataset de test tiene solo 9 meses, de enero a septiembre, y entonces la variable month solo se convierte en 9 variables, mientras que el dataset tendriamos 12, los 12 meses del anho. \n",
        "# Con el siguiente codigo solucionamos el problema (falta referencia)\n",
        "\n",
        "# Get missing columns in the training test\n",
        "missing_cols = set( X_train.columns ) - set( X_test.columns )\n",
        "# Add a missing column in test set with default value equal to 0\n",
        "for c in missing_cols:\n",
        "    X_test[c] = 0\n",
        "# Ensure the order of column in the test set is in the same order than in train set\n",
        "X_test = X_test[X_train.columns]\n",
        "# This code also ensure that column resulting from category in the test dataset but not present in the training dataset will be removed\n",
        "\n",
        "\n",
        "regXGB = XGBRegressor(n_estimators=100, min_samples_leaf=10,max_depth=2, random_state=42)\n",
        "regXGB.fit(X_train,y_train)\n",
        "\n",
        "\n",
        "# Compute train scores\n",
        "\n",
        "y_pred = regXGB.predict(X_train)\n",
        "\n",
        "r2_train = r2_score(y_train, y_pred)\n",
        "rmse_train = np.sqrt(mean_squared_error(y_train, y_pred))\n",
        "mae_train = mean_absolute_error(y_train, y_pred)\n",
        "r2_adjusted_train = 1 - (1-r2_score(y_train, y_pred))*(len(y_train)-1)/(len(y_train)-X_train.shape[1]-1)\n",
        "sd_train = std(y_train)\n",
        "\n",
        "print(\"R^2 train: {}\".format(r2_train))\n",
        "print(\"R^2 adjusted train: {}\".format(r2_adjusted_train))\n",
        "print(\"Mean Absolute Error train: {}\".format(mae_train))\n",
        "print(\"Root Mean Squared Error train: {}\".format(rmse_train)) \n",
        "print(\"Standard Deviation train: {}\".format(sd_train))  \n",
        "\n",
        "# Compute test scores\n",
        "\n",
        "y_pred = regXGB.predict(X_test)\n",
        "\n",
        "r2_test = r2_score(y_test, y_pred)\n",
        "rmse_test = np.sqrt(mean_squared_error(y_test, y_pred))\n",
        "mae_test = mean_absolute_error(y_test, y_pred)\n",
        "r2_adjusted_test = 1 - (1-r2_score(y_test, y_pred))*(len(y_test)-1)/(len(y_test)-X_test.shape[1]-1)\n",
        "sd_test = std(y_test)\n",
        "\n",
        "print(\"R^2 test: {}\".format(r2_test))\n",
        "print(\"R^2 adjusted test: {}\".format(r2_adjusted_test))\n",
        "print(\"Mean Absolute Error test: {}\".format(mae_test))\n",
        "print(\"Root Mean Squared Error test: {}\".format(rmse_test))\n",
        "print(\"Standard Deviation test: {}\".format(sd_test)) "
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "R^2 train: 0.6787248499472722\n",
            "R^2 adjusted train: 0.6785384377837727\n",
            "Mean Absolute Error train: 6.350930068143664\n",
            "Root Mean Squared Error train: 8.790844641943044\n",
            "Standard Deviation train: NO2_0    15.509294\n",
            "dtype: float64\n",
            "R^2 test: 0.5955976751835792\n",
            "R^2 adjusted test: 0.5946449447183293\n",
            "Mean Absolute Error test: 8.101517691879275\n",
            "Root Mean Squared Error test: 11.736664446889112\n",
            "Standard Deviation test: NO2_0    18.456012\n",
            "dtype: float64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Y2vi0PWVw4Iw",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 6 hours ahead"
      ]
    },
    {
      "metadata": {
        "id": "XwRFqznHw4Qt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "0f6ef58f-8717-4de8-f35a-ad7c5682b13b"
      },
      "cell_type": "code",
      "source": [
        "X_train = pyreadr.read_r(\"X_train_NO2_201401_201612_multivar.rds\")\n",
        "y_train = pyreadr.read_r(\"y_train_NO2_201401_201612_multivar.rds\")\n",
        "\n",
        "X_test = pyreadr.read_r(\"X_test_NO2_201701_201709_multivar.rds\")\n",
        "y_test = pyreadr.read_r(\"y_test_NO2_201701_201709_multivar.rds\")\n",
        "\n",
        "X_train = X_train[None]\n",
        "y_train = y_train[None]\n",
        "X_test = X_test[None]\n",
        "y_test = y_test[None]\n",
        "\n",
        "# We convert the 'hour' variable to string\n",
        "X_train.hour = X_train.hour.astype(str)\n",
        "X_test.hour = X_test.hour.astype(str)\n",
        "\n",
        "# We convert the 'week_day' variable to string\n",
        "X_train.week_day = X_train.week_day.astype(str)\n",
        "X_test.week_day = X_test.week_day.astype(str)\n",
        "\n",
        "# We convert the 'month' variable to string\n",
        "X_train.month = X_train.month.astype(str)\n",
        "X_test.month = X_test.month.astype(str)\n",
        "\n",
        "X_train = X_train[['NO2_6', 'NO2_7', 'NO2_10', 'NO2_11', 'NO2_22', 'NO2_23', 'NO2_24',\n",
        "                   'NO2_25', 'NO2_26', 'NO2_27','NO2_48', 'NO2_72', 'NO2_96', 'NO2_120', 'NO2_144', 'NO2_168']]\n",
        "\n",
        "X_test = X_test[['NO2_6', 'NO2_7', 'NO2_10', 'NO2_11', 'NO2_22', 'NO2_23', 'NO2_24',\n",
        "                   'NO2_25', 'NO2_26', 'NO2_27','NO2_48', 'NO2_72', 'NO2_96', 'NO2_120', 'NO2_144', 'NO2_168']]\n",
        "\n",
        "\n",
        "X_train = pd.get_dummies(X_train)\n",
        "X_test  = pd.get_dummies(X_test)\n",
        "\n",
        "\n",
        "# Al hacer el one hot encoding el X_train y el X_test tienen distintas dimensiones. X_train tiene 47 variables y X_test 44. Por que? Porque el dataset de test tiene solo 9 meses, de enero a septiembre, y entonces la variable month solo se convierte en 9 variables, mientras que el dataset tendriamos 12, los 12 meses del anho. \n",
        "# Con el siguiente codigo solucionamos el problema (falta referencia)\n",
        "\n",
        "# Get missing columns in the training test\n",
        "missing_cols = set( X_train.columns ) - set( X_test.columns )\n",
        "# Add a missing column in test set with default value equal to 0\n",
        "for c in missing_cols:\n",
        "    X_test[c] = 0\n",
        "# Ensure the order of column in the test set is in the same order than in train set\n",
        "X_test = X_test[X_train.columns]\n",
        "# This code also ensure that column resulting from category in the test dataset but not present in the training dataset will be removed\n",
        "\n",
        "\n",
        "regXGB = XGBRegressor(n_estimators=100, min_samples_leaf=10,max_depth=2, random_state=42)\n",
        "regXGB.fit(X_train,y_train)\n",
        "\n",
        "\n",
        "# Compute train scores\n",
        "\n",
        "y_pred = regXGB.predict(X_train)\n",
        "\n",
        "r2_train = r2_score(y_train, y_pred)\n",
        "rmse_train = np.sqrt(mean_squared_error(y_train, y_pred))\n",
        "mae_train = mean_absolute_error(y_train, y_pred)\n",
        "r2_adjusted_train = 1 - (1-r2_score(y_train, y_pred))*(len(y_train)-1)/(len(y_train)-X_train.shape[1]-1)\n",
        "sd_train = std(y_train)\n",
        "\n",
        "print(\"R^2 train: {}\".format(r2_train))\n",
        "print(\"R^2 adjusted train: {}\".format(r2_adjusted_train))\n",
        "print(\"Mean Absolute Error train: {}\".format(mae_train))\n",
        "print(\"Root Mean Squared Error train: {}\".format(rmse_train)) \n",
        "print(\"Standard Deviation train: {}\".format(sd_train))  \n",
        "\n",
        "# Compute test scores\n",
        "\n",
        "y_pred = regXGB.predict(X_test)\n",
        "\n",
        "r2_test = r2_score(y_test, y_pred)\n",
        "rmse_test = np.sqrt(mean_squared_error(y_test, y_pred))\n",
        "mae_test = mean_absolute_error(y_test, y_pred)\n",
        "r2_adjusted_test = 1 - (1-r2_score(y_test, y_pred))*(len(y_test)-1)/(len(y_test)-X_test.shape[1]-1)\n",
        "sd_test = std(y_test)\n",
        "\n",
        "print(\"R^2 test: {}\".format(r2_test))\n",
        "print(\"R^2 adjusted test: {}\".format(r2_adjusted_test))\n",
        "print(\"Mean Absolute Error test: {}\".format(mae_test))\n",
        "print(\"Root Mean Squared Error test: {}\".format(rmse_test))\n",
        "print(\"Standard Deviation test: {}\".format(sd_test)) \n"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "R^2 train: 0.505434230269822\n",
            "R^2 adjusted train: 0.5051281279018021\n",
            "Mean Absolute Error train: 8.25219944389317\n",
            "Root Mean Squared Error train: 10.906968643481578\n",
            "Standard Deviation train: NO2_0    15.509294\n",
            "dtype: float64\n",
            "R^2 test: 0.3947446094575423\n",
            "R^2 adjusted test: 0.39322338950016256\n",
            "Mean Absolute Error test: 10.476092412226016\n",
            "Root Mean Squared Error test: 14.358438073405999\n",
            "Standard Deviation test: NO2_0    18.456012\n",
            "dtype: float64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "jiSo4-yPw4Xa",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 12 hours ahead"
      ]
    },
    {
      "metadata": {
        "id": "rdCcOD49w4dn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "efc540f7-f5d7-48ab-abc2-9dcbd1b02377"
      },
      "cell_type": "code",
      "source": [
        "X_train = pyreadr.read_r(\"X_train_NO2_201401_201612_multivar.rds\")\n",
        "y_train = pyreadr.read_r(\"y_train_NO2_201401_201612_multivar.rds\")\n",
        "\n",
        "X_test = pyreadr.read_r(\"X_test_NO2_201701_201709_multivar.rds\")\n",
        "y_test = pyreadr.read_r(\"y_test_NO2_201701_201709_multivar.rds\")\n",
        "\n",
        "X_train = X_train[None]\n",
        "y_train = y_train[None]\n",
        "X_test = X_test[None]\n",
        "y_test = y_test[None]\n",
        "\n",
        "# We convert the 'hour' variable to string\n",
        "X_train.hour = X_train.hour.astype(str)\n",
        "X_test.hour = X_test.hour.astype(str)\n",
        "\n",
        "# We convert the 'week_day' variable to string\n",
        "X_train.week_day = X_train.week_day.astype(str)\n",
        "X_test.week_day = X_test.week_day.astype(str)\n",
        "\n",
        "# We convert the 'month' variable to string\n",
        "X_train.month = X_train.month.astype(str)\n",
        "X_test.month = X_test.month.astype(str)\n",
        "\n",
        "X_train = X_train[['NO2_12', 'NO2_13','NO2_22', 'NO2_23', 'NO2_24',\n",
        "                   'NO2_25', 'NO2_26', 'NO2_27','NO2_48', 'NO2_72', 'NO2_96', 'NO2_120', 'NO2_144', 'NO2_168']]\n",
        "\n",
        "X_test = X_test[['NO2_12', 'NO2_13','NO2_22', 'NO2_23', 'NO2_24',\n",
        "                   'NO2_25', 'NO2_26', 'NO2_27','NO2_48', 'NO2_72', 'NO2_96', 'NO2_120', 'NO2_144', 'NO2_168']]\n",
        "\n",
        "\n",
        "\n",
        "X_train = pd.get_dummies(X_train)\n",
        "X_test  = pd.get_dummies(X_test)\n",
        "\n",
        "\n",
        "# Al hacer el one hot encoding el X_train y el X_test tienen distintas dimensiones. X_train tiene 47 variables y X_test 44. Por que? Porque el dataset de test tiene solo 9 meses, de enero a septiembre, y entonces la variable month solo se convierte en 9 variables, mientras que el dataset tendriamos 12, los 12 meses del anho. \n",
        "# Con el siguiente codigo solucionamos el problema (falta referencia)\n",
        "\n",
        "# Get missing columns in the training test\n",
        "missing_cols = set( X_train.columns ) - set( X_test.columns )\n",
        "# Add a missing column in test set with default value equal to 0\n",
        "for c in missing_cols:\n",
        "    X_test[c] = 0\n",
        "# Ensure the order of column in the test set is in the same order than in train set\n",
        "X_test = X_test[X_train.columns]\n",
        "# This code also ensure that column resulting from category in the test dataset but not present in the training dataset will be removed\n",
        "\n",
        "\n",
        "\n",
        "regXGB = XGBRegressor(n_estimators=100, min_samples_leaf=10,max_depth=2, random_state=42)\n",
        "regXGB.fit(X_train,y_train)\n",
        "\n",
        "\n",
        "# Compute train scores\n",
        "\n",
        "y_pred = regXGB.predict(X_train)\n",
        "\n",
        "r2_train = r2_score(y_train, y_pred)\n",
        "rmse_train = np.sqrt(mean_squared_error(y_train, y_pred))\n",
        "mae_train = mean_absolute_error(y_train, y_pred)\n",
        "r2_adjusted_train = 1 - (1-r2_score(y_train, y_pred))*(len(y_train)-1)/(len(y_train)-X_train.shape[1]-1)\n",
        "sd_train = std(y_train)\n",
        "\n",
        "print(\"R^2 train: {}\".format(r2_train))\n",
        "print(\"R^2 adjusted train: {}\".format(r2_adjusted_train))\n",
        "print(\"Mean Absolute Error train: {}\".format(mae_train))\n",
        "print(\"Root Mean Squared Error train: {}\".format(rmse_train)) \n",
        "print(\"Standard Deviation train: {}\".format(sd_train))  \n",
        "\n",
        "# Compute test scores\n",
        "\n",
        "y_pred = regXGB.predict(X_test)\n",
        "\n",
        "r2_test = r2_score(y_test, y_pred)\n",
        "rmse_test = np.sqrt(mean_squared_error(y_test, y_pred))\n",
        "mae_test = mean_absolute_error(y_test, y_pred)\n",
        "r2_adjusted_test = 1 - (1-r2_score(y_test, y_pred))*(len(y_test)-1)/(len(y_test)-X_test.shape[1]-1)\n",
        "sd_test = std(y_test)\n",
        "\n",
        "print(\"R^2 test: {}\".format(r2_test))\n",
        "print(\"R^2 adjusted test: {}\".format(r2_adjusted_test))\n",
        "print(\"Mean Absolute Error test: {}\".format(mae_test))\n",
        "print(\"Root Mean Squared Error test: {}\".format(rmse_test))\n",
        "print(\"Standard Deviation test: {}\".format(sd_test))  \n"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "R^2 train: 0.48245294949412454\n",
            "R^2 adjusted train: 0.48217268574496264\n",
            "Mean Absolute Error train: 8.50924019304368\n",
            "Root Mean Squared Error train: 11.157501563151524\n",
            "Standard Deviation train: NO2_0    15.509294\n",
            "dtype: float64\n",
            "R^2 test: 0.37314522722893506\n",
            "R^2 adjusted test: 0.37176709173603384\n",
            "Mean Absolute Error test: 10.677783072908605\n",
            "Root Mean Squared Error test: 14.612392690820352\n",
            "Standard Deviation test: NO2_0    18.456012\n",
            "dtype: float64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "LhZDCp6WxULE",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 24 hours ahead"
      ]
    },
    {
      "metadata": {
        "id": "HyiGnHHNxUcn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "f0b8f91f-8ef7-4ea1-c20e-fd62540b3678"
      },
      "cell_type": "code",
      "source": [
        "X_train = pyreadr.read_r(\"X_train_NO2_201401_201612_multivar.rds\")\n",
        "y_train = pyreadr.read_r(\"y_train_NO2_201401_201612_multivar.rds\")\n",
        "\n",
        "X_test = pyreadr.read_r(\"X_test_NO2_201701_201709_multivar.rds\")\n",
        "y_test = pyreadr.read_r(\"y_test_NO2_201701_201709_multivar.rds\")\n",
        "\n",
        "X_train = X_train[None]\n",
        "y_train = y_train[None]\n",
        "X_test = X_test[None]\n",
        "y_test = y_test[None]\n",
        "\n",
        "# We convert the 'hour' variable to string\n",
        "X_train.hour = X_train.hour.astype(str)\n",
        "X_test.hour = X_test.hour.astype(str)\n",
        "\n",
        "# We convert the 'week_day' variable to string\n",
        "X_train.week_day = X_train.week_day.astype(str)\n",
        "X_test.week_day = X_test.week_day.astype(str)\n",
        "\n",
        "# We convert the 'month' variable to string\n",
        "X_train.month = X_train.month.astype(str)\n",
        "X_test.month = X_test.month.astype(str)\n",
        "\n",
        "X_train = X_train[[ 'NO2_24','NO2_25', 'NO2_26', 'NO2_27','NO2_48', 'NO2_72', 'NO2_96', 'NO2_120', 'NO2_144', 'NO2_168']]\n",
        "\n",
        "X_test = X_test[['NO2_24', 'NO2_25', 'NO2_26', 'NO2_27','NO2_48', 'NO2_72', 'NO2_96', 'NO2_120', 'NO2_144', 'NO2_168']]\n",
        "\n",
        "\n",
        "\n",
        "X_train = pd.get_dummies(X_train)\n",
        "X_test  = pd.get_dummies(X_test)\n",
        "\n",
        "\n",
        "# Al hacer el one hot encoding el X_train y el X_test tienen distintas dimensiones. X_train tiene 47 variables y X_test 44. Por que? Porque el dataset de test tiene solo 9 meses, de enero a septiembre, y entonces la variable month solo se convierte en 9 variables, mientras que el dataset tendriamos 12, los 12 meses del anho. \n",
        "# Con el siguiente codigo solucionamos el problema (falta referencia)\n",
        "\n",
        "# Get missing columns in the training test\n",
        "missing_cols = set( X_train.columns ) - set( X_test.columns )\n",
        "# Add a missing column in test set with default value equal to 0\n",
        "for c in missing_cols:\n",
        "    X_test[c] = 0\n",
        "# Ensure the order of column in the test set is in the same order than in train set\n",
        "X_test = X_test[X_train.columns]\n",
        "# This code also ensure that column resulting from category in the test dataset but not present in the training dataset will be removed\n",
        "\n",
        "\n",
        "\n",
        "regXGB = XGBRegressor(n_estimators=500, min_samples_leaf=10,max_depth=2, random_state=42)\n",
        "regXGB.fit(X_train,y_train)\n",
        "\n",
        "\n",
        "# Compute train scores\n",
        "\n",
        "y_pred = regXGB.predict(X_train)\n",
        "\n",
        "r2_train = r2_score(y_train, y_pred)\n",
        "rmse_train = np.sqrt(mean_squared_error(y_train, y_pred))\n",
        "mae_train = mean_absolute_error(y_train, y_pred)\n",
        "r2_adjusted_train = 1 - (1-r2_score(y_train, y_pred))*(len(y_train)-1)/(len(y_train)-X_train.shape[1]-1)\n",
        "sd_train = std(y_train)\n",
        "\n",
        "print(\"R^2 train: {}\".format(r2_train))\n",
        "print(\"R^2 adjusted train: {}\".format(r2_adjusted_train))\n",
        "print(\"Mean Absolute Error train: {}\".format(mae_train))\n",
        "print(\"Root Mean Squared Error train: {}\".format(rmse_train)) \n",
        "print(\"Standard Deviation train: {}\".format(sd_train))  \n",
        "\n",
        "# Compute test scores\n",
        "\n",
        "y_pred = regXGB.predict(X_test)\n",
        "\n",
        "r2_test = r2_score(y_test, y_pred)\n",
        "rmse_test = np.sqrt(mean_squared_error(y_test, y_pred))\n",
        "mae_test = mean_absolute_error(y_test, y_pred)\n",
        "r2_adjusted_test = 1 - (1-r2_score(y_test, y_pred))*(len(y_test)-1)/(len(y_test)-X_test.shape[1]-1)\n",
        "sd_test = std(y_test)\n",
        "\n",
        "print(\"R^2 test: {}\".format(r2_test))\n",
        "print(\"R^2 adjusted test: {}\".format(r2_adjusted_test))\n",
        "print(\"Mean Absolute Error test: {}\".format(mae_test))\n",
        "print(\"Root Mean Squared Error test: {}\".format(rmse_test))\n",
        "print(\"Standard Deviation test: {}\".format(sd_test))  \n"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "R^2 train: 0.48563518522341775\n",
            "R^2 adjusted train: 0.48543625850540073\n",
            "Mean Absolute Error train: 8.527055341972911\n",
            "Root Mean Squared Error train: 11.123146670143798\n",
            "Standard Deviation train: NO2_0    15.509294\n",
            "dtype: float64\n",
            "R^2 test: 0.32238873999820905\n",
            "R^2 adjusted test: 0.3213253199417091\n",
            "Mean Absolute Error test: 11.08488724252079\n",
            "Root Mean Squared Error test: 15.192462515751007\n",
            "Standard Deviation test: NO2_0    18.456012\n",
            "dtype: float64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "u-TSqvXqhSu2",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### I add the rest of variables"
      ]
    },
    {
      "metadata": {
        "id": "UpeBxoWzhS8k",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "d5b74f1c-1126-442e-d12c-3025b6afc232"
      },
      "cell_type": "code",
      "source": [
        "X_train = pyreadr.read_r(\"X_train_NO2_201401_201612_multivar.rds\")\n",
        "y_train = pyreadr.read_r(\"y_train_NO2_201401_201612_multivar.rds\")\n",
        "\n",
        "X_test = pyreadr.read_r(\"X_test_NO2_201701_201709_multivar.rds\")\n",
        "y_test = pyreadr.read_r(\"y_test_NO2_201701_201709_multivar.rds\")\n",
        "\n",
        "X_train = X_train[None]\n",
        "y_train = y_train[None]\n",
        "X_test = X_test[None]\n",
        "y_test = y_test[None]\n",
        "\n",
        "# We convert the 'hour' variable to string\n",
        "X_train.hour = X_train.hour.astype(str)\n",
        "X_test.hour = X_test.hour.astype(str)\n",
        "\n",
        "# We convert the 'week_day' variable to string\n",
        "X_train.week_day = X_train.week_day.astype(str)\n",
        "X_test.week_day = X_test.week_day.astype(str)\n",
        "\n",
        "# We convert the 'month' variable to string\n",
        "X_train.month = X_train.month.astype(str)\n",
        "X_test.month = X_test.month.astype(str)\n",
        "\n",
        "X_train = X_train[['NO2_1', 'NO2_2', 'NO2_10', 'NO2_11', 'NO2_22', 'NO2_23', 'NO2_24',\n",
        "                   'NO2_25', 'NO2_26', 'NO2_27','NO2_48', 'NO2_72', 'NO2_96', 'NO2_120', 'NO2_144', 'NO2_168',\n",
        "                  'no_lab_days', 'hour','month', 'week_day','vv_1', 'wd_1', 'LL_1', 'LL_2', 'RS_1', 'RS_2', 'HR_1', 'HR_2', 'PRB_1', 'PRB_2', 'NO_1', 'NO_2']]\n",
        "\n",
        "X_test = X_test[['NO2_1', 'NO2_2', 'NO2_10', 'NO2_11', 'NO2_22', 'NO2_23', 'NO2_24',\n",
        "                   'NO2_25', 'NO2_26', 'NO2_27','NO2_48', 'NO2_72', 'NO2_96', 'NO2_120', 'NO2_144', 'NO2_168',\n",
        "                  'no_lab_days', 'hour','month', 'week_day','vv_1', 'wd_1', 'LL_1', 'LL_2', 'RS_1', 'RS_2', 'HR_1', 'HR_2', 'PRB_1', 'PRB_2', 'NO_1', 'NO_2']]\n",
        "\n",
        "\n",
        "X_train = pd.get_dummies(X_train)\n",
        "X_test  = pd.get_dummies(X_test)\n",
        "\n",
        "\n",
        "# Al hacer el one hot encoding el X_train y el X_test tienen distintas dimensiones. X_train tiene 47 variables y X_test 44. Por que? Porque el dataset de test tiene solo 9 meses, de enero a septiembre, y entonces la variable month solo se convierte en 9 variables, mientras que el dataset tendriamos 12, los 12 meses del anho. \n",
        "# Con el siguiente codigo solucionamos el problema (falta referencia)\n",
        "\n",
        "# Get missing columns in the training test\n",
        "missing_cols = set( X_train.columns ) - set( X_test.columns )\n",
        "# Add a missing column in test set with default value equal to 0\n",
        "for c in missing_cols:\n",
        "    X_test[c] = 0\n",
        "# Ensure the order of column in the test set is in the same order than in train set\n",
        "X_test = X_test[X_train.columns]\n",
        "# This code also ensure that column resulting from category in the test dataset but not present in the training dataset will be removed\n",
        "\n",
        "\n",
        "regXGB = XGBRegressor(n_estimators=100, min_samples_leaf=10,max_depth=2, random_state=42)\n",
        "regXGB.fit(X_train,y_train)\n",
        "\n",
        "\n",
        "# Compute train scores\n",
        "\n",
        "y_pred = regXGB.predict(X_train)\n",
        "\n",
        "r2_train = r2_score(y_train, y_pred)\n",
        "rmse_train = np.sqrt(mean_squared_error(y_train, y_pred))\n",
        "mae_train = mean_absolute_error(y_train, y_pred)\n",
        "r2_adjusted_train = 1 - (1-r2_score(y_train, y_pred))*(len(y_train)-1)/(len(y_train)-X_train.shape[1]-1)\n",
        "sd_train = std(y_train)\n",
        "\n",
        "print(\"R^2 train: {}\".format(r2_train))\n",
        "print(\"R^2 adjusted train: {}\".format(r2_adjusted_train))\n",
        "print(\"Mean Absolute Error train: {}\".format(mae_train))\n",
        "print(\"Root Mean Squared Error train: {}\".format(rmse_train)) \n",
        "print(\"Standard Deviation train: {}\".format(sd_train))  \n",
        "\n",
        "# Compute test scores\n",
        "\n",
        "y_pred = regXGB.predict(X_test)\n",
        "\n",
        "r2_test = r2_score(y_test, y_pred)\n",
        "rmse_test = np.sqrt(mean_squared_error(y_test, y_pred))\n",
        "mae_test = mean_absolute_error(y_test, y_pred)\n",
        "r2_adjusted_test = 1 - (1-r2_score(y_test, y_pred))*(len(y_test)-1)/(len(y_test)-X_test.shape[1]-1)\n",
        "sd_test = std(y_test)\n",
        "\n",
        "print(\"R^2 test: {}\".format(r2_test))\n",
        "print(\"R^2 adjusted test: {}\".format(r2_adjusted_test))\n",
        "print(\"Mean Absolute Error test: {}\".format(mae_test))\n",
        "print(\"Root Mean Squared Error test: {}\".format(rmse_test))\n",
        "print(\"Standard Deviation test: {}\".format(sd_test))  "
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "R^2 train: 0.8281368982852535\n",
            "R^2 adjusted train: 0.8275502210304765\n",
            "Mean Absolute Error train: 4.482929764284935\n",
            "Root Mean Squared Error train: 6.42959118883823\n",
            "Standard Deviation train: NO2_0    15.509294\n",
            "dtype: float64\n",
            "R^2 test: 0.76681906718038\n",
            "R^2 adjusted test: 0.7635588317040332\n",
            "Mean Absolute Error test: 5.724267636207306\n",
            "Root Mean Squared Error test: 8.912188920157883\n",
            "Standard Deviation test: NO2_0    18.456012\n",
            "dtype: float64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "pBRprxjZ_o04",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### grid"
      ]
    },
    {
      "metadata": {
        "id": "Ko2iPms2l8Q0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "X_train = pyreadr.read_r(\"X_train_NO2_201401_201612_multivar.rds\")\n",
        "y_train = pyreadr.read_r(\"y_train_NO2_201401_201612_multivar.rds\")\n",
        "\n",
        "X_test = pyreadr.read_r(\"X_test_NO2_201701_201709_multivar.rds\")\n",
        "y_test = pyreadr.read_r(\"y_test_NO2_201701_201709_multivar.rds\")\n",
        "\n",
        "X_train = X_train[None]\n",
        "y_train = y_train[None]\n",
        "X_test = X_test[None]\n",
        "y_test = y_test[None]\n",
        "\n",
        "# We convert the 'hour' variable to string\n",
        "X_train.hour = X_train.hour.astype(str)\n",
        "X_test.hour = X_test.hour.astype(str)\n",
        "\n",
        "# We convert the 'week_day' variable to string\n",
        "X_train.week_day = X_train.week_day.astype(str)\n",
        "X_test.week_day = X_test.week_day.astype(str)\n",
        "\n",
        "# We convert the 'month' variable to string\n",
        "X_train.month = X_train.month.astype(str)\n",
        "X_test.month = X_test.month.astype(str)\n",
        "\n",
        "X_train = X_train[['NO2_1', 'NO2_2', 'NO2_10', 'NO2_11', 'NO2_22', 'NO2_23', 'NO2_24',\n",
        "                   'NO2_25', 'NO2_26', 'NO2_27','NO2_48', 'NO2_72', 'NO2_96', 'NO2_120', 'NO2_144', 'NO2_168',\n",
        "                  'no_lab_days', 'hour','month', 'week_day','vv_1', 'wd_1', 'LL_1', 'LL_2', 'RS_1', 'RS_2', 'HR_1', 'HR_2', 'PRB_1', 'PRB_2', 'NO_1', 'NO_2']]\n",
        "\n",
        "X_test = X_test[['NO2_1', 'NO2_2', 'NO2_10', 'NO2_11', 'NO2_22', 'NO2_23', 'NO2_24',\n",
        "                   'NO2_25', 'NO2_26', 'NO2_27','NO2_48', 'NO2_72', 'NO2_96', 'NO2_120', 'NO2_144', 'NO2_168',\n",
        "                  'no_lab_days', 'hour','month', 'week_day','vv_1', 'wd_1', 'LL_1', 'LL_2', 'RS_1', 'RS_2', 'HR_1', 'HR_2', 'PRB_1', 'PRB_2', 'NO_1', 'NO_2']]\n",
        "\n",
        "\n",
        "X_train = pd.get_dummies(X_train)\n",
        "X_test  = pd.get_dummies(X_test)\n",
        "\n",
        "\n",
        "# Al hacer el one hot encoding el X_train y el X_test tienen distintas dimensiones. X_train tiene 47 variables y X_test 44. Por que? Porque el dataset de test tiene solo 9 meses, de enero a septiembre, y entonces la variable month solo se convierte en 9 variables, mientras que el dataset tendriamos 12, los 12 meses del anho. \n",
        "# Con el siguiente codigo solucionamos el problema (falta referencia)\n",
        "\n",
        "# Get missing columns in the training test\n",
        "missing_cols = set( X_train.columns ) - set( X_test.columns )\n",
        "# Add a missing column in test set with default value equal to 0\n",
        "for c in missing_cols:\n",
        "    X_test[c] = 0\n",
        "# Ensure the order of column in the test set is in the same order than in train set\n",
        "X_test = X_test[X_train.columns]\n",
        "# This code also ensure that column resulting from category in the test dataset but not present in the training dataset will be removed\n",
        "\n",
        "\n",
        "regRFR = GridSearchCV(RandomForestRegressor(n_estimators=350,min_samples_leaf=1,max_depth=4, random_state=42),\n",
        "                   param_grid={\"n_estimators\":[100, 350, 500, 1000],\n",
        "                              \"min_samples_leaf\":[5,10,20,30,40,70,100],\n",
        "                              \"max_depth\":range(2,15)},\n",
        "                   scoring=\"neg_mean_absolute_error\")\n",
        "regRFR.fit(X_train,y_train.values.ravel())\n",
        "print(regRFR.best_params_)\n",
        "print(regRFR.best_score_)\n",
        "\n",
        "\n",
        "\n",
        "# Compute train scores\n",
        "\n",
        "y_pred = regXGB.predict(X_train)\n",
        "\n",
        "r2_train = r2_score(y_train, y_pred)\n",
        "rmse_train = np.sqrt(mean_squared_error(y_train, y_pred))\n",
        "mae_train = mean_absolute_error(y_train, y_pred)\n",
        "r2_adjusted_train = 1 - (1-r2_score(y_train, y_pred))*(len(y_train)-1)/(len(y_train)-X_train.shape[1]-1)\n",
        "sd_train = std(y_train)\n",
        "\n",
        "print(\"R^2 train: {}\".format(r2_train))\n",
        "print(\"R^2 adjusted train: {}\".format(r2_adjusted_train))\n",
        "print(\"Mean Absolute Error train: {}\".format(mae_train))\n",
        "print(\"Root Mean Squared Error train: {}\".format(rmse_train)) \n",
        "print(\"Standard Deviation train: {}\".format(sd_train))  \n",
        "\n",
        "# Compute test scores\n",
        "\n",
        "y_pred = regXGB.predict(X_test)\n",
        "\n",
        "r2_test = r2_score(y_test, y_pred)\n",
        "rmse_test = np.sqrt(mean_squared_error(y_test, y_pred))\n",
        "mae_test = mean_absolute_error(y_test, y_pred)\n",
        "r2_adjusted_test = 1 - (1-r2_score(y_test, y_pred))*(len(y_test)-1)/(len(y_test)-X_test.shape[1]-1)\n",
        "sd_test = std(y_test)\n",
        "\n",
        "print(\"R^2 test: {}\".format(r2_test))\n",
        "print(\"R^2 adjusted test: {}\".format(r2_adjusted_test))\n",
        "print(\"Mean Absolute Error test: {}\".format(mae_test))\n",
        "print(\"Root Mean Squared Error test: {}\".format(rmse_test))\n",
        "print(\"Standard Deviation test: {}\".format(sd_test))  \n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "outputId": "b5348de0-db42-4c17-c2f8-edcbc97ab337",
        "id": "B_eG3xeemAD4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "cell_type": "code",
      "source": [
        "X_train = pyreadr.read_r(\"X_train_NO2_201401_201612_multivar.rds\")\n",
        "y_train = pyreadr.read_r(\"y_train_NO2_201401_201612_multivar.rds\")\n",
        "\n",
        "X_test = pyreadr.read_r(\"X_test_NO2_201701_201709_multivar.rds\")\n",
        "y_test = pyreadr.read_r(\"y_test_NO2_201701_201709_multivar.rds\")\n",
        "\n",
        "X_train = X_train[None]\n",
        "y_train = y_train[None]\n",
        "X_test = X_test[None]\n",
        "y_test = y_test[None]\n",
        "\n",
        "# We convert the 'hour' variable to string\n",
        "X_train.hour = X_train.hour.astype(str)\n",
        "X_test.hour = X_test.hour.astype(str)\n",
        "\n",
        "# We convert the 'week_day' variable to string\n",
        "X_train.week_day = X_train.week_day.astype(str)\n",
        "X_test.week_day = X_test.week_day.astype(str)\n",
        "\n",
        "# We convert the 'month' variable to string\n",
        "X_train.month = X_train.month.astype(str)\n",
        "X_test.month = X_test.month.astype(str)\n",
        "\n",
        "X_train = X_train[['NO2_1', 'NO2_2', 'NO2_10', 'NO2_11', 'NO2_22', 'NO2_23', 'NO2_24',\n",
        "                   'NO2_25', 'NO2_26', 'NO2_27','NO2_48', 'NO2_72', 'NO2_96', 'NO2_120', 'NO2_144', 'NO2_168',\n",
        "                  'no_lab_days', 'hour','month', 'week_day','vv_1', 'wd_1', 'LL_1', 'LL_2', 'RS_1', 'RS_2', 'HR_1', 'HR_2', 'PRB_1', 'PRB_2', 'NO_1', 'NO_2']]\n",
        "\n",
        "X_test = X_test[['NO2_1', 'NO2_2', 'NO2_10', 'NO2_11', 'NO2_22', 'NO2_23', 'NO2_24',\n",
        "                   'NO2_25', 'NO2_26', 'NO2_27','NO2_48', 'NO2_72', 'NO2_96', 'NO2_120', 'NO2_144', 'NO2_168',\n",
        "                  'no_lab_days', 'hour','month', 'week_day','vv_1', 'wd_1', 'LL_1', 'LL_2', 'RS_1', 'RS_2', 'HR_1', 'HR_2', 'PRB_1', 'PRB_2', 'NO_1', 'NO_2']]\n",
        "\n",
        "\n",
        "X_train = pd.get_dummies(X_train)\n",
        "X_test  = pd.get_dummies(X_test)\n",
        "\n",
        "\n",
        "# Al hacer el one hot encoding el X_train y el X_test tienen distintas dimensiones. X_train tiene 47 variables y X_test 44. Por que? Porque el dataset de test tiene solo 9 meses, de enero a septiembre, y entonces la variable month solo se convierte en 9 variables, mientras que el dataset tendriamos 12, los 12 meses del anho. \n",
        "# Con el siguiente codigo solucionamos el problema (falta referencia)\n",
        "\n",
        "# Get missing columns in the training test\n",
        "missing_cols = set( X_train.columns ) - set( X_test.columns )\n",
        "# Add a missing column in test set with default value equal to 0\n",
        "for c in missing_cols:\n",
        "    X_test[c] = 0\n",
        "# Ensure the order of column in the test set is in the same order than in train set\n",
        "X_test = X_test[X_train.columns]\n",
        "# This code also ensure that column resulting from category in the test dataset but not present in the training dataset will be removed\n",
        "\n",
        "\n",
        "regXGB = XGBRegressor(n_estimators=100, min_samples_leaf=10,max_depth=2, random_state=42)\n",
        "regXGB.fit(X_train,y_train)\n",
        "\n",
        "\n",
        "# Compute train scores\n",
        "\n",
        "y_pred = regXGB.predict(X_train)\n",
        "\n",
        "r2_train = r2_score(y_train, y_pred)\n",
        "rmse_train = np.sqrt(mean_squared_error(y_train, y_pred))\n",
        "mae_train = mean_absolute_error(y_train, y_pred)\n",
        "r2_adjusted_train = 1 - (1-r2_score(y_train, y_pred))*(len(y_train)-1)/(len(y_train)-X_train.shape[1]-1)\n",
        "sd_train = std(y_train)\n",
        "\n",
        "print(\"R^2 train: {}\".format(r2_train))\n",
        "print(\"R^2 adjusted train: {}\".format(r2_adjusted_train))\n",
        "print(\"Mean Absolute Error train: {}\".format(mae_train))\n",
        "print(\"Root Mean Squared Error train: {}\".format(rmse_train)) \n",
        "print(\"Standard Deviation train: {}\".format(sd_train))  \n",
        "\n",
        "# Compute test scores\n",
        "\n",
        "y_pred = regXGB.predict(X_test)\n",
        "\n",
        "r2_test = r2_score(y_test, y_pred)\n",
        "rmse_test = np.sqrt(mean_squared_error(y_test, y_pred))\n",
        "mae_test = mean_absolute_error(y_test, y_pred)\n",
        "r2_adjusted_test = 1 - (1-r2_score(y_test, y_pred))*(len(y_test)-1)/(len(y_test)-X_test.shape[1]-1)\n",
        "sd_test = std(y_test)\n",
        "\n",
        "print(\"R^2 test: {}\".format(r2_test))\n",
        "print(\"R^2 adjusted test: {}\".format(r2_adjusted_test))\n",
        "print(\"Mean Absolute Error test: {}\".format(mae_test))\n",
        "print(\"Root Mean Squared Error test: {}\".format(rmse_test))\n",
        "print(\"Standard Deviation test: {}\".format(sd_test))  "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "R^2 train: 0.8281368982852535\n",
            "R^2 adjusted train: 0.8275502210304765\n",
            "Mean Absolute Error train: 4.482929764284935\n",
            "Root Mean Squared Error train: 6.42959118883823\n",
            "Standard Deviation train: NO2_0    15.509294\n",
            "dtype: float64\n",
            "R^2 test: 0.76681906718038\n",
            "R^2 adjusted test: 0.7635588317040332\n",
            "Mean Absolute Error test: 5.724267636207306\n",
            "Root Mean Squared Error test: 8.912188920157883\n",
            "Standard Deviation test: NO2_0    18.456012\n",
            "dtype: float64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "eDauVJKo4JfJ"
      },
      "cell_type": "markdown",
      "source": [
        "# NO2 forecasts 2 hours ahead\n",
        "n_estimators=500, min_samples_leaf=10,max_depth=2, random_state=42"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "outputId": "d964d76b-1935-458b-8fce-347f73583bed",
        "id": "RLME_PlZ4JfK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "cell_type": "code",
      "source": [
        "X_train = pyreadr.read_r(\"X_train_NO2_201401_201612_multivar.rds\")\n",
        "y_train = pyreadr.read_r(\"y_train_NO2_201401_201612_multivar.rds\")\n",
        "\n",
        "X_test = pyreadr.read_r(\"X_test_NO2_201701_201709_multivar.rds\")\n",
        "y_test = pyreadr.read_r(\"y_test_NO2_201701_201709_multivar.rds\")\n",
        "\n",
        "X_train = X_train[None]\n",
        "y_train = y_train[None]\n",
        "X_test = X_test[None]\n",
        "y_test = y_test[None]\n",
        "\n",
        "# We convert the 'hour' variable to string\n",
        "X_train.hour = X_train.hour.astype(str)\n",
        "X_test.hour = X_test.hour.astype(str)\n",
        "\n",
        "# We convert the 'week_day' variable to string\n",
        "X_train.week_day = X_train.week_day.astype(str)\n",
        "X_test.week_day = X_test.week_day.astype(str)\n",
        "\n",
        "# We convert the 'month' variable to string\n",
        "X_train.month = X_train.month.astype(str)\n",
        "X_test.month = X_test.month.astype(str)\n",
        "\n",
        "X_train = X_train[[ 'NO2_2', 'NO2_10', 'NO2_11', 'NO2_22', 'NO2_23', 'NO2_24',\n",
        "                   'NO2_25', 'NO2_26', 'NO2_27','NO2_48', 'NO2_72', 'NO2_96', 'NO2_120', 'NO2_144', 'NO2_168',\n",
        "                  'no_lab_days', 'hour','month', 'week_day', 'wd_2', 'LL_2', 'RS_2', 'HR_2', 'PRB_2', 'NO_2']]\n",
        "\n",
        "X_test = X_test[['NO2_2', 'NO2_10', 'NO2_11', 'NO2_22', 'NO2_23', 'NO2_24',\n",
        "                   'NO2_25', 'NO2_26', 'NO2_27','NO2_48', 'NO2_72', 'NO2_96', 'NO2_120', 'NO2_144', 'NO2_168',\n",
        "                  'no_lab_days', 'hour','month', 'week_day', 'wd_2', 'LL_2', 'RS_2', 'HR_2', 'PRB_2', 'NO_2']]\n",
        "\n",
        "X_train = pd.get_dummies(X_train)\n",
        "X_test  = pd.get_dummies(X_test)\n",
        "\n",
        "\n",
        "# Al hacer el one hot encoding el X_train y el X_test tienen distintas dimensiones. X_train tiene 47 variables y X_test 44. Por que? Porque el dataset de test tiene solo 9 meses, de enero a septiembre, y entonces la variable month solo se convierte en 9 variables, mientras que el dataset tendriamos 12, los 12 meses del anho. \n",
        "# Con el siguiente codigo solucionamos el problema (falta referencia)\n",
        "\n",
        "# Get missing columns in the training test\n",
        "missing_cols = set( X_train.columns ) - set( X_test.columns )\n",
        "# Add a missing column in test set with default value equal to 0\n",
        "for c in missing_cols:\n",
        "    X_test[c] = 0\n",
        "# Ensure the order of column in the test set is in the same order than in train set\n",
        "X_test = X_test[X_train.columns]\n",
        "# This code also ensure that column resulting from category in the test dataset but not present in the training dataset will be removed\n",
        "\n",
        "\n",
        "regXGB = XGBRegressor(n_estimators=100, min_samples_leaf=10,max_depth=2, random_state=42)\n",
        "regXGB.fit(X_train,y_train)\n",
        "\n",
        "\n",
        "# Compute train scores\n",
        "\n",
        "y_pred = regXGB.predict(X_train)\n",
        "\n",
        "r2_train = r2_score(y_train, y_pred)\n",
        "rmse_train = np.sqrt(mean_squared_error(y_train, y_pred))\n",
        "mae_train = mean_absolute_error(y_train, y_pred)\n",
        "r2_adjusted_train = 1 - (1-r2_score(y_train, y_pred))*(len(y_train)-1)/(len(y_train)-X_train.shape[1]-1)\n",
        "sd_train = std(y_train)\n",
        "\n",
        "print(\"R^2 train: {}\".format(r2_train))\n",
        "print(\"R^2 adjusted train: {}\".format(r2_adjusted_train))\n",
        "print(\"Mean Absolute Error train: {}\".format(mae_train))\n",
        "print(\"Root Mean Squared Error train: {}\".format(rmse_train)) \n",
        "print(\"Standard Deviation train: {}\".format(sd_train))  \n",
        "\n",
        "# Compute test scores\n",
        "\n",
        "y_pred = regXGB.predict(X_test)\n",
        "\n",
        "r2_test = r2_score(y_test, y_pred)\n",
        "rmse_test = np.sqrt(mean_squared_error(y_test, y_pred))\n",
        "mae_test = mean_absolute_error(y_test, y_pred)\n",
        "r2_adjusted_test = 1 - (1-r2_score(y_test, y_pred))*(len(y_test)-1)/(len(y_test)-X_test.shape[1]-1)\n",
        "sd_test = std(y_test)\n",
        "\n",
        "print(\"R^2 test: {}\".format(r2_test))\n",
        "print(\"R^2 adjusted test: {}\".format(r2_adjusted_test))\n",
        "print(\"Mean Absolute Error test: {}\".format(mae_test))\n",
        "print(\"Root Mean Squared Error test: {}\".format(rmse_test))\n",
        "print(\"Standard Deviation test: {}\".format(sd_test)) \n"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "R^2 train: 0.6965437725030348\n",
            "R^2 adjusted train: 0.6955905438352594\n",
            "Mean Absolute Error train: 6.147501952031749\n",
            "Root Mean Squared Error train: 8.543583427500705\n",
            "Standard Deviation train: NO2_0    15.509294\n",
            "dtype: float64\n",
            "R^2 test: 0.6113603451702769\n",
            "R^2 adjusted test: 0.6063643426244576\n",
            "Mean Absolute Error test: 7.867007822413982\n",
            "Root Mean Squared Error test: 11.505656982615232\n",
            "Standard Deviation test: NO2_0    18.456012\n",
            "dtype: float64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "BGcFlBxqAhIb",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        ""
      ]
    },
    {
      "metadata": {
        "id": "Ht2DvjhDAHzd",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# NO2 forecasts 6 hours ahead\n",
        "n_estimators=500, min_samples_leaf=10,max_depth=2, random_state=42"
      ]
    },
    {
      "metadata": {
        "id": "mCef-K8-mL8b",
        "colab_type": "code",
        "outputId": "de778d9f-f313-4269-d87f-fba98922608f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "cell_type": "code",
      "source": [
        "X_train = pyreadr.read_r(\"X_train_NO2_201401_201612_multivar.rds\")\n",
        "y_train = pyreadr.read_r(\"y_train_NO2_201401_201612_multivar.rds\")\n",
        "\n",
        "X_test = pyreadr.read_r(\"X_test_NO2_201701_201709_multivar.rds\")\n",
        "y_test = pyreadr.read_r(\"y_test_NO2_201701_201709_multivar.rds\")\n",
        "\n",
        "X_train = X_train[None]\n",
        "y_train = y_train[None]\n",
        "X_test = X_test[None]\n",
        "y_test = y_test[None]\n",
        "\n",
        "# We convert the 'hour' variable to string\n",
        "X_train.hour = X_train.hour.astype(str)\n",
        "X_test.hour = X_test.hour.astype(str)\n",
        "\n",
        "# We convert the 'week_day' variable to string\n",
        "X_train.week_day = X_train.week_day.astype(str)\n",
        "X_test.week_day = X_test.week_day.astype(str)\n",
        "\n",
        "# We convert the 'month' variable to string\n",
        "X_train.month = X_train.month.astype(str)\n",
        "X_test.month = X_test.month.astype(str)\n",
        "\n",
        "X_train = X_train[['NO2_6', 'NO2_7', 'NO2_10', 'NO2_11', 'NO2_22', 'NO2_23', 'NO2_24',\n",
        "                   'NO2_25', 'NO2_26', 'NO2_27','NO2_48', 'NO2_72', 'NO2_96', 'NO2_120', 'NO2_144', 'NO2_168',\n",
        "                  'no_lab_days', 'hour','month', 'week_day']]\n",
        "\n",
        "X_test = X_test[['NO2_6', 'NO2_7', 'NO2_10', 'NO2_11', 'NO2_22', 'NO2_23', 'NO2_24',\n",
        "                   'NO2_25', 'NO2_26', 'NO2_27','NO2_48', 'NO2_72', 'NO2_96', 'NO2_120', 'NO2_144', 'NO2_168',\n",
        "                  'no_lab_days', 'hour','month', 'week_day']]\n",
        "\n",
        "\n",
        "X_train = pd.get_dummies(X_train)\n",
        "X_test  = pd.get_dummies(X_test)\n",
        "\n",
        "\n",
        "# Al hacer el one hot encoding el X_train y el X_test tienen distintas dimensiones. X_train tiene 47 variables y X_test 44. Por que? Porque el dataset de test tiene solo 9 meses, de enero a septiembre, y entonces la variable month solo se convierte en 9 variables, mientras que el dataset tendriamos 12, los 12 meses del anho. \n",
        "# Con el siguiente codigo solucionamos el problema (falta referencia)\n",
        "\n",
        "# Get missing columns in the training test\n",
        "missing_cols = set( X_train.columns ) - set( X_test.columns )\n",
        "# Add a missing column in test set with default value equal to 0\n",
        "for c in missing_cols:\n",
        "    X_test[c] = 0\n",
        "# Ensure the order of column in the test set is in the same order than in train set\n",
        "X_test = X_test[X_train.columns]\n",
        "# This code also ensure that column resulting from category in the test dataset but not present in the training dataset will be removed\n",
        "\n",
        "\n",
        "regXGB = XGBRegressor(n_estimators=100, min_samples_leaf=10,max_depth=2, random_state=42)\n",
        "regXGB.fit(X_train,y_train)\n",
        "\n",
        "\n",
        "# Compute train scores\n",
        "\n",
        "y_pred = regXGB.predict(X_train)\n",
        "\n",
        "r2_train = r2_score(y_train, y_pred)\n",
        "rmse_train = np.sqrt(mean_squared_error(y_train, y_pred))\n",
        "mae_train = mean_absolute_error(y_train, y_pred)\n",
        "r2_adjusted_train = 1 - (1-r2_score(y_train, y_pred))*(len(y_train)-1)/(len(y_train)-X_train.shape[1]-1)\n",
        "sd_train = std(y_train)\n",
        "\n",
        "print(\"R^2 train: {}\".format(r2_train))\n",
        "print(\"R^2 adjusted train: {}\".format(r2_adjusted_train))\n",
        "print(\"Mean Absolute Error train: {}\".format(mae_train))\n",
        "print(\"Root Mean Squared Error train: {}\".format(rmse_train)) \n",
        "print(\"Standard Deviation train: {}\".format(sd_train))  \n",
        "\n",
        "# Compute test scores\n",
        "\n",
        "y_pred = regXGB.predict(X_test)\n",
        "\n",
        "r2_test = r2_score(y_test, y_pred)\n",
        "rmse_test = np.sqrt(mean_squared_error(y_test, y_pred))\n",
        "mae_test = mean_absolute_error(y_test, y_pred)\n",
        "r2_adjusted_test = 1 - (1-r2_score(y_test, y_pred))*(len(y_test)-1)/(len(y_test)-X_test.shape[1]-1)\n",
        "sd_test = std(y_test)\n",
        "\n",
        "print(\"R^2 test: {}\".format(r2_test))\n",
        "print(\"R^2 adjusted test: {}\".format(r2_adjusted_test))\n",
        "print(\"Mean Absolute Error test: {}\".format(mae_test))\n",
        "print(\"Root Mean Squared Error test: {}\".format(rmse_test))\n",
        "print(\"Standard Deviation test: {}\".format(sd_test)) \n"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "R^2 train: 0.5362032971606577\n",
            "R^2 adjusted train: 0.535106978518745\n",
            "Mean Absolute Error train: 7.938518851557161\n",
            "Root Mean Squared Error train: 10.562235971415772\n",
            "Standard Deviation train: NO2_0    15.509294\n",
            "dtype: float64\n",
            "R^2 test: 0.4230134972332297\n",
            "R^2 adjusted test: 0.41744536297143997\n",
            "Mean Absolute Error test: 10.162366484658447\n",
            "Root Mean Squared Error test: 14.019118069751247\n",
            "Standard Deviation test: NO2_0    18.456012\n",
            "dtype: float64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "VsFdGORYGEa9",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# NO2 forecasts 6 hours ahead\n",
        "### Gridsearchcv  \n",
        " \"n_estimators\":[100, 500, 1000, 2000],  \n",
        "                                \"min_samples_leaf\":[10,30],  \n",
        "                                  \"max_depth\":range(2,5)},  \n",
        "                                    scoring=\"neg_mean_absolute_error\")  \n"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "7pd2ElriFRPJ",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "X_train = pyreadr.read_r(\"X_train_PM10_201401_201612_multivar.rds\")\n",
        "y_train = pyreadr.read_r(\"y_train_PM10_201401_201612_multivar.rds\")\n",
        "\n",
        "X_test = pyreadr.read_r(\"X_test_PM10_201701_201709_multivar.rds\")\n",
        "y_test = pyreadr.read_r(\"y_test_PM10_201701_201709_multivar.rds\")\n",
        "\n",
        "X_train = X_train[None]\n",
        "y_train = y_train[None]\n",
        "X_test = X_test[None]\n",
        "y_test = y_test[None]\n",
        "\n",
        "# We convert the 'hour' variable to string\n",
        "X_train.hour = X_train.hour.astype(str)\n",
        "X_test.hour = X_test.hour.astype(str)\n",
        "\n",
        "# We convert the 'week_day' variable to string\n",
        "X_train.week_day = X_train.week_day.astype(str)\n",
        "X_test.week_day = X_test.week_day.astype(str)\n",
        "\n",
        "# We convert the 'month' variable to string\n",
        "X_train.month = X_train.month.astype(str)\n",
        "X_test.month = X_test.month.astype(str)\n",
        "\n",
        "X_train = X_train[['NO2_6', 'NO2_7', 'NO2_10', 'NO2_11', 'NO2_22', 'NO2_23', 'NO2_24',\n",
        "                   'NO2_25', 'NO2_26', 'NO2_27','NO2_48', 'NO2_72', 'NO2_96', 'NO2_120', 'NO2_144', 'NO2_168',\n",
        "                  'no_lab_days', 'hour','month', 'week_day']]\n",
        "\n",
        "X_test = X_test[['NO2_6', 'NO2_7', 'NO2_10', 'NO2_11', 'NO2_22', 'NO2_23', 'NO2_24',\n",
        "                   'NO2_25', 'NO2_26', 'NO2_27','NO2_48', 'NO2_72', 'NO2_96', 'NO2_120', 'NO2_144', 'NO2_168',\n",
        "                  'no_lab_days', 'hour','month', 'week_day']]\n",
        "\n",
        "\n",
        "\n",
        "X_train = pd.get_dummies(X_train)\n",
        "X_test  = pd.get_dummies(X_test)\n",
        "\n",
        "\n",
        "# Al hacer el one hot encoding el X_train y el X_test tienen distintas dimensiones. X_train tiene 47 variables y X_test 44. Por que? Porque el dataset de test tiene solo 9 meses, de enero a septiembre, y entonces la variable month solo se convierte en 9 variables, mientras que el dataset tendriamos 12, los 12 meses del anho. \n",
        "# Con el siguiente codigo solucionamos el problema (falta referencia)\n",
        "\n",
        "# Get missing columns in the training test\n",
        "missing_cols = set( X_train.columns ) - set( X_test.columns )\n",
        "# Add a missing column in test set with default value equal to 0\n",
        "for c in missing_cols:\n",
        "    X_test[c] = 0\n",
        "# Ensure the order of column in the test set is in the same order than in train set\n",
        "X_test = X_test[X_train.columns]\n",
        "# This code also ensure that column resulting from category in the test dataset but not present in the training dataset will be removed\n",
        "\n",
        "\n",
        "\n",
        "regXGB = GridSearchCV(XGBRegressor(n_estimators=350, min_samples_leaf=1,max_depth=4, random_state=42),\n",
        "                   param_grid={\"n_estimators\":[100, 500, 1000, 2000],\n",
        "                                \"min_samples_leaf\":[10,30],\n",
        "                                  \"max_depth\":range(2,5)},\n",
        "                                    scoring=\"neg_mean_absolute_error\")\n",
        "\n",
        "regXGB.fit(X_train,y_train)\n",
        "\n",
        "print(regXGB.best_params_)\n",
        "print(\"Best score: {}\".format(regXGB.best_score_))\n",
        "\n",
        "\n",
        "# Compute train scores\n",
        "\n",
        "y_pred = regXGB.predict(X_train)\n",
        "\n",
        "r2_train = r2_score(y_train, y_pred)\n",
        "rmse_train = np.sqrt(mean_squared_error(y_train, y_pred))\n",
        "mae_train = mean_absolute_error(y_train, y_pred)\n",
        "r2_adjusted_train = 1 - (1-r2_score(y_train, y_pred))*(len(y_train)-1)/(len(y_train)-X_train.shape[1]-1)\n",
        "sd_train = std(y_train)\n",
        "\n",
        "print(\"R^2 train: {}\".format(r2_train))\n",
        "print(\"R^2 adjusted train: {}\".format(r2_adjusted_train))\n",
        "print(\"Mean Absolute Error train: {}\".format(mae_train))\n",
        "print(\"Root Mean Squared Error train: {}\".format(rmse_train)) \n",
        "print(\"Standard Deviation train: {}\".format(sd_train))  \n",
        "\n",
        "# Compute test scores\n",
        "\n",
        "y_pred = regXGB.predict(X_test)\n",
        "\n",
        "r2_test = r2_score(y_test, y_pred)\n",
        "rmse_test = np.sqrt(mean_squared_error(y_test, y_pred))\n",
        "mae_test = mean_absolute_error(y_test, y_pred)\n",
        "r2_adjusted_test = 1 - (1-r2_score(y_test, y_pred))*(len(y_test)-1)/(len(y_test)-X_test.shape[1]-1)\n",
        "sd_test = std(y_test)\n",
        "\n",
        "print(\"R^2 test: {}\".format(r2_test))\n",
        "print(\"R^2 adjusted test: {}\".format(r2_adjusted_test))\n",
        "print(\"Mean Absolute Error test: {}\".format(mae_test))\n",
        "print(\"Root Mean Squared Error test: {}\".format(rmse_test))\n",
        "print(\"Standard Deviation test: {}\".format(sd_test))  \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "zF9wio5RBWQ2"
      },
      "cell_type": "markdown",
      "source": [
        "# NO2 forecasts 12 hours ahead"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "outputId": "54abde34-4dd7-4bc1-d979-8dd9a6f78740",
        "id": "mLQaa1ynBWQ3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "cell_type": "code",
      "source": [
        "X_train = pyreadr.read_r(\"X_train_NO2_201401_201612_multivar.rds\")\n",
        "y_train = pyreadr.read_r(\"y_train_NO2_201401_201612_multivar.rds\")\n",
        "\n",
        "X_test = pyreadr.read_r(\"X_test_NO2_201701_201709_multivar.rds\")\n",
        "y_test = pyreadr.read_r(\"y_test_NO2_201701_201709_multivar.rds\")\n",
        "\n",
        "X_train = X_train[None]\n",
        "y_train = y_train[None]\n",
        "X_test = X_test[None]\n",
        "y_test = y_test[None]\n",
        "\n",
        "# We convert the 'hour' variable to string\n",
        "X_train.hour = X_train.hour.astype(str)\n",
        "X_test.hour = X_test.hour.astype(str)\n",
        "\n",
        "# We convert the 'week_day' variable to string\n",
        "X_train.week_day = X_train.week_day.astype(str)\n",
        "X_test.week_day = X_test.week_day.astype(str)\n",
        "\n",
        "# We convert the 'month' variable to string\n",
        "X_train.month = X_train.month.astype(str)\n",
        "X_test.month = X_test.month.astype(str)\n",
        "\n",
        "X_train = X_train[['NO2_12', 'NO2_13','NO2_22', 'NO2_23', 'NO2_24',\n",
        "                   'NO2_25', 'NO2_26', 'NO2_27','NO2_48', 'NO2_72', 'NO2_96', 'NO2_120', 'NO2_144', 'NO2_168',\n",
        "                  'no_lab_days', 'hour','month', 'week_day']]\n",
        "\n",
        "X_test = X_test[['NO2_12', 'NO2_13','NO2_22', 'NO2_23', 'NO2_24',\n",
        "                   'NO2_25', 'NO2_26', 'NO2_27','NO2_48', 'NO2_72', 'NO2_96', 'NO2_120', 'NO2_144', 'NO2_168',\n",
        "                  'no_lab_days', 'hour','month', 'week_day']]\n",
        "\n",
        "\n",
        "\n",
        "X_train = pd.get_dummies(X_train)\n",
        "X_test  = pd.get_dummies(X_test)\n",
        "\n",
        "\n",
        "# Al hacer el one hot encoding el X_train y el X_test tienen distintas dimensiones. X_train tiene 47 variables y X_test 44. Por que? Porque el dataset de test tiene solo 9 meses, de enero a septiembre, y entonces la variable month solo se convierte en 9 variables, mientras que el dataset tendriamos 12, los 12 meses del anho. \n",
        "# Con el siguiente codigo solucionamos el problema (falta referencia)\n",
        "\n",
        "# Get missing columns in the training test\n",
        "missing_cols = set( X_train.columns ) - set( X_test.columns )\n",
        "# Add a missing column in test set with default value equal to 0\n",
        "for c in missing_cols:\n",
        "    X_test[c] = 0\n",
        "# Ensure the order of column in the test set is in the same order than in train set\n",
        "X_test = X_test[X_train.columns]\n",
        "# This code also ensure that column resulting from category in the test dataset but not present in the training dataset will be removed\n",
        "\n",
        "\n",
        "\n",
        "regXGB = XGBRegressor(n_estimators=500, min_samples_leaf=10,max_depth=2, random_state=42)\n",
        "regXGB.fit(X_train,y_train)\n",
        "\n",
        "\n",
        "# Compute train scores\n",
        "\n",
        "y_pred = regXGB.predict(X_train)\n",
        "\n",
        "r2_train = r2_score(y_train, y_pred)\n",
        "rmse_train = np.sqrt(mean_squared_error(y_train, y_pred))\n",
        "mae_train = mean_absolute_error(y_train, y_pred)\n",
        "r2_adjusted_train = 1 - (1-r2_score(y_train, y_pred))*(len(y_train)-1)/(len(y_train)-X_train.shape[1]-1)\n",
        "sd_train = std(y_train)\n",
        "\n",
        "print(\"R^2 train: {}\".format(r2_train))\n",
        "print(\"R^2 adjusted train: {}\".format(r2_adjusted_train))\n",
        "print(\"Mean Absolute Error train: {}\".format(mae_train))\n",
        "print(\"Root Mean Squared Error train: {}\".format(rmse_train)) \n",
        "print(\"Standard Deviation train: {}\".format(sd_train))  \n",
        "\n",
        "# Compute test scores\n",
        "\n",
        "y_pred = regXGB.predict(X_test)\n",
        "\n",
        "r2_test = r2_score(y_test, y_pred)\n",
        "rmse_test = np.sqrt(mean_squared_error(y_test, y_pred))\n",
        "mae_test = mean_absolute_error(y_test, y_pred)\n",
        "r2_adjusted_test = 1 - (1-r2_score(y_test, y_pred))*(len(y_test)-1)/(len(y_test)-X_test.shape[1]-1)\n",
        "sd_test = std(y_test)\n",
        "\n",
        "print(\"R^2 test: {}\".format(r2_test))\n",
        "print(\"R^2 adjusted test: {}\".format(r2_adjusted_test))\n",
        "print(\"Mean Absolute Error test: {}\".format(mae_test))\n",
        "print(\"Root Mean Squared Error test: {}\".format(rmse_test))\n",
        "print(\"Standard Deviation test: {}\".format(sd_test))  \n"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "R^2 train: 0.5569001723831173\n",
            "R^2 adjusted train: 0.5558871961808003\n",
            "Mean Absolute Error train: 7.809096928173695\n",
            "Root Mean Squared Error train: 10.323877149442207\n",
            "Standard Deviation train: NO2_0    15.509294\n",
            "dtype: float64\n",
            "R^2 test: 0.4129202206779562\n",
            "R^2 adjusted test: 0.40744217117930037\n",
            "Mean Absolute Error test: 10.236640899401651\n",
            "Root Mean Squared Error test: 14.141205307604745\n",
            "Standard Deviation test: NO2_0    18.456012\n",
            "dtype: float64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "WEwgalJwB2lw"
      },
      "cell_type": "markdown",
      "source": [
        "# NO2 forecasts 24 hours ahead"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "outputId": "2bbe0033-e8ae-4dbf-c25b-09a509e53098",
        "id": "ThpX0n9dB2lx",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "cell_type": "code",
      "source": [
        "X_train = pyreadr.read_r(\"X_train_NO2_201401_201612_multivar.rds\")\n",
        "y_train = pyreadr.read_r(\"y_train_NO2_201401_201612_multivar.rds\")\n",
        "\n",
        "X_test = pyreadr.read_r(\"X_test_NO2_201701_201709_multivar.rds\")\n",
        "y_test = pyreadr.read_r(\"y_test_NO2_201701_201709_multivar.rds\")\n",
        "\n",
        "X_train = X_train[None]\n",
        "y_train = y_train[None]\n",
        "X_test = X_test[None]\n",
        "y_test = y_test[None]\n",
        "\n",
        "# We convert the 'hour' variable to string\n",
        "X_train.hour = X_train.hour.astype(str)\n",
        "X_test.hour = X_test.hour.astype(str)\n",
        "\n",
        "# We convert the 'week_day' variable to string\n",
        "X_train.week_day = X_train.week_day.astype(str)\n",
        "X_test.week_day = X_test.week_day.astype(str)\n",
        "\n",
        "# We convert the 'month' variable to string\n",
        "X_train.month = X_train.month.astype(str)\n",
        "X_test.month = X_test.month.astype(str)\n",
        "\n",
        "X_train = X_train[[ 'NO2_24','NO2_25', 'NO2_26', 'NO2_27','NO2_48', 'NO2_72', 'NO2_96', 'NO2_120', 'NO2_144', 'NO2_168',\n",
        "                  'no_lab_days', 'hour','month', 'week_day']]\n",
        "\n",
        "X_test = X_test[['NO2_24', 'NO2_25', 'NO2_26', 'NO2_27','NO2_48', 'NO2_72', 'NO2_96', 'NO2_120', 'NO2_144', 'NO2_168',\n",
        "                  'no_lab_days', 'hour','month', 'week_day']]\n",
        "\n",
        "\n",
        "\n",
        "X_train = pd.get_dummies(X_train)\n",
        "X_test  = pd.get_dummies(X_test)\n",
        "\n",
        "\n",
        "# Al hacer el one hot encoding el X_train y el X_test tienen distintas dimensiones. X_train tiene 47 variables y X_test 44. Por que? Porque el dataset de test tiene solo 9 meses, de enero a septiembre, y entonces la variable month solo se convierte en 9 variables, mientras que el dataset tendriamos 12, los 12 meses del anho. \n",
        "# Con el siguiente codigo solucionamos el problema (falta referencia)\n",
        "\n",
        "# Get missing columns in the training test\n",
        "missing_cols = set( X_train.columns ) - set( X_test.columns )\n",
        "# Add a missing column in test set with default value equal to 0\n",
        "for c in missing_cols:\n",
        "    X_test[c] = 0\n",
        "# Ensure the order of column in the test set is in the same order than in train set\n",
        "X_test = X_test[X_train.columns]\n",
        "# This code also ensure that column resulting from category in the test dataset but not present in the training dataset will be removed\n",
        "\n",
        "\n",
        "\n",
        "regXGB = XGBRegressor(n_estimators=500, min_samples_leaf=10,max_depth=2, random_state=42)\n",
        "regXGB.fit(X_train,y_train)\n",
        "\n",
        "\n",
        "# Compute train scores\n",
        "\n",
        "y_pred = regXGB.predict(X_train)\n",
        "\n",
        "r2_train = r2_score(y_train, y_pred)\n",
        "rmse_train = np.sqrt(mean_squared_error(y_train, y_pred))\n",
        "mae_train = mean_absolute_error(y_train, y_pred)\n",
        "r2_adjusted_train = 1 - (1-r2_score(y_train, y_pred))*(len(y_train)-1)/(len(y_train)-X_train.shape[1]-1)\n",
        "sd_train = std(y_train)\n",
        "\n",
        "print(\"R^2 train: {}\".format(r2_train))\n",
        "print(\"R^2 adjusted train: {}\".format(r2_adjusted_train))\n",
        "print(\"Mean Absolute Error train: {}\".format(mae_train))\n",
        "print(\"Root Mean Squared Error train: {}\".format(rmse_train)) \n",
        "print(\"Standard Deviation train: {}\".format(sd_train))  \n",
        "\n",
        "# Compute test scores\n",
        "\n",
        "y_pred = regXGB.predict(X_test)\n",
        "\n",
        "r2_test = r2_score(y_test, y_pred)\n",
        "rmse_test = np.sqrt(mean_squared_error(y_test, y_pred))\n",
        "mae_test = mean_absolute_error(y_test, y_pred)\n",
        "r2_adjusted_test = 1 - (1-r2_score(y_test, y_pred))*(len(y_test)-1)/(len(y_test)-X_test.shape[1]-1)\n",
        "sd_test = std(y_test)\n",
        "\n",
        "print(\"R^2 test: {}\".format(r2_test))\n",
        "print(\"R^2 adjusted test: {}\".format(r2_adjusted_test))\n",
        "print(\"Mean Absolute Error test: {}\".format(mae_test))\n",
        "print(\"Root Mean Squared Error test: {}\".format(rmse_test))\n",
        "print(\"Standard Deviation test: {}\".format(sd_test))  \n"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "R^2 train: 0.540393368346495\n",
            "R^2 adjusted train: 0.5394140422678904\n",
            "Mean Absolute Error train: 7.952183695451996\n",
            "Root Mean Squared Error train: 10.514416602596459\n",
            "Standard Deviation train: NO2_0    15.509294\n",
            "dtype: float64\n",
            "R^2 test: 0.3866394169849271\n",
            "R^2 adjusted test: 0.3813075326691646\n",
            "Mean Absolute Error test: 10.417640159747808\n",
            "Root Mean Squared Error test: 14.454257853387166\n",
            "Standard Deviation test: NO2_0    18.456012\n",
            "dtype: float64\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}