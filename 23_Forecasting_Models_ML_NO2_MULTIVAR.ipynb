{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "23_Forecasting_Models_ML_NO2_MULTIVAR.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sergioberdiales/TFM_KSchool_Gijon_Air_Pollution/blob/master/23_Forecasting_Models_ML_NO2_MULTIVAR.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "C2KUABWEp4T6",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "23_Forecasting_Models_ML_NO2_MULTIVAR.ipynb\n",
        "\n",
        "In this notebook we are going to try to improve the forecasts creating multivariate models. \n",
        "We will use the XGBoost algorithm and the three years training period (2014-01-01 - 2016-12-31).\n",
        "Testing period: 2017-01-01 - 2017-09-30. "
      ]
    },
    {
      "metadata": {
        "id": "i-4Gs37dWIA0",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### We import the libraries we need to run the algorithms"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "outputId": "98b4dfd0-2b0b-4905-814f-f933427d9373",
        "id": "OxJRU8VLpp9W",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "cell_type": "code",
      "source": [
        "%pylab inline\n",
        "import pandas as pd\n",
        "\n",
        "# We install and import pyreadr, in order to read rds objects.  \n",
        "# https://github.com/ofajardo/pyreadr\n",
        "\n",
        "!pip install pyreadr\n",
        "import pyreadr\n",
        "\n",
        "\n",
        "# Importing models\n",
        "\n",
        "\n",
        "import statsmodels.api as sm\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from xgboost import XGBRegressor\n",
        "import os\n",
        "os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\"\n",
        "\n",
        "# Importing metrics\n",
        "\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "from sklearn.metrics import r2_score\n",
        "\n",
        "# Model selection\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# Variable selection\n",
        "\n",
        "import sklearn\n",
        "from sklearn.feature_selection import f_regression\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Populating the interactive namespace from numpy and matplotlib\n",
            "Collecting pyreadr\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ed/a1/ee5e65051881ee8c9e0774fd04f1d3916671d9a067c86ddcdb1e5734f99a/pyreadr-0.1.6-cp36-cp36m-manylinux1_x86_64.whl (210kB)\n",
            "\u001b[K    100% |████████████████████████████████| 215kB 25.7MB/s \n",
            "\u001b[?25hInstalling collected packages: pyreadr\n",
            "Successfully installed pyreadr-0.1.6\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/compat/pandas.py:56: FutureWarning: The pandas.core.datetools module is deprecated and will be removed in a future version. Please use the pandas.tseries module instead.\n",
            "  from pandas.core import datetools\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "Dh0qqPFMpp9d"
      },
      "cell_type": "markdown",
      "source": [
        "We upload the train and test data. All rds files from this folder  ~\\`TFM_KSchool_Gijon_Air_Pollution\\train_test\\\n",
        "Forecasting_Models_ML_NO2\n",
        "\n",
        "The train and test datasets were generated running this rmd file \"_10_2_train_test_MULTIVAR_datasets.rmd\""
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "gWOu3DSopp9e",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 650
        },
        "outputId": "1b020e3a-45c9-4dd9-9f4c-aa0bf0c65fd5"
      },
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "uploaded = files.upload()\n",
        "\n",
        "for fn in uploaded.keys():\n",
        "  print('User uploaded file \"{name}\" with length {length} bytes'.format(\n",
        "      name=fn, length=len(uploaded[fn])))"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-df9994cd-3bfe-4189-a7ae-3af8e272e9a2\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-df9994cd-3bfe-4189-a7ae-3af8e272e9a2\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving X_test_NO2_201701_201709_multivar.rds to X_test_NO2_201701_201709_multivar.rds\n",
            "Saving X_test_NO2_20170101_20170114_multivar.rds to X_test_NO2_20170101_20170114_multivar.rds\n",
            "Saving X_train_NO2_200901_201612_multivar.rds to X_train_NO2_200901_201612_multivar.rds\n",
            "Saving X_train_NO2_201401_201612_multivar.rds to X_train_NO2_201401_201612_multivar.rds\n",
            "Saving X_train_NO2_201610_201612_multivar.rds to X_train_NO2_201610_201612_multivar.rds\n",
            "Saving X_validation_NO2_201710_201712_multivar.rds to X_validation_NO2_201710_201712_multivar.rds\n",
            "Saving y_test_NO2_201701_201709_multivar.rds to y_test_NO2_201701_201709_multivar.rds\n",
            "Saving y_test_NO2_20170101_20170114_multivar.rds to y_test_NO2_20170101_20170114_multivar.rds\n",
            "Saving y_train_NO2_200901_201612_multivar.rds to y_train_NO2_200901_201612_multivar.rds\n",
            "Saving y_train_NO2_201401_201612_multivar.rds to y_train_NO2_201401_201612_multivar.rds\n",
            "Saving y_train_NO2_201610_201612_multivar.rds to y_train_NO2_201610_201612_multivar.rds\n",
            "Saving y_validation_NO2_201710_201712_multivar.rds to y_validation_NO2_201710_201712_multivar.rds\n",
            "User uploaded file \"X_test_NO2_201701_201709_multivar.rds\" with length 410278 bytes\n",
            "User uploaded file \"X_test_NO2_20170101_20170114_multivar.rds\" with length 4972 bytes\n",
            "User uploaded file \"X_train_NO2_200901_201612_multivar.rds\" with length 1756553 bytes\n",
            "User uploaded file \"X_train_NO2_201401_201612_multivar.rds\" with length 1544441 bytes\n",
            "User uploaded file \"X_train_NO2_201610_201612_multivar.rds\" with length 40831 bytes\n",
            "User uploaded file \"X_validation_NO2_201710_201712_multivar.rds\" with length 41209 bytes\n",
            "User uploaded file \"y_test_NO2_201701_201709_multivar.rds\" with length 9275 bytes\n",
            "User uploaded file \"y_test_NO2_20170101_20170114_multivar.rds\" with length 1225 bytes\n",
            "User uploaded file \"y_train_NO2_200901_201612_multivar.rds\" with length 237413 bytes\n",
            "User uploaded file \"y_train_NO2_201401_201612_multivar.rds\" with length 32833 bytes\n",
            "User uploaded file \"y_train_NO2_201610_201612_multivar.rds\" with length 3910 bytes\n",
            "User uploaded file \"y_validation_NO2_201710_201712_multivar.rds\" with length 4084 bytes\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "kV-EfqxNtTqI",
        "colab_type": "code",
        "outputId": "58a03ec2-4385-4908-c4bb-1041f66b6685",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "sample_data\n",
            "X_test_NO2_20170101_20170114_multivar.rds\n",
            "X_test_NO2_201701_201709_multivar.rds\n",
            "X_train_NO2_200901_201612_multivar.rds\n",
            "X_train_NO2_201401_201612_multivar.rds\n",
            "X_train_NO2_201610_201612_multivar.rds\n",
            "X_validation_NO2_201710_201712_multivar.rds\n",
            "y_test_NO2_20170101_20170114_multivar.rds\n",
            "y_test_NO2_201701_201709_multivar.rds\n",
            "y_train_NO2_200901_201612_multivar.rds\n",
            "y_train_NO2_201401_201612_multivar.rds\n",
            "y_train_NO2_201610_201612_multivar.rds\n",
            "y_validation_NO2_201710_201712_multivar.rds\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "oytAsB0os3OL",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# NO2 forecasts auto regressive models\n",
        "Only NO2 lagged values"
      ]
    },
    {
      "metadata": {
        "id": "kK1hRo93OzCi",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### XGBOOST"
      ]
    },
    {
      "metadata": {
        "id": "BJQ_OmsOwo6a",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Variables selection"
      ]
    },
    {
      "metadata": {
        "id": "CYJF87J0dres",
        "colab_type": "code",
        "outputId": "cc3e9813-013e-4405-855f-413a2c25f809",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1072
        }
      },
      "cell_type": "code",
      "source": [
        "X_train = pyreadr.read_r(\"X_train_NO2_201401_201612_multivar.rds\")\n",
        "y_train = pyreadr.read_r(\"y_train_NO2_201401_201612_multivar.rds\")\n",
        "\n",
        "X_test = pyreadr.read_r(\"X_test_NO2_201701_201709_multivar.rds\")\n",
        "y_test = pyreadr.read_r(\"y_test_NO2_201701_201709_multivar.rds\")\n",
        "\n",
        "X_train = X_train[None]\n",
        "y_train = y_train[None]\n",
        "X_test = X_test[None]\n",
        "y_test = y_test[None]\n",
        "\n",
        "# We select only the lagged variables of the NO2 pollutant\n",
        "X_train = X_train.loc[:, X_train.columns.str.startswith('NO2')]\n",
        "\n",
        "X_test = X_test.loc[:, X_train.columns.str.startswith('NO2')]\n",
        "\n",
        "\n",
        "results = sm.OLS(y_train, X_train).fit()\n",
        "\n",
        "results_summary = results.summary()\n",
        "\n",
        "# We extract the table with the variables, coefficientes, p-values, etc.\n",
        "\n",
        "results_as_html = results_summary.tables[1].as_html()\n",
        "table_p = pd.read_html(results_as_html, header=0, index_col=0)[0]\n",
        "table_p\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>coef</th>\n",
              "      <th>std err</th>\n",
              "      <th>t</th>\n",
              "      <th>P&gt;|t|</th>\n",
              "      <th>[0.025</th>\n",
              "      <th>0.975]</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>NO2_1</th>\n",
              "      <td>0.8980</td>\n",
              "      <td>0.006</td>\n",
              "      <td>143.597</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.886</td>\n",
              "      <td>0.910</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>NO2_2</th>\n",
              "      <td>-0.1225</td>\n",
              "      <td>0.008</td>\n",
              "      <td>-14.620</td>\n",
              "      <td>0.000</td>\n",
              "      <td>-0.139</td>\n",
              "      <td>-0.106</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>NO2_3</th>\n",
              "      <td>0.0083</td>\n",
              "      <td>0.008</td>\n",
              "      <td>0.985</td>\n",
              "      <td>0.325</td>\n",
              "      <td>-0.008</td>\n",
              "      <td>0.025</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>NO2_4</th>\n",
              "      <td>-0.0122</td>\n",
              "      <td>0.008</td>\n",
              "      <td>-1.459</td>\n",
              "      <td>0.145</td>\n",
              "      <td>-0.029</td>\n",
              "      <td>0.004</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>NO2_5</th>\n",
              "      <td>0.0160</td>\n",
              "      <td>0.008</td>\n",
              "      <td>1.907</td>\n",
              "      <td>0.056</td>\n",
              "      <td>-0.000</td>\n",
              "      <td>0.032</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>NO2_6</th>\n",
              "      <td>-0.0119</td>\n",
              "      <td>0.008</td>\n",
              "      <td>-1.422</td>\n",
              "      <td>0.155</td>\n",
              "      <td>-0.028</td>\n",
              "      <td>0.005</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>NO2_7</th>\n",
              "      <td>0.0001</td>\n",
              "      <td>0.008</td>\n",
              "      <td>0.013</td>\n",
              "      <td>0.990</td>\n",
              "      <td>-0.016</td>\n",
              "      <td>0.017</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>NO2_8</th>\n",
              "      <td>0.0094</td>\n",
              "      <td>0.008</td>\n",
              "      <td>1.119</td>\n",
              "      <td>0.263</td>\n",
              "      <td>-0.007</td>\n",
              "      <td>0.026</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>NO2_9</th>\n",
              "      <td>-0.0032</td>\n",
              "      <td>0.008</td>\n",
              "      <td>-0.379</td>\n",
              "      <td>0.705</td>\n",
              "      <td>-0.020</td>\n",
              "      <td>0.013</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>NO2_10</th>\n",
              "      <td>0.0366</td>\n",
              "      <td>0.008</td>\n",
              "      <td>4.374</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.020</td>\n",
              "      <td>0.053</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>NO2_11</th>\n",
              "      <td>0.0188</td>\n",
              "      <td>0.008</td>\n",
              "      <td>2.236</td>\n",
              "      <td>0.025</td>\n",
              "      <td>0.002</td>\n",
              "      <td>0.035</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>NO2_12</th>\n",
              "      <td>0.0042</td>\n",
              "      <td>0.008</td>\n",
              "      <td>0.499</td>\n",
              "      <td>0.618</td>\n",
              "      <td>-0.012</td>\n",
              "      <td>0.021</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>NO2_13</th>\n",
              "      <td>-0.0016</td>\n",
              "      <td>0.008</td>\n",
              "      <td>-0.195</td>\n",
              "      <td>0.845</td>\n",
              "      <td>-0.018</td>\n",
              "      <td>0.015</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>NO2_14</th>\n",
              "      <td>-0.0132</td>\n",
              "      <td>0.008</td>\n",
              "      <td>-1.569</td>\n",
              "      <td>0.117</td>\n",
              "      <td>-0.030</td>\n",
              "      <td>0.003</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>NO2_15</th>\n",
              "      <td>-0.0222</td>\n",
              "      <td>0.008</td>\n",
              "      <td>-2.646</td>\n",
              "      <td>0.008</td>\n",
              "      <td>-0.039</td>\n",
              "      <td>-0.006</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>NO2_16</th>\n",
              "      <td>-0.0118</td>\n",
              "      <td>0.008</td>\n",
              "      <td>-1.407</td>\n",
              "      <td>0.159</td>\n",
              "      <td>-0.028</td>\n",
              "      <td>0.005</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>NO2_17</th>\n",
              "      <td>0.0027</td>\n",
              "      <td>0.008</td>\n",
              "      <td>0.325</td>\n",
              "      <td>0.745</td>\n",
              "      <td>-0.014</td>\n",
              "      <td>0.019</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>NO2_18</th>\n",
              "      <td>0.0077</td>\n",
              "      <td>0.008</td>\n",
              "      <td>0.916</td>\n",
              "      <td>0.360</td>\n",
              "      <td>-0.009</td>\n",
              "      <td>0.024</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>NO2_19</th>\n",
              "      <td>0.0077</td>\n",
              "      <td>0.008</td>\n",
              "      <td>0.917</td>\n",
              "      <td>0.359</td>\n",
              "      <td>-0.009</td>\n",
              "      <td>0.024</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>NO2_20</th>\n",
              "      <td>-0.0066</td>\n",
              "      <td>0.008</td>\n",
              "      <td>-0.788</td>\n",
              "      <td>0.430</td>\n",
              "      <td>-0.023</td>\n",
              "      <td>0.010</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>NO2_21</th>\n",
              "      <td>0.0035</td>\n",
              "      <td>0.008</td>\n",
              "      <td>0.415</td>\n",
              "      <td>0.678</td>\n",
              "      <td>-0.013</td>\n",
              "      <td>0.020</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>NO2_22</th>\n",
              "      <td>0.0572</td>\n",
              "      <td>0.008</td>\n",
              "      <td>6.810</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.041</td>\n",
              "      <td>0.074</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>NO2_23</th>\n",
              "      <td>0.0578</td>\n",
              "      <td>0.008</td>\n",
              "      <td>6.866</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.041</td>\n",
              "      <td>0.074</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>NO2_24</th>\n",
              "      <td>0.0614</td>\n",
              "      <td>0.008</td>\n",
              "      <td>7.280</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.045</td>\n",
              "      <td>0.078</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>NO2_25</th>\n",
              "      <td>-0.0426</td>\n",
              "      <td>0.008</td>\n",
              "      <td>-5.056</td>\n",
              "      <td>0.000</td>\n",
              "      <td>-0.059</td>\n",
              "      <td>-0.026</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>NO2_26</th>\n",
              "      <td>-0.0306</td>\n",
              "      <td>0.008</td>\n",
              "      <td>-3.641</td>\n",
              "      <td>0.000</td>\n",
              "      <td>-0.047</td>\n",
              "      <td>-0.014</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>NO2_27</th>\n",
              "      <td>-0.0462</td>\n",
              "      <td>0.006</td>\n",
              "      <td>-7.545</td>\n",
              "      <td>0.000</td>\n",
              "      <td>-0.058</td>\n",
              "      <td>-0.034</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>NO2_48</th>\n",
              "      <td>0.0240</td>\n",
              "      <td>0.004</td>\n",
              "      <td>6.586</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.017</td>\n",
              "      <td>0.031</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>NO2_72</th>\n",
              "      <td>0.0157</td>\n",
              "      <td>0.004</td>\n",
              "      <td>4.338</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.009</td>\n",
              "      <td>0.023</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>NO2_96</th>\n",
              "      <td>0.0150</td>\n",
              "      <td>0.004</td>\n",
              "      <td>4.158</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.008</td>\n",
              "      <td>0.022</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>NO2_120</th>\n",
              "      <td>0.0104</td>\n",
              "      <td>0.004</td>\n",
              "      <td>2.870</td>\n",
              "      <td>0.004</td>\n",
              "      <td>0.003</td>\n",
              "      <td>0.017</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>NO2_144</th>\n",
              "      <td>0.0236</td>\n",
              "      <td>0.004</td>\n",
              "      <td>6.551</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.017</td>\n",
              "      <td>0.031</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>NO2_168</th>\n",
              "      <td>0.0455</td>\n",
              "      <td>0.004</td>\n",
              "      <td>12.965</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.039</td>\n",
              "      <td>0.052</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           coef  std err        t  P>|t|  [0.025  0.975]\n",
              "NO2_1    0.8980    0.006  143.597  0.000   0.886   0.910\n",
              "NO2_2   -0.1225    0.008  -14.620  0.000  -0.139  -0.106\n",
              "NO2_3    0.0083    0.008    0.985  0.325  -0.008   0.025\n",
              "NO2_4   -0.0122    0.008   -1.459  0.145  -0.029   0.004\n",
              "NO2_5    0.0160    0.008    1.907  0.056  -0.000   0.032\n",
              "NO2_6   -0.0119    0.008   -1.422  0.155  -0.028   0.005\n",
              "NO2_7    0.0001    0.008    0.013  0.990  -0.016   0.017\n",
              "NO2_8    0.0094    0.008    1.119  0.263  -0.007   0.026\n",
              "NO2_9   -0.0032    0.008   -0.379  0.705  -0.020   0.013\n",
              "NO2_10   0.0366    0.008    4.374  0.000   0.020   0.053\n",
              "NO2_11   0.0188    0.008    2.236  0.025   0.002   0.035\n",
              "NO2_12   0.0042    0.008    0.499  0.618  -0.012   0.021\n",
              "NO2_13  -0.0016    0.008   -0.195  0.845  -0.018   0.015\n",
              "NO2_14  -0.0132    0.008   -1.569  0.117  -0.030   0.003\n",
              "NO2_15  -0.0222    0.008   -2.646  0.008  -0.039  -0.006\n",
              "NO2_16  -0.0118    0.008   -1.407  0.159  -0.028   0.005\n",
              "NO2_17   0.0027    0.008    0.325  0.745  -0.014   0.019\n",
              "NO2_18   0.0077    0.008    0.916  0.360  -0.009   0.024\n",
              "NO2_19   0.0077    0.008    0.917  0.359  -0.009   0.024\n",
              "NO2_20  -0.0066    0.008   -0.788  0.430  -0.023   0.010\n",
              "NO2_21   0.0035    0.008    0.415  0.678  -0.013   0.020\n",
              "NO2_22   0.0572    0.008    6.810  0.000   0.041   0.074\n",
              "NO2_23   0.0578    0.008    6.866  0.000   0.041   0.074\n",
              "NO2_24   0.0614    0.008    7.280  0.000   0.045   0.078\n",
              "NO2_25  -0.0426    0.008   -5.056  0.000  -0.059  -0.026\n",
              "NO2_26  -0.0306    0.008   -3.641  0.000  -0.047  -0.014\n",
              "NO2_27  -0.0462    0.006   -7.545  0.000  -0.058  -0.034\n",
              "NO2_48   0.0240    0.004    6.586  0.000   0.017   0.031\n",
              "NO2_72   0.0157    0.004    4.338  0.000   0.009   0.023\n",
              "NO2_96   0.0150    0.004    4.158  0.000   0.008   0.022\n",
              "NO2_120  0.0104    0.004    2.870  0.004   0.003   0.017\n",
              "NO2_144  0.0236    0.004    6.551  0.000   0.017   0.031\n",
              "NO2_168  0.0455    0.004   12.965  0.000   0.039   0.052"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "metadata": {
        "id": "ISmFPWzzdqXe",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 1 **hour** ahead"
      ]
    },
    {
      "metadata": {
        "id": "a-qac8vAo_dy",
        "colab_type": "code",
        "outputId": "013bb502-e68f-4a65-ad3f-b500861c9222",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "cell_type": "code",
      "source": [
        "X_train = pyreadr.read_r(\"X_train_NO2_201401_201612_multivar.rds\")\n",
        "y_train = pyreadr.read_r(\"y_train_NO2_201401_201612_multivar.rds\")\n",
        "\n",
        "X_test = pyreadr.read_r(\"X_test_NO2_201701_201709_multivar.rds\")\n",
        "y_test = pyreadr.read_r(\"y_test_NO2_201701_201709_multivar.rds\")\n",
        "\n",
        "X_train = X_train[None]\n",
        "y_train = y_train[None]\n",
        "X_test = X_test[None]\n",
        "y_test = y_test[None]\n",
        "\n",
        "X_train = X_train[['NO2_1', 'NO2_2', 'NO2_10', 'NO2_11', 'NO2_22', 'NO2_23', 'NO2_24',\n",
        "                   'NO2_25', 'NO2_26', 'NO2_27','NO2_48', 'NO2_72', 'NO2_96', 'NO2_120', 'NO2_144', 'NO2_168']]\n",
        "X_test = X_test[['NO2_1', 'NO2_2', 'NO2_10', 'NO2_11',  'NO2_22', 'NO2_23', 'NO2_24',\n",
        "                   'NO2_25', 'NO2_26', 'NO2_27','NO2_48', 'NO2_72', 'NO2_96', 'NO2_120', 'NO2_144', 'NO2_168']]\n",
        "\n",
        "\n",
        "\n",
        "regXGB = XGBRegressor(n_estimators=100, min_samples_leaf=10,max_depth=2, random_state=42)\n",
        "regXGB.fit(X_train,y_train)\n",
        "\n",
        "\n",
        "# Compute train scores\n",
        "\n",
        "y_pred = regXGB.predict(X_train)\n",
        "\n",
        "r2_train = r2_score(y_train, y_pred)\n",
        "rmse_train = np.sqrt(mean_squared_error(y_train, y_pred))\n",
        "mae_train = mean_absolute_error(y_train, y_pred)\n",
        "r2_adjusted_train = 1 - (1-r2_score(y_train, y_pred))*(len(y_train)-1)/(len(y_train)-X_train.shape[1]-1)\n",
        "sd_train = std(y_train)\n",
        "\n",
        "print(\"R^2 train: {}\".format(r2_train))\n",
        "print(\"R^2 adjusted train: {}\".format(r2_adjusted_train))\n",
        "print(\"Mean Absolute Error train: {}\".format(mae_train))\n",
        "print(\"Root Mean Squared Error train: {}\".format(rmse_train)) \n",
        "print(\"Standard Deviation train: {}\".format(sd_train))  \n",
        "\n",
        "# Compute test scores\n",
        "\n",
        "y_pred = regXGB.predict(X_test)\n",
        "\n",
        "r2_test = r2_score(y_test, y_pred)\n",
        "rmse_test = np.sqrt(mean_squared_error(y_test, y_pred))\n",
        "mae_test = mean_absolute_error(y_test, y_pred)\n",
        "r2_adjusted_test = 1 - (1-r2_score(y_test, y_pred))*(len(y_test)-1)/(len(y_test)-X_test.shape[1]-1)\n",
        "sd_test = std(y_test)\n",
        "\n",
        "print(\"R^2 test: {}\".format(r2_test))\n",
        "print(\"R^2 adjusted test: {}\".format(r2_adjusted_test))\n",
        "print(\"Mean Absolute Error test: {}\".format(mae_test))\n",
        "print(\"Root Mean Squared Error test: {}\".format(rmse_test))\n",
        "print(\"Standard Deviation test: {}\".format(sd_test))  \n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "R^2 train: 0.8196088276734563\n",
            "R^2 adjusted train: 0.8194971778820663\n",
            "Mean Absolute Error train: 4.612765113046078\n",
            "Root Mean Squared Error train: 6.587182227288358\n",
            "Standard Deviation train: NO2_0    15.509294\n",
            "dtype: float64\n",
            "R^2 test: 0.7611771043535913\n",
            "R^2 adjusted test: 0.7605768583073547\n",
            "Mean Absolute Error test: 5.877690026111055\n",
            "Root Mean Squared Error test: 9.019362585841288\n",
            "Standard Deviation test: NO2_0    18.456012\n",
            "dtype: float64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "kwzb51Vaw3yk",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 2 hours ahead"
      ]
    },
    {
      "metadata": {
        "id": "BTz7Rp_sw376",
        "colab_type": "code",
        "outputId": "3ed9dc97-7c0f-4bec-df35-7b53ef636bf6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "cell_type": "code",
      "source": [
        "X_train = pyreadr.read_r(\"X_train_NO2_201401_201612_multivar.rds\")\n",
        "y_train = pyreadr.read_r(\"y_train_NO2_201401_201612_multivar.rds\")\n",
        "\n",
        "X_test = pyreadr.read_r(\"X_test_NO2_201701_201709_multivar.rds\")\n",
        "y_test = pyreadr.read_r(\"y_test_NO2_201701_201709_multivar.rds\")\n",
        "\n",
        "X_train = X_train[None]\n",
        "y_train = y_train[None]\n",
        "X_test = X_test[None]\n",
        "y_test = y_test[None]\n",
        "\n",
        "\n",
        "\n",
        "X_train = X_train[[ 'NO2_2', 'NO2_10', 'NO2_11', 'NO2_22', 'NO2_23', 'NO2_24',\n",
        "                   'NO2_25', 'NO2_26', 'NO2_27','NO2_48', 'NO2_72', 'NO2_96', 'NO2_120', 'NO2_144', 'NO2_168']]\n",
        "\n",
        "X_test = X_test[['NO2_2', 'NO2_10', 'NO2_11', 'NO2_22', 'NO2_23', 'NO2_24',\n",
        "                   'NO2_25', 'NO2_26', 'NO2_27','NO2_48', 'NO2_72', 'NO2_96', 'NO2_120', 'NO2_144', 'NO2_168']]\n",
        "\n",
        "X_train = pd.get_dummies(X_train)\n",
        "X_test  = pd.get_dummies(X_test)\n",
        "\n",
        "\n",
        "\n",
        "regXGB = XGBRegressor(n_estimators=100, min_samples_leaf=10,max_depth=2, random_state=42)\n",
        "regXGB.fit(X_train,y_train)\n",
        "\n",
        "\n",
        "# Compute train scores\n",
        "\n",
        "y_pred = regXGB.predict(X_train)\n",
        "\n",
        "r2_train = r2_score(y_train, y_pred)\n",
        "rmse_train = np.sqrt(mean_squared_error(y_train, y_pred))\n",
        "mae_train = mean_absolute_error(y_train, y_pred)\n",
        "r2_adjusted_train = 1 - (1-r2_score(y_train, y_pred))*(len(y_train)-1)/(len(y_train)-X_train.shape[1]-1)\n",
        "sd_train = std(y_train)\n",
        "\n",
        "print(\"R^2 train: {}\".format(r2_train))\n",
        "print(\"R^2 adjusted train: {}\".format(r2_adjusted_train))\n",
        "print(\"Mean Absolute Error train: {}\".format(mae_train))\n",
        "print(\"Root Mean Squared Error train: {}\".format(rmse_train)) \n",
        "print(\"Standard Deviation train: {}\".format(sd_train))  \n",
        "\n",
        "# Compute test scores\n",
        "\n",
        "y_pred = regXGB.predict(X_test)\n",
        "\n",
        "r2_test = r2_score(y_test, y_pred)\n",
        "rmse_test = np.sqrt(mean_squared_error(y_test, y_pred))\n",
        "mae_test = mean_absolute_error(y_test, y_pred)\n",
        "r2_adjusted_test = 1 - (1-r2_score(y_test, y_pred))*(len(y_test)-1)/(len(y_test)-X_test.shape[1]-1)\n",
        "sd_test = std(y_test)\n",
        "\n",
        "print(\"R^2 test: {}\".format(r2_test))\n",
        "print(\"R^2 adjusted test: {}\".format(r2_adjusted_test))\n",
        "print(\"Mean Absolute Error test: {}\".format(mae_test))\n",
        "print(\"Root Mean Squared Error test: {}\".format(rmse_test))\n",
        "print(\"Standard Deviation test: {}\".format(sd_test)) "
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "R^2 train: 0.6787248499472722\n",
            "R^2 adjusted train: 0.6785384377837727\n",
            "Mean Absolute Error train: 6.350930068143664\n",
            "Root Mean Squared Error train: 8.790844641943044\n",
            "Standard Deviation train: NO2_0    15.509294\n",
            "dtype: float64\n",
            "R^2 test: 0.5955976751835792\n",
            "R^2 adjusted test: 0.5946449447183293\n",
            "Mean Absolute Error test: 8.101517691879275\n",
            "Root Mean Squared Error test: 11.736664446889112\n",
            "Standard Deviation test: NO2_0    18.456012\n",
            "dtype: float64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Y2vi0PWVw4Iw",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 6 hours ahead"
      ]
    },
    {
      "metadata": {
        "id": "XwRFqznHw4Qt",
        "colab_type": "code",
        "outputId": "4bee45bc-ac02-4f96-df63-52bea95ff782",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "cell_type": "code",
      "source": [
        "X_train = pyreadr.read_r(\"X_train_NO2_201401_201612_multivar.rds\")\n",
        "y_train = pyreadr.read_r(\"y_train_NO2_201401_201612_multivar.rds\")\n",
        "\n",
        "X_test = pyreadr.read_r(\"X_test_NO2_201701_201709_multivar.rds\")\n",
        "y_test = pyreadr.read_r(\"y_test_NO2_201701_201709_multivar.rds\")\n",
        "\n",
        "X_train = X_train[None]\n",
        "y_train = y_train[None]\n",
        "X_test = X_test[None]\n",
        "y_test = y_test[None]\n",
        "\n",
        "\n",
        "X_train = X_train[['NO2_6', 'NO2_7', 'NO2_10', 'NO2_11', 'NO2_22', 'NO2_23', 'NO2_24',\n",
        "                   'NO2_25', 'NO2_26', 'NO2_27','NO2_48', 'NO2_72', 'NO2_96', 'NO2_120', 'NO2_144', 'NO2_168']]\n",
        "\n",
        "X_test = X_test[['NO2_6', 'NO2_7', 'NO2_10', 'NO2_11', 'NO2_22', 'NO2_23', 'NO2_24',\n",
        "                   'NO2_25', 'NO2_26', 'NO2_27','NO2_48', 'NO2_72', 'NO2_96', 'NO2_120', 'NO2_144', 'NO2_168']]\n",
        "\n",
        "\n",
        "\n",
        "regXGB = XGBRegressor(n_estimators=100, min_samples_leaf=10,max_depth=2, random_state=42)\n",
        "regXGB.fit(X_train,y_train)\n",
        "\n",
        "\n",
        "# Compute train scores\n",
        "\n",
        "y_pred = regXGB.predict(X_train)\n",
        "\n",
        "r2_train = r2_score(y_train, y_pred)\n",
        "rmse_train = np.sqrt(mean_squared_error(y_train, y_pred))\n",
        "mae_train = mean_absolute_error(y_train, y_pred)\n",
        "r2_adjusted_train = 1 - (1-r2_score(y_train, y_pred))*(len(y_train)-1)/(len(y_train)-X_train.shape[1]-1)\n",
        "sd_train = std(y_train)\n",
        "\n",
        "print(\"R^2 train: {}\".format(r2_train))\n",
        "print(\"R^2 adjusted train: {}\".format(r2_adjusted_train))\n",
        "print(\"Mean Absolute Error train: {}\".format(mae_train))\n",
        "print(\"Root Mean Squared Error train: {}\".format(rmse_train)) \n",
        "print(\"Standard Deviation train: {}\".format(sd_train))  \n",
        "\n",
        "# Compute test scores\n",
        "\n",
        "y_pred = regXGB.predict(X_test)\n",
        "\n",
        "r2_test = r2_score(y_test, y_pred)\n",
        "rmse_test = np.sqrt(mean_squared_error(y_test, y_pred))\n",
        "mae_test = mean_absolute_error(y_test, y_pred)\n",
        "r2_adjusted_test = 1 - (1-r2_score(y_test, y_pred))*(len(y_test)-1)/(len(y_test)-X_test.shape[1]-1)\n",
        "sd_test = std(y_test)\n",
        "\n",
        "print(\"R^2 test: {}\".format(r2_test))\n",
        "print(\"R^2 adjusted test: {}\".format(r2_adjusted_test))\n",
        "print(\"Mean Absolute Error test: {}\".format(mae_test))\n",
        "print(\"Root Mean Squared Error test: {}\".format(rmse_test))\n",
        "print(\"Standard Deviation test: {}\".format(sd_test)) \n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "R^2 train: 0.505434230269822\n",
            "R^2 adjusted train: 0.5051281279018021\n",
            "Mean Absolute Error train: 8.25219944389317\n",
            "Root Mean Squared Error train: 10.906968643481578\n",
            "Standard Deviation train: NO2_0    15.509294\n",
            "dtype: float64\n",
            "R^2 test: 0.3947446094575423\n",
            "R^2 adjusted test: 0.39322338950016256\n",
            "Mean Absolute Error test: 10.476092412226016\n",
            "Root Mean Squared Error test: 14.358438073405999\n",
            "Standard Deviation test: NO2_0    18.456012\n",
            "dtype: float64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "jiSo4-yPw4Xa",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 12 hours ahead"
      ]
    },
    {
      "metadata": {
        "id": "rdCcOD49w4dn",
        "colab_type": "code",
        "outputId": "04bd74d7-1692-4c12-c70a-c537a93b6f67",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "cell_type": "code",
      "source": [
        "X_train = pyreadr.read_r(\"X_train_NO2_201401_201612_multivar.rds\")\n",
        "y_train = pyreadr.read_r(\"y_train_NO2_201401_201612_multivar.rds\")\n",
        "\n",
        "X_test = pyreadr.read_r(\"X_test_NO2_201701_201709_multivar.rds\")\n",
        "y_test = pyreadr.read_r(\"y_test_NO2_201701_201709_multivar.rds\")\n",
        "\n",
        "X_train = X_train[None]\n",
        "y_train = y_train[None]\n",
        "X_test = X_test[None]\n",
        "y_test = y_test[None]\n",
        "\n",
        "\n",
        "X_train = X_train[['NO2_12', 'NO2_13','NO2_22', 'NO2_23', 'NO2_24',\n",
        "                   'NO2_25', 'NO2_26', 'NO2_27','NO2_48', 'NO2_72', 'NO2_96', 'NO2_120', 'NO2_144', 'NO2_168']]\n",
        "\n",
        "X_test = X_test[['NO2_12', 'NO2_13','NO2_22', 'NO2_23', 'NO2_24',\n",
        "                   'NO2_25', 'NO2_26', 'NO2_27','NO2_48', 'NO2_72', 'NO2_96', 'NO2_120', 'NO2_144', 'NO2_168']]\n",
        "\n",
        "\n",
        "X_train = pd.get_dummies(X_train)\n",
        "X_test  = pd.get_dummies(X_test)\n",
        "\n",
        "\n",
        "\n",
        "regXGB = XGBRegressor(n_estimators=100, min_samples_leaf=10,max_depth=2, random_state=42)\n",
        "regXGB.fit(X_train,y_train)\n",
        "\n",
        "\n",
        "# Compute train scores\n",
        "\n",
        "y_pred = regXGB.predict(X_train)\n",
        "\n",
        "r2_train = r2_score(y_train, y_pred)\n",
        "rmse_train = np.sqrt(mean_squared_error(y_train, y_pred))\n",
        "mae_train = mean_absolute_error(y_train, y_pred)\n",
        "r2_adjusted_train = 1 - (1-r2_score(y_train, y_pred))*(len(y_train)-1)/(len(y_train)-X_train.shape[1]-1)\n",
        "sd_train = std(y_train)\n",
        "\n",
        "print(\"R^2 train: {}\".format(r2_train))\n",
        "print(\"R^2 adjusted train: {}\".format(r2_adjusted_train))\n",
        "print(\"Mean Absolute Error train: {}\".format(mae_train))\n",
        "print(\"Root Mean Squared Error train: {}\".format(rmse_train)) \n",
        "print(\"Standard Deviation train: {}\".format(sd_train))  \n",
        "\n",
        "# Compute test scores\n",
        "\n",
        "y_pred = regXGB.predict(X_test)\n",
        "\n",
        "r2_test = r2_score(y_test, y_pred)\n",
        "rmse_test = np.sqrt(mean_squared_error(y_test, y_pred))\n",
        "mae_test = mean_absolute_error(y_test, y_pred)\n",
        "r2_adjusted_test = 1 - (1-r2_score(y_test, y_pred))*(len(y_test)-1)/(len(y_test)-X_test.shape[1]-1)\n",
        "sd_test = std(y_test)\n",
        "\n",
        "print(\"R^2 test: {}\".format(r2_test))\n",
        "print(\"R^2 adjusted test: {}\".format(r2_adjusted_test))\n",
        "print(\"Mean Absolute Error test: {}\".format(mae_test))\n",
        "print(\"Root Mean Squared Error test: {}\".format(rmse_test))\n",
        "print(\"Standard Deviation test: {}\".format(sd_test))  \n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "R^2 train: 0.48245294949412454\n",
            "R^2 adjusted train: 0.48217268574496264\n",
            "Mean Absolute Error train: 8.50924019304368\n",
            "Root Mean Squared Error train: 11.157501563151524\n",
            "Standard Deviation train: NO2_0    15.509294\n",
            "dtype: float64\n",
            "R^2 test: 0.37314522722893506\n",
            "R^2 adjusted test: 0.37176709173603384\n",
            "Mean Absolute Error test: 10.677783072908605\n",
            "Root Mean Squared Error test: 14.612392690820352\n",
            "Standard Deviation test: NO2_0    18.456012\n",
            "dtype: float64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "LhZDCp6WxULE",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 24 hours ahead"
      ]
    },
    {
      "metadata": {
        "id": "HyiGnHHNxUcn",
        "colab_type": "code",
        "outputId": "50ea4339-1f7d-4f0c-9756-3df0911b58b2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "cell_type": "code",
      "source": [
        "X_train = pyreadr.read_r(\"X_train_NO2_201401_201612_multivar.rds\")\n",
        "y_train = pyreadr.read_r(\"y_train_NO2_201401_201612_multivar.rds\")\n",
        "\n",
        "X_test = pyreadr.read_r(\"X_test_NO2_201701_201709_multivar.rds\")\n",
        "y_test = pyreadr.read_r(\"y_test_NO2_201701_201709_multivar.rds\")\n",
        "\n",
        "X_train = X_train[None]\n",
        "y_train = y_train[None]\n",
        "X_test = X_test[None]\n",
        "y_test = y_test[None]\n",
        "\n",
        "\n",
        "X_train = X_train[[ 'NO2_24','NO2_25', 'NO2_26', 'NO2_27','NO2_48', 'NO2_72', 'NO2_96', 'NO2_120', 'NO2_144', 'NO2_168']]\n",
        "\n",
        "X_test = X_test[['NO2_24', 'NO2_25', 'NO2_26', 'NO2_27','NO2_48', 'NO2_72', 'NO2_96', 'NO2_120', 'NO2_144', 'NO2_168']]\n",
        "\n",
        "\n",
        "\n",
        "regXGB = XGBRegressor(n_estimators=500, min_samples_leaf=10,max_depth=2, random_state=42)\n",
        "regXGB.fit(X_train,y_train)\n",
        "\n",
        "\n",
        "# Compute train scores\n",
        "\n",
        "y_pred = regXGB.predict(X_train)\n",
        "\n",
        "r2_train = r2_score(y_train, y_pred)\n",
        "rmse_train = np.sqrt(mean_squared_error(y_train, y_pred))\n",
        "mae_train = mean_absolute_error(y_train, y_pred)\n",
        "r2_adjusted_train = 1 - (1-r2_score(y_train, y_pred))*(len(y_train)-1)/(len(y_train)-X_train.shape[1]-1)\n",
        "sd_train = std(y_train)\n",
        "\n",
        "print(\"R^2 train: {}\".format(r2_train))\n",
        "print(\"R^2 adjusted train: {}\".format(r2_adjusted_train))\n",
        "print(\"Mean Absolute Error train: {}\".format(mae_train))\n",
        "print(\"Root Mean Squared Error train: {}\".format(rmse_train)) \n",
        "print(\"Standard Deviation train: {}\".format(sd_train))  \n",
        "\n",
        "# Compute test scores\n",
        "\n",
        "y_pred = regXGB.predict(X_test)\n",
        "\n",
        "r2_test = r2_score(y_test, y_pred)\n",
        "rmse_test = np.sqrt(mean_squared_error(y_test, y_pred))\n",
        "mae_test = mean_absolute_error(y_test, y_pred)\n",
        "r2_adjusted_test = 1 - (1-r2_score(y_test, y_pred))*(len(y_test)-1)/(len(y_test)-X_test.shape[1]-1)\n",
        "sd_test = std(y_test)\n",
        "\n",
        "print(\"R^2 test: {}\".format(r2_test))\n",
        "print(\"R^2 adjusted test: {}\".format(r2_adjusted_test))\n",
        "print(\"Mean Absolute Error test: {}\".format(mae_test))\n",
        "print(\"Root Mean Squared Error test: {}\".format(rmse_test))\n",
        "print(\"Standard Deviation test: {}\".format(sd_test))  \n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "R^2 train: 0.48563518522341775\n",
            "R^2 adjusted train: 0.48543625850540073\n",
            "Mean Absolute Error train: 8.527055341972911\n",
            "Root Mean Squared Error train: 11.123146670143798\n",
            "Standard Deviation train: NO2_0    15.509294\n",
            "dtype: float64\n",
            "R^2 test: 0.32238873999820905\n",
            "R^2 adjusted test: 0.3213253199417091\n",
            "Mean Absolute Error test: 11.08488724252079\n",
            "Root Mean Squared Error test: 15.192462515751007\n",
            "Standard Deviation test: NO2_0    18.456012\n",
            "dtype: float64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "u-TSqvXqhSu2",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### I add the rest of variables"
      ]
    },
    {
      "metadata": {
        "id": "UpeBxoWzhS8k",
        "colab_type": "code",
        "outputId": "d5b74f1c-1126-442e-d12c-3025b6afc232",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "cell_type": "code",
      "source": [
        "X_train = pyreadr.read_r(\"X_train_NO2_201401_201612_multivar.rds\")\n",
        "y_train = pyreadr.read_r(\"y_train_NO2_201401_201612_multivar.rds\")\n",
        "\n",
        "X_test = pyreadr.read_r(\"X_test_NO2_201701_201709_multivar.rds\")\n",
        "y_test = pyreadr.read_r(\"y_test_NO2_201701_201709_multivar.rds\")\n",
        "\n",
        "X_train = X_train[None]\n",
        "y_train = y_train[None]\n",
        "X_test = X_test[None]\n",
        "y_test = y_test[None]\n",
        "\n",
        "# We convert the 'hour' variable to string\n",
        "X_train.hour = X_train.hour.astype(str)\n",
        "X_test.hour = X_test.hour.astype(str)\n",
        "\n",
        "# We convert the 'week_day' variable to string\n",
        "X_train.week_day = X_train.week_day.astype(str)\n",
        "X_test.week_day = X_test.week_day.astype(str)\n",
        "\n",
        "# We convert the 'month' variable to string\n",
        "X_train.month = X_train.month.astype(str)\n",
        "X_test.month = X_test.month.astype(str)\n",
        "\n",
        "X_train = X_train[['NO2_1', 'NO2_2', 'NO2_10', 'NO2_11', 'NO2_22', 'NO2_23', 'NO2_24',\n",
        "                   'NO2_25', 'NO2_26', 'NO2_27','NO2_48', 'NO2_72', 'NO2_96', 'NO2_120', 'NO2_144', 'NO2_168',\n",
        "                  'no_lab_days', 'hour','month', 'week_day','vv_1', 'wd_1', 'LL_1', 'LL_2', 'RS_1', 'RS_2', 'HR_1', 'HR_2', 'PRB_1', 'PRB_2', 'NO_1', 'NO_2']]\n",
        "\n",
        "X_test = X_test[['NO2_1', 'NO2_2', 'NO2_10', 'NO2_11', 'NO2_22', 'NO2_23', 'NO2_24',\n",
        "                   'NO2_25', 'NO2_26', 'NO2_27','NO2_48', 'NO2_72', 'NO2_96', 'NO2_120', 'NO2_144', 'NO2_168',\n",
        "                  'no_lab_days', 'hour','month', 'week_day','vv_1', 'wd_1', 'LL_1', 'LL_2', 'RS_1', 'RS_2', 'HR_1', 'HR_2', 'PRB_1', 'PRB_2', 'NO_1', 'NO_2']]\n",
        "\n",
        "\n",
        "X_train = pd.get_dummies(X_train)\n",
        "X_test  = pd.get_dummies(X_test)\n",
        "\n",
        "\n",
        "# The next code, which solves the problem of columns missmatching is from here https://stackoverflow.com/questions/52072821/how-to-predict-if-number-of-features-are-not-matching-with-number-of-features-av\n",
        "\n",
        "# Get missing columns in the training test\n",
        "missing_cols = set( X_train.columns ) - set( X_test.columns )\n",
        "# Add a missing column in test set with default value equal to 0\n",
        "for c in missing_cols:\n",
        "    X_test[c] = 0\n",
        "# Ensure the order of column in the test set is in the same order than in train set\n",
        "X_test = X_test[X_train.columns]\n",
        "# This code also ensure that column resulting from category in the test dataset but not present in the training dataset will be removed\n",
        "\n",
        "\n",
        "regXGB = XGBRegressor(n_estimators=100, min_samples_leaf=10,max_depth=2, random_state=42)\n",
        "regXGB.fit(X_train,y_train)\n",
        "\n",
        "\n",
        "# Compute train scores\n",
        "\n",
        "y_pred = regXGB.predict(X_train)\n",
        "\n",
        "r2_train = r2_score(y_train, y_pred)\n",
        "rmse_train = np.sqrt(mean_squared_error(y_train, y_pred))\n",
        "mae_train = mean_absolute_error(y_train, y_pred)\n",
        "r2_adjusted_train = 1 - (1-r2_score(y_train, y_pred))*(len(y_train)-1)/(len(y_train)-X_train.shape[1]-1)\n",
        "sd_train = std(y_train)\n",
        "\n",
        "print(\"R^2 train: {}\".format(r2_train))\n",
        "print(\"R^2 adjusted train: {}\".format(r2_adjusted_train))\n",
        "print(\"Mean Absolute Error train: {}\".format(mae_train))\n",
        "print(\"Root Mean Squared Error train: {}\".format(rmse_train)) \n",
        "print(\"Standard Deviation train: {}\".format(sd_train))  \n",
        "\n",
        "# Compute test scores\n",
        "\n",
        "y_pred = regXGB.predict(X_test)\n",
        "\n",
        "r2_test = r2_score(y_test, y_pred)\n",
        "rmse_test = np.sqrt(mean_squared_error(y_test, y_pred))\n",
        "mae_test = mean_absolute_error(y_test, y_pred)\n",
        "r2_adjusted_test = 1 - (1-r2_score(y_test, y_pred))*(len(y_test)-1)/(len(y_test)-X_test.shape[1]-1)\n",
        "sd_test = std(y_test)\n",
        "\n",
        "print(\"R^2 test: {}\".format(r2_test))\n",
        "print(\"R^2 adjusted test: {}\".format(r2_adjusted_test))\n",
        "print(\"Mean Absolute Error test: {}\".format(mae_test))\n",
        "print(\"Root Mean Squared Error test: {}\".format(rmse_test))\n",
        "print(\"Standard Deviation test: {}\".format(sd_test))  "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "R^2 train: 0.8281368982852535\n",
            "R^2 adjusted train: 0.8275502210304765\n",
            "Mean Absolute Error train: 4.482929764284935\n",
            "Root Mean Squared Error train: 6.42959118883823\n",
            "Standard Deviation train: NO2_0    15.509294\n",
            "dtype: float64\n",
            "R^2 test: 0.76681906718038\n",
            "R^2 adjusted test: 0.7635588317040332\n",
            "Mean Absolute Error test: 5.724267636207306\n",
            "Root Mean Squared Error test: 8.912188920157883\n",
            "Standard Deviation test: NO2_0    18.456012\n",
            "dtype: float64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "pBRprxjZ_o04",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### grid"
      ]
    },
    {
      "metadata": {
        "id": "Ko2iPms2l8Q0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "X_train = pyreadr.read_r(\"X_train_NO2_201401_201612_multivar.rds\")\n",
        "y_train = pyreadr.read_r(\"y_train_NO2_201401_201612_multivar.rds\")\n",
        "\n",
        "X_test = pyreadr.read_r(\"X_test_NO2_201701_201709_multivar.rds\")\n",
        "y_test = pyreadr.read_r(\"y_test_NO2_201701_201709_multivar.rds\")\n",
        "\n",
        "X_train = X_train[None]\n",
        "y_train = y_train[None]\n",
        "X_test = X_test[None]\n",
        "y_test = y_test[None]\n",
        "\n",
        "# We convert the 'hour' variable to string\n",
        "X_train.hour = X_train.hour.astype(str)\n",
        "X_test.hour = X_test.hour.astype(str)\n",
        "\n",
        "# We convert the 'week_day' variable to string\n",
        "X_train.week_day = X_train.week_day.astype(str)\n",
        "X_test.week_day = X_test.week_day.astype(str)\n",
        "\n",
        "# We convert the 'month' variable to string\n",
        "X_train.month = X_train.month.astype(str)\n",
        "X_test.month = X_test.month.astype(str)\n",
        "\n",
        "X_train = X_train[['NO2_1', 'NO2_2', 'NO2_10', 'NO2_11', 'NO2_22', 'NO2_23', 'NO2_24',\n",
        "                   'NO2_25', 'NO2_26', 'NO2_27','NO2_48', 'NO2_72', 'NO2_96', 'NO2_120', 'NO2_144', 'NO2_168',\n",
        "                  'no_lab_days', 'hour','month', 'week_day','vv_1', 'wd_1', 'LL_1', 'LL_2', 'RS_1', 'RS_2', 'HR_1', 'HR_2', 'PRB_1', 'PRB_2', 'NO_1', 'NO_2']]\n",
        "\n",
        "X_test = X_test[['NO2_1', 'NO2_2', 'NO2_10', 'NO2_11', 'NO2_22', 'NO2_23', 'NO2_24',\n",
        "                   'NO2_25', 'NO2_26', 'NO2_27','NO2_48', 'NO2_72', 'NO2_96', 'NO2_120', 'NO2_144', 'NO2_168',\n",
        "                  'no_lab_days', 'hour','month', 'week_day','vv_1', 'wd_1', 'LL_1', 'LL_2', 'RS_1', 'RS_2', 'HR_1', 'HR_2', 'PRB_1', 'PRB_2', 'NO_1', 'NO_2']]\n",
        "\n",
        "\n",
        "X_train = pd.get_dummies(X_train)\n",
        "X_test  = pd.get_dummies(X_test)\n",
        "\n",
        "\n",
        "# The next code, which solves the problem of columns missmatching is from here https://stackoverflow.com/questions/52072821/how-to-predict-if-number-of-features-are-not-matching-with-number-of-features-av\n",
        "\n",
        "# Get missing columns in the training test\n",
        "missing_cols = set( X_train.columns ) - set( X_test.columns )\n",
        "# Add a missing column in test set with default value equal to 0\n",
        "for c in missing_cols:\n",
        "    X_test[c] = 0\n",
        "# Ensure the order of column in the test set is in the same order than in train set\n",
        "X_test = X_test[X_train.columns]\n",
        "# This code also ensure that column resulting from category in the test dataset but not present in the training dataset will be removed\n",
        "\n",
        "\n",
        "regRFR = GridSearchCV(RandomForestRegressor(n_estimators=350,min_samples_leaf=1,max_depth=4, random_state=42),\n",
        "                   param_grid={\"n_estimators\":[100, 350, 500, 1000],\n",
        "                              \"min_samples_leaf\":[5,10,20,30,40,70,100],\n",
        "                              \"max_depth\":range(2,15)},\n",
        "                   scoring=\"neg_mean_absolute_error\")\n",
        "regRFR.fit(X_train,y_train.values.ravel())\n",
        "print(regRFR.best_params_)\n",
        "print(regRFR.best_score_)\n",
        "\n",
        "\n",
        "\n",
        "# Compute train scores\n",
        "\n",
        "y_pred = regXGB.predict(X_train)\n",
        "\n",
        "r2_train = r2_score(y_train, y_pred)\n",
        "rmse_train = np.sqrt(mean_squared_error(y_train, y_pred))\n",
        "mae_train = mean_absolute_error(y_train, y_pred)\n",
        "r2_adjusted_train = 1 - (1-r2_score(y_train, y_pred))*(len(y_train)-1)/(len(y_train)-X_train.shape[1]-1)\n",
        "sd_train = std(y_train)\n",
        "\n",
        "print(\"R^2 train: {}\".format(r2_train))\n",
        "print(\"R^2 adjusted train: {}\".format(r2_adjusted_train))\n",
        "print(\"Mean Absolute Error train: {}\".format(mae_train))\n",
        "print(\"Root Mean Squared Error train: {}\".format(rmse_train)) \n",
        "print(\"Standard Deviation train: {}\".format(sd_train))  \n",
        "\n",
        "# Compute test scores\n",
        "\n",
        "y_pred = regXGB.predict(X_test)\n",
        "\n",
        "r2_test = r2_score(y_test, y_pred)\n",
        "rmse_test = np.sqrt(mean_squared_error(y_test, y_pred))\n",
        "mae_test = mean_absolute_error(y_test, y_pred)\n",
        "r2_adjusted_test = 1 - (1-r2_score(y_test, y_pred))*(len(y_test)-1)/(len(y_test)-X_test.shape[1]-1)\n",
        "sd_test = std(y_test)\n",
        "\n",
        "print(\"R^2 test: {}\".format(r2_test))\n",
        "print(\"R^2 adjusted test: {}\".format(r2_adjusted_test))\n",
        "print(\"Mean Absolute Error test: {}\".format(mae_test))\n",
        "print(\"Root Mean Squared Error test: {}\".format(rmse_test))\n",
        "print(\"Standard Deviation test: {}\".format(sd_test))  \n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "outputId": "b5348de0-db42-4c17-c2f8-edcbc97ab337",
        "id": "B_eG3xeemAD4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "cell_type": "code",
      "source": [
        "X_train = pyreadr.read_r(\"X_train_NO2_201401_201612_multivar.rds\")\n",
        "y_train = pyreadr.read_r(\"y_train_NO2_201401_201612_multivar.rds\")\n",
        "\n",
        "X_test = pyreadr.read_r(\"X_test_NO2_201701_201709_multivar.rds\")\n",
        "y_test = pyreadr.read_r(\"y_test_NO2_201701_201709_multivar.rds\")\n",
        "\n",
        "X_train = X_train[None]\n",
        "y_train = y_train[None]\n",
        "X_test = X_test[None]\n",
        "y_test = y_test[None]\n",
        "\n",
        "# We convert the 'hour' variable to string\n",
        "X_train.hour = X_train.hour.astype(str)\n",
        "X_test.hour = X_test.hour.astype(str)\n",
        "\n",
        "# We convert the 'week_day' variable to string\n",
        "X_train.week_day = X_train.week_day.astype(str)\n",
        "X_test.week_day = X_test.week_day.astype(str)\n",
        "\n",
        "# We convert the 'month' variable to string\n",
        "X_train.month = X_train.month.astype(str)\n",
        "X_test.month = X_test.month.astype(str)\n",
        "\n",
        "X_train = X_train[['NO2_1', 'NO2_2', 'NO2_10', 'NO2_11', 'NO2_22', 'NO2_23', 'NO2_24',\n",
        "                   'NO2_25', 'NO2_26', 'NO2_27','NO2_48', 'NO2_72', 'NO2_96', 'NO2_120', 'NO2_144', 'NO2_168',\n",
        "                  'no_lab_days', 'hour','month', 'week_day','vv_1', 'wd_1', 'LL_1', 'LL_2', 'RS_1', 'RS_2', 'HR_1', 'HR_2', 'PRB_1', 'PRB_2', 'NO_1', 'NO_2']]\n",
        "\n",
        "X_test = X_test[['NO2_1', 'NO2_2', 'NO2_10', 'NO2_11', 'NO2_22', 'NO2_23', 'NO2_24',\n",
        "                   'NO2_25', 'NO2_26', 'NO2_27','NO2_48', 'NO2_72', 'NO2_96', 'NO2_120', 'NO2_144', 'NO2_168',\n",
        "                  'no_lab_days', 'hour','month', 'week_day','vv_1', 'wd_1', 'LL_1', 'LL_2', 'RS_1', 'RS_2', 'HR_1', 'HR_2', 'PRB_1', 'PRB_2', 'NO_1', 'NO_2']]\n",
        "\n",
        "\n",
        "X_train = pd.get_dummies(X_train)\n",
        "X_test  = pd.get_dummies(X_test)\n",
        "\n",
        "\n",
        "# The next code, which solves the problem of columns missmatching is from here https://stackoverflow.com/questions/52072821/how-to-predict-if-number-of-features-are-not-matching-with-number-of-features-av\n",
        "\n",
        "# Get missing columns in the training test\n",
        "missing_cols = set( X_train.columns ) - set( X_test.columns )\n",
        "# Add a missing column in test set with default value equal to 0\n",
        "for c in missing_cols:\n",
        "    X_test[c] = 0\n",
        "# Ensure the order of column in the test set is in the same order than in train set\n",
        "X_test = X_test[X_train.columns]\n",
        "# This code also ensure that column resulting from category in the test dataset but not present in the training dataset will be removed\n",
        "\n",
        "\n",
        "regXGB = XGBRegressor(n_estimators=100, min_samples_leaf=10,max_depth=2, random_state=42)\n",
        "regXGB.fit(X_train,y_train)\n",
        "\n",
        "\n",
        "# Compute train scores\n",
        "\n",
        "y_pred = regXGB.predict(X_train)\n",
        "\n",
        "r2_train = r2_score(y_train, y_pred)\n",
        "rmse_train = np.sqrt(mean_squared_error(y_train, y_pred))\n",
        "mae_train = mean_absolute_error(y_train, y_pred)\n",
        "r2_adjusted_train = 1 - (1-r2_score(y_train, y_pred))*(len(y_train)-1)/(len(y_train)-X_train.shape[1]-1)\n",
        "sd_train = std(y_train)\n",
        "\n",
        "print(\"R^2 train: {}\".format(r2_train))\n",
        "print(\"R^2 adjusted train: {}\".format(r2_adjusted_train))\n",
        "print(\"Mean Absolute Error train: {}\".format(mae_train))\n",
        "print(\"Root Mean Squared Error train: {}\".format(rmse_train)) \n",
        "print(\"Standard Deviation train: {}\".format(sd_train))  \n",
        "\n",
        "# Compute test scores\n",
        "\n",
        "y_pred = regXGB.predict(X_test)\n",
        "\n",
        "r2_test = r2_score(y_test, y_pred)\n",
        "rmse_test = np.sqrt(mean_squared_error(y_test, y_pred))\n",
        "mae_test = mean_absolute_error(y_test, y_pred)\n",
        "r2_adjusted_test = 1 - (1-r2_score(y_test, y_pred))*(len(y_test)-1)/(len(y_test)-X_test.shape[1]-1)\n",
        "sd_test = std(y_test)\n",
        "\n",
        "print(\"R^2 test: {}\".format(r2_test))\n",
        "print(\"R^2 adjusted test: {}\".format(r2_adjusted_test))\n",
        "print(\"Mean Absolute Error test: {}\".format(mae_test))\n",
        "print(\"Root Mean Squared Error test: {}\".format(rmse_test))\n",
        "print(\"Standard Deviation test: {}\".format(sd_test))  "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "R^2 train: 0.8281368982852535\n",
            "R^2 adjusted train: 0.8275502210304765\n",
            "Mean Absolute Error train: 4.482929764284935\n",
            "Root Mean Squared Error train: 6.42959118883823\n",
            "Standard Deviation train: NO2_0    15.509294\n",
            "dtype: float64\n",
            "R^2 test: 0.76681906718038\n",
            "R^2 adjusted test: 0.7635588317040332\n",
            "Mean Absolute Error test: 5.724267636207306\n",
            "Root Mean Squared Error test: 8.912188920157883\n",
            "Standard Deviation test: NO2_0    18.456012\n",
            "dtype: float64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "eDauVJKo4JfJ"
      },
      "cell_type": "markdown",
      "source": [
        "# NO2 forecasts 2 hours ahead\n"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "outputId": "d964d76b-1935-458b-8fce-347f73583bed",
        "id": "RLME_PlZ4JfK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "cell_type": "code",
      "source": [
        "X_train = pyreadr.read_r(\"X_train_NO2_201401_201612_multivar.rds\")\n",
        "y_train = pyreadr.read_r(\"y_train_NO2_201401_201612_multivar.rds\")\n",
        "\n",
        "X_test = pyreadr.read_r(\"X_test_NO2_201701_201709_multivar.rds\")\n",
        "y_test = pyreadr.read_r(\"y_test_NO2_201701_201709_multivar.rds\")\n",
        "\n",
        "X_train = X_train[None]\n",
        "y_train = y_train[None]\n",
        "X_test = X_test[None]\n",
        "y_test = y_test[None]\n",
        "\n",
        "# We convert the 'hour' variable to string\n",
        "X_train.hour = X_train.hour.astype(str)\n",
        "X_test.hour = X_test.hour.astype(str)\n",
        "\n",
        "# We convert the 'week_day' variable to string\n",
        "X_train.week_day = X_train.week_day.astype(str)\n",
        "X_test.week_day = X_test.week_day.astype(str)\n",
        "\n",
        "# We convert the 'month' variable to string\n",
        "X_train.month = X_train.month.astype(str)\n",
        "X_test.month = X_test.month.astype(str)\n",
        "\n",
        "X_train = X_train[[ 'NO2_2', 'NO2_10', 'NO2_11', 'NO2_22', 'NO2_23', 'NO2_24',\n",
        "                   'NO2_25', 'NO2_26', 'NO2_27','NO2_48', 'NO2_72', 'NO2_96', 'NO2_120', 'NO2_144', 'NO2_168',\n",
        "                  'no_lab_days', 'hour','month', 'week_day', 'wd_2', 'LL_2', 'RS_2', 'HR_2', 'PRB_2', 'NO_2']]\n",
        "\n",
        "X_test = X_test[['NO2_2', 'NO2_10', 'NO2_11', 'NO2_22', 'NO2_23', 'NO2_24',\n",
        "                   'NO2_25', 'NO2_26', 'NO2_27','NO2_48', 'NO2_72', 'NO2_96', 'NO2_120', 'NO2_144', 'NO2_168',\n",
        "                  'no_lab_days', 'hour','month', 'week_day', 'wd_2', 'LL_2', 'RS_2', 'HR_2', 'PRB_2', 'NO_2']]\n",
        "\n",
        "X_train = pd.get_dummies(X_train)\n",
        "X_test  = pd.get_dummies(X_test)\n",
        "\n",
        "\n",
        "# The next code, which solves the problem of columns missmatching is from here https://stackoverflow.com/questions/52072821/how-to-predict-if-number-of-features-are-not-matching-with-number-of-features-av\n",
        "\n",
        "# Get missing columns in the training test\n",
        "missing_cols = set( X_train.columns ) - set( X_test.columns )\n",
        "# Add a missing column in test set with default value equal to 0\n",
        "for c in missing_cols:\n",
        "    X_test[c] = 0\n",
        "# Ensure the order of column in the test set is in the same order than in train set\n",
        "X_test = X_test[X_train.columns]\n",
        "# This code also ensure that column resulting from category in the test dataset but not present in the training dataset will be removed\n",
        "\n",
        "\n",
        "regXGB = XGBRegressor(n_estimators=100, min_samples_leaf=10,max_depth=2, random_state=42)\n",
        "regXGB.fit(X_train,y_train)\n",
        "\n",
        "\n",
        "# Compute train scores\n",
        "\n",
        "y_pred = regXGB.predict(X_train)\n",
        "\n",
        "r2_train = r2_score(y_train, y_pred)\n",
        "rmse_train = np.sqrt(mean_squared_error(y_train, y_pred))\n",
        "mae_train = mean_absolute_error(y_train, y_pred)\n",
        "r2_adjusted_train = 1 - (1-r2_score(y_train, y_pred))*(len(y_train)-1)/(len(y_train)-X_train.shape[1]-1)\n",
        "sd_train = std(y_train)\n",
        "\n",
        "print(\"R^2 train: {}\".format(r2_train))\n",
        "print(\"R^2 adjusted train: {}\".format(r2_adjusted_train))\n",
        "print(\"Mean Absolute Error train: {}\".format(mae_train))\n",
        "print(\"Root Mean Squared Error train: {}\".format(rmse_train)) \n",
        "print(\"Standard Deviation train: {}\".format(sd_train))  \n",
        "\n",
        "# Compute test scores\n",
        "\n",
        "y_pred = regXGB.predict(X_test)\n",
        "\n",
        "r2_test = r2_score(y_test, y_pred)\n",
        "rmse_test = np.sqrt(mean_squared_error(y_test, y_pred))\n",
        "mae_test = mean_absolute_error(y_test, y_pred)\n",
        "r2_adjusted_test = 1 - (1-r2_score(y_test, y_pred))*(len(y_test)-1)/(len(y_test)-X_test.shape[1]-1)\n",
        "sd_test = std(y_test)\n",
        "\n",
        "print(\"R^2 test: {}\".format(r2_test))\n",
        "print(\"R^2 adjusted test: {}\".format(r2_adjusted_test))\n",
        "print(\"Mean Absolute Error test: {}\".format(mae_test))\n",
        "print(\"Root Mean Squared Error test: {}\".format(rmse_test))\n",
        "print(\"Standard Deviation test: {}\".format(sd_test)) \n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "R^2 train: 0.6965437725030348\n",
            "R^2 adjusted train: 0.6955905438352594\n",
            "Mean Absolute Error train: 6.147501952031749\n",
            "Root Mean Squared Error train: 8.543583427500705\n",
            "Standard Deviation train: NO2_0    15.509294\n",
            "dtype: float64\n",
            "R^2 test: 0.6113603451702769\n",
            "R^2 adjusted test: 0.6063643426244576\n",
            "Mean Absolute Error test: 7.867007822413982\n",
            "Root Mean Squared Error test: 11.505656982615232\n",
            "Standard Deviation test: NO2_0    18.456012\n",
            "dtype: float64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "BGcFlBxqAhIb",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        ""
      ]
    },
    {
      "metadata": {
        "id": "Ht2DvjhDAHzd",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# NO2 forecasts 6 hours ahead"
      ]
    },
    {
      "metadata": {
        "id": "mCef-K8-mL8b",
        "colab_type": "code",
        "outputId": "de778d9f-f313-4269-d87f-fba98922608f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "cell_type": "code",
      "source": [
        "X_train = pyreadr.read_r(\"X_train_NO2_201401_201612_multivar.rds\")\n",
        "y_train = pyreadr.read_r(\"y_train_NO2_201401_201612_multivar.rds\")\n",
        "\n",
        "X_test = pyreadr.read_r(\"X_test_NO2_201701_201709_multivar.rds\")\n",
        "y_test = pyreadr.read_r(\"y_test_NO2_201701_201709_multivar.rds\")\n",
        "\n",
        "X_train = X_train[None]\n",
        "y_train = y_train[None]\n",
        "X_test = X_test[None]\n",
        "y_test = y_test[None]\n",
        "\n",
        "# We convert the 'hour' variable to string\n",
        "X_train.hour = X_train.hour.astype(str)\n",
        "X_test.hour = X_test.hour.astype(str)\n",
        "\n",
        "# We convert the 'week_day' variable to string\n",
        "X_train.week_day = X_train.week_day.astype(str)\n",
        "X_test.week_day = X_test.week_day.astype(str)\n",
        "\n",
        "# We convert the 'month' variable to string\n",
        "X_train.month = X_train.month.astype(str)\n",
        "X_test.month = X_test.month.astype(str)\n",
        "\n",
        "X_train = X_train[['NO2_6', 'NO2_7', 'NO2_10', 'NO2_11', 'NO2_22', 'NO2_23', 'NO2_24',\n",
        "                   'NO2_25', 'NO2_26', 'NO2_27','NO2_48', 'NO2_72', 'NO2_96', 'NO2_120', 'NO2_144', 'NO2_168',\n",
        "                  'no_lab_days', 'hour','month', 'week_day']]\n",
        "\n",
        "X_test = X_test[['NO2_6', 'NO2_7', 'NO2_10', 'NO2_11', 'NO2_22', 'NO2_23', 'NO2_24',\n",
        "                   'NO2_25', 'NO2_26', 'NO2_27','NO2_48', 'NO2_72', 'NO2_96', 'NO2_120', 'NO2_144', 'NO2_168',\n",
        "                  'no_lab_days', 'hour','month', 'week_day']]\n",
        "\n",
        "\n",
        "X_train = pd.get_dummies(X_train)\n",
        "X_test  = pd.get_dummies(X_test)\n",
        "\n",
        "\n",
        "# The next code, which solves the problem of columns missmatching is from here https://stackoverflow.com/questions/52072821/how-to-predict-if-number-of-features-are-not-matching-with-number-of-features-av\n",
        "\n",
        "# Get missing columns in the training test\n",
        "missing_cols = set( X_train.columns ) - set( X_test.columns )\n",
        "# Add a missing column in test set with default value equal to 0\n",
        "for c in missing_cols:\n",
        "    X_test[c] = 0\n",
        "# Ensure the order of column in the test set is in the same order than in train set\n",
        "X_test = X_test[X_train.columns]\n",
        "# This code also ensure that column resulting from category in the test dataset but not present in the training dataset will be removed\n",
        "\n",
        "\n",
        "regXGB = XGBRegressor(n_estimators=100, min_samples_leaf=10,max_depth=2, random_state=42)\n",
        "regXGB.fit(X_train,y_train)\n",
        "\n",
        "\n",
        "# Compute train scores\n",
        "\n",
        "y_pred = regXGB.predict(X_train)\n",
        "\n",
        "r2_train = r2_score(y_train, y_pred)\n",
        "rmse_train = np.sqrt(mean_squared_error(y_train, y_pred))\n",
        "mae_train = mean_absolute_error(y_train, y_pred)\n",
        "r2_adjusted_train = 1 - (1-r2_score(y_train, y_pred))*(len(y_train)-1)/(len(y_train)-X_train.shape[1]-1)\n",
        "sd_train = std(y_train)\n",
        "\n",
        "print(\"R^2 train: {}\".format(r2_train))\n",
        "print(\"R^2 adjusted train: {}\".format(r2_adjusted_train))\n",
        "print(\"Mean Absolute Error train: {}\".format(mae_train))\n",
        "print(\"Root Mean Squared Error train: {}\".format(rmse_train)) \n",
        "print(\"Standard Deviation train: {}\".format(sd_train))  \n",
        "\n",
        "# Compute test scores\n",
        "\n",
        "y_pred = regXGB.predict(X_test)\n",
        "\n",
        "r2_test = r2_score(y_test, y_pred)\n",
        "rmse_test = np.sqrt(mean_squared_error(y_test, y_pred))\n",
        "mae_test = mean_absolute_error(y_test, y_pred)\n",
        "r2_adjusted_test = 1 - (1-r2_score(y_test, y_pred))*(len(y_test)-1)/(len(y_test)-X_test.shape[1]-1)\n",
        "sd_test = std(y_test)\n",
        "\n",
        "print(\"R^2 test: {}\".format(r2_test))\n",
        "print(\"R^2 adjusted test: {}\".format(r2_adjusted_test))\n",
        "print(\"Mean Absolute Error test: {}\".format(mae_test))\n",
        "print(\"Root Mean Squared Error test: {}\".format(rmse_test))\n",
        "print(\"Standard Deviation test: {}\".format(sd_test)) \n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "R^2 train: 0.5362032971606577\n",
            "R^2 adjusted train: 0.535106978518745\n",
            "Mean Absolute Error train: 7.938518851557161\n",
            "Root Mean Squared Error train: 10.562235971415772\n",
            "Standard Deviation train: NO2_0    15.509294\n",
            "dtype: float64\n",
            "R^2 test: 0.4230134972332297\n",
            "R^2 adjusted test: 0.41744536297143997\n",
            "Mean Absolute Error test: 10.162366484658447\n",
            "Root Mean Squared Error test: 14.019118069751247\n",
            "Standard Deviation test: NO2_0    18.456012\n",
            "dtype: float64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "zF9wio5RBWQ2"
      },
      "cell_type": "markdown",
      "source": [
        "# NO2 forecasts 12 hours ahead"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "outputId": "54abde34-4dd7-4bc1-d979-8dd9a6f78740",
        "id": "mLQaa1ynBWQ3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "cell_type": "code",
      "source": [
        "X_train = pyreadr.read_r(\"X_train_NO2_201401_201612_multivar.rds\")\n",
        "y_train = pyreadr.read_r(\"y_train_NO2_201401_201612_multivar.rds\")\n",
        "\n",
        "X_test = pyreadr.read_r(\"X_test_NO2_201701_201709_multivar.rds\")\n",
        "y_test = pyreadr.read_r(\"y_test_NO2_201701_201709_multivar.rds\")\n",
        "\n",
        "X_train = X_train[None]\n",
        "y_train = y_train[None]\n",
        "X_test = X_test[None]\n",
        "y_test = y_test[None]\n",
        "\n",
        "# We convert the 'hour' variable to string\n",
        "X_train.hour = X_train.hour.astype(str)\n",
        "X_test.hour = X_test.hour.astype(str)\n",
        "\n",
        "# We convert the 'week_day' variable to string\n",
        "X_train.week_day = X_train.week_day.astype(str)\n",
        "X_test.week_day = X_test.week_day.astype(str)\n",
        "\n",
        "# We convert the 'month' variable to string\n",
        "X_train.month = X_train.month.astype(str)\n",
        "X_test.month = X_test.month.astype(str)\n",
        "\n",
        "X_train = X_train[['NO2_12', 'NO2_13','NO2_22', 'NO2_23', 'NO2_24',\n",
        "                   'NO2_25', 'NO2_26', 'NO2_27','NO2_48', 'NO2_72', 'NO2_96', 'NO2_120', 'NO2_144', 'NO2_168',\n",
        "                  'no_lab_days', 'hour','month', 'week_day']]\n",
        "\n",
        "X_test = X_test[['NO2_12', 'NO2_13','NO2_22', 'NO2_23', 'NO2_24',\n",
        "                   'NO2_25', 'NO2_26', 'NO2_27','NO2_48', 'NO2_72', 'NO2_96', 'NO2_120', 'NO2_144', 'NO2_168',\n",
        "                  'no_lab_days', 'hour','month', 'week_day']]\n",
        "\n",
        "\n",
        "\n",
        "X_train = pd.get_dummies(X_train)\n",
        "X_test  = pd.get_dummies(X_test)\n",
        "\n",
        "\n",
        "# The next code, which solves the problem of columns missmatching is from here https://stackoverflow.com/questions/52072821/how-to-predict-if-number-of-features-are-not-matching-with-number-of-features-av\n",
        "\n",
        "# Get missing columns in the training test\n",
        "missing_cols = set( X_train.columns ) - set( X_test.columns )\n",
        "# Add a missing column in test set with default value equal to 0\n",
        "for c in missing_cols:\n",
        "    X_test[c] = 0\n",
        "# Ensure the order of column in the test set is in the same order than in train set\n",
        "X_test = X_test[X_train.columns]\n",
        "# This code also ensure that column resulting from category in the test dataset but not present in the training dataset will be removed\n",
        "\n",
        "\n",
        "\n",
        "regXGB = XGBRegressor(n_estimators=500, min_samples_leaf=10,max_depth=2, random_state=42)\n",
        "regXGB.fit(X_train,y_train)\n",
        "\n",
        "\n",
        "# Compute train scores\n",
        "\n",
        "y_pred = regXGB.predict(X_train)\n",
        "\n",
        "r2_train = r2_score(y_train, y_pred)\n",
        "rmse_train = np.sqrt(mean_squared_error(y_train, y_pred))\n",
        "mae_train = mean_absolute_error(y_train, y_pred)\n",
        "r2_adjusted_train = 1 - (1-r2_score(y_train, y_pred))*(len(y_train)-1)/(len(y_train)-X_train.shape[1]-1)\n",
        "sd_train = std(y_train)\n",
        "\n",
        "print(\"R^2 train: {}\".format(r2_train))\n",
        "print(\"R^2 adjusted train: {}\".format(r2_adjusted_train))\n",
        "print(\"Mean Absolute Error train: {}\".format(mae_train))\n",
        "print(\"Root Mean Squared Error train: {}\".format(rmse_train)) \n",
        "print(\"Standard Deviation train: {}\".format(sd_train))  \n",
        "\n",
        "# Compute test scores\n",
        "\n",
        "y_pred = regXGB.predict(X_test)\n",
        "\n",
        "r2_test = r2_score(y_test, y_pred)\n",
        "rmse_test = np.sqrt(mean_squared_error(y_test, y_pred))\n",
        "mae_test = mean_absolute_error(y_test, y_pred)\n",
        "r2_adjusted_test = 1 - (1-r2_score(y_test, y_pred))*(len(y_test)-1)/(len(y_test)-X_test.shape[1]-1)\n",
        "sd_test = std(y_test)\n",
        "\n",
        "print(\"R^2 test: {}\".format(r2_test))\n",
        "print(\"R^2 adjusted test: {}\".format(r2_adjusted_test))\n",
        "print(\"Mean Absolute Error test: {}\".format(mae_test))\n",
        "print(\"Root Mean Squared Error test: {}\".format(rmse_test))\n",
        "print(\"Standard Deviation test: {}\".format(sd_test))  \n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "R^2 train: 0.5569001723831173\n",
            "R^2 adjusted train: 0.5558871961808003\n",
            "Mean Absolute Error train: 7.809096928173695\n",
            "Root Mean Squared Error train: 10.323877149442207\n",
            "Standard Deviation train: NO2_0    15.509294\n",
            "dtype: float64\n",
            "R^2 test: 0.4129202206779562\n",
            "R^2 adjusted test: 0.40744217117930037\n",
            "Mean Absolute Error test: 10.236640899401651\n",
            "Root Mean Squared Error test: 14.141205307604745\n",
            "Standard Deviation test: NO2_0    18.456012\n",
            "dtype: float64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "WEwgalJwB2lw"
      },
      "cell_type": "markdown",
      "source": [
        "# NO2 forecasts 24 hours ahead"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "outputId": "2bbe0033-e8ae-4dbf-c25b-09a509e53098",
        "id": "ThpX0n9dB2lx",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "cell_type": "code",
      "source": [
        "X_train = pyreadr.read_r(\"X_train_NO2_201401_201612_multivar.rds\")\n",
        "y_train = pyreadr.read_r(\"y_train_NO2_201401_201612_multivar.rds\")\n",
        "\n",
        "X_test = pyreadr.read_r(\"X_test_NO2_201701_201709_multivar.rds\")\n",
        "y_test = pyreadr.read_r(\"y_test_NO2_201701_201709_multivar.rds\")\n",
        "\n",
        "X_train = X_train[None]\n",
        "y_train = y_train[None]\n",
        "X_test = X_test[None]\n",
        "y_test = y_test[None]\n",
        "\n",
        "# We convert the 'hour' variable to string\n",
        "X_train.hour = X_train.hour.astype(str)\n",
        "X_test.hour = X_test.hour.astype(str)\n",
        "\n",
        "# We convert the 'week_day' variable to string\n",
        "X_train.week_day = X_train.week_day.astype(str)\n",
        "X_test.week_day = X_test.week_day.astype(str)\n",
        "\n",
        "# We convert the 'month' variable to string\n",
        "X_train.month = X_train.month.astype(str)\n",
        "X_test.month = X_test.month.astype(str)\n",
        "\n",
        "X_train = X_train[[ 'NO2_24','NO2_25', 'NO2_26', 'NO2_27','NO2_48', 'NO2_72', 'NO2_96', 'NO2_120', 'NO2_144', 'NO2_168',\n",
        "                  'no_lab_days', 'hour','month', 'week_day']]\n",
        "\n",
        "X_test = X_test[['NO2_24', 'NO2_25', 'NO2_26', 'NO2_27','NO2_48', 'NO2_72', 'NO2_96', 'NO2_120', 'NO2_144', 'NO2_168',\n",
        "                  'no_lab_days', 'hour','month', 'week_day']]\n",
        "\n",
        "\n",
        "\n",
        "X_train = pd.get_dummies(X_train)\n",
        "X_test  = pd.get_dummies(X_test)\n",
        "\n",
        "\n",
        "# The next code, which solves the problem of columns missmatching is from here https://stackoverflow.com/questions/52072821/how-to-predict-if-number-of-features-are-not-matching-with-number-of-features-av\n",
        "\n",
        "# Get missing columns in the training test\n",
        "missing_cols = set( X_train.columns ) - set( X_test.columns )\n",
        "# Add a missing column in test set with default value equal to 0\n",
        "for c in missing_cols:\n",
        "    X_test[c] = 0\n",
        "# Ensure the order of column in the test set is in the same order than in train set\n",
        "X_test = X_test[X_train.columns]\n",
        "# This code also ensure that column resulting from category in the test dataset but not present in the training dataset will be removed\n",
        "\n",
        "\n",
        "\n",
        "regXGB = XGBRegressor(n_estimators=500, min_samples_leaf=10,max_depth=2, random_state=42)\n",
        "regXGB.fit(X_train,y_train)\n",
        "\n",
        "\n",
        "# Compute train scores\n",
        "\n",
        "y_pred = regXGB.predict(X_train)\n",
        "\n",
        "r2_train = r2_score(y_train, y_pred)\n",
        "rmse_train = np.sqrt(mean_squared_error(y_train, y_pred))\n",
        "mae_train = mean_absolute_error(y_train, y_pred)\n",
        "r2_adjusted_train = 1 - (1-r2_score(y_train, y_pred))*(len(y_train)-1)/(len(y_train)-X_train.shape[1]-1)\n",
        "sd_train = std(y_train)\n",
        "\n",
        "print(\"R^2 train: {}\".format(r2_train))\n",
        "print(\"R^2 adjusted train: {}\".format(r2_adjusted_train))\n",
        "print(\"Mean Absolute Error train: {}\".format(mae_train))\n",
        "print(\"Root Mean Squared Error train: {}\".format(rmse_train)) \n",
        "print(\"Standard Deviation train: {}\".format(sd_train))  \n",
        "\n",
        "# Compute test scores\n",
        "\n",
        "y_pred = regXGB.predict(X_test)\n",
        "\n",
        "r2_test = r2_score(y_test, y_pred)\n",
        "rmse_test = np.sqrt(mean_squared_error(y_test, y_pred))\n",
        "mae_test = mean_absolute_error(y_test, y_pred)\n",
        "r2_adjusted_test = 1 - (1-r2_score(y_test, y_pred))*(len(y_test)-1)/(len(y_test)-X_test.shape[1]-1)\n",
        "sd_test = std(y_test)\n",
        "\n",
        "print(\"R^2 test: {}\".format(r2_test))\n",
        "print(\"R^2 adjusted test: {}\".format(r2_adjusted_test))\n",
        "print(\"Mean Absolute Error test: {}\".format(mae_test))\n",
        "print(\"Root Mean Squared Error test: {}\".format(rmse_test))\n",
        "print(\"Standard Deviation test: {}\".format(sd_test))  \n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "R^2 train: 0.540393368346495\n",
            "R^2 adjusted train: 0.5394140422678904\n",
            "Mean Absolute Error train: 7.952183695451996\n",
            "Root Mean Squared Error train: 10.514416602596459\n",
            "Standard Deviation train: NO2_0    15.509294\n",
            "dtype: float64\n",
            "R^2 test: 0.3866394169849271\n",
            "R^2 adjusted test: 0.3813075326691646\n",
            "Mean Absolute Error test: 10.417640159747808\n",
            "Root Mean Squared Error test: 14.454257853387166\n",
            "Standard Deviation test: NO2_0    18.456012\n",
            "dtype: float64\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}